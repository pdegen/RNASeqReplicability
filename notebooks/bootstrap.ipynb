{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5b552a5-cac0-43d1-849c-222f86b5bb44",
   "metadata": {},
   "source": [
    "# Bootstrap estimation of DEG reliability\n",
    "\n",
    "**Scenario:**\n",
    "\n",
    "- We have an RNA-Seq data set with a relativeily small number of N replicates and wish to perform DEG analysis.\n",
    "\n",
    "**Observation 1:**\n",
    "\n",
    "- SNF2 data set has very high precision for small N (~3)\n",
    "- LMAB data set has very bad precision even for N much larger than 15\n",
    "- Most other data sets we tested are between these two extremes.\n",
    "\n",
    "**Goal:**\n",
    "\n",
    "Can we bootstrap the replicates to predict how \"well-behaved\" the data set is? Concretely, we calculate a metric for each bootstrap sample (e.g. the Kullback–Leibler divergence) and check if the metrics correlates with the precision.\n",
    "\n",
    "- What is the minimum N?\n",
    "- What is the minimum number of bootstrap trials?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae9707b-450a-434f-bce4-2be2f85d4afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import re\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from pathlib import Path\n",
    "\n",
    "datapath = Path(\"../data\")\n",
    "\n",
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "modpath = Path(\"../scripts\")\n",
    "sys.path.append(os.path.abspath(modpath))\n",
    "\n",
    "from misc import open_table\n",
    "\n",
    "# when using UBELIX on-demand\n",
    "os.environ['R_HOME'] = '/storage/homefs/pd21v747/.conda/rna-rep/lib/R/'\n",
    "\n",
    "cores = int(os.getenv(\"SLURM_CPUS_PER_TASK\"))\n",
    "print(\"Cores:\", cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd7f13c-7d9b-422d-be0b-7d8e6dd2b500",
   "metadata": {},
   "source": [
    "# Select data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa2edb0-46cc-4ff9-90aa-68b7b25c9bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_sites_paired = {\"liver\": \"LIHC\",\n",
    "         \"thyroid\": \"THCA\",\n",
    "         \"lung\": \"LUAD\",\n",
    "         \"lung2\": \"LUSC\",\n",
    "         \"kidney\": \"KIRC\",\n",
    "         \"colorectal\": \"COAD\",\n",
    "         \"breast\": \"BRCA\",\n",
    "         \"prostate\": \"PRAD\"}\n",
    "\n",
    "# Misc unpaired only datasets added in revision\n",
    "misc_unpaired = {\n",
    "         \"GSETB\":\"LWPL\",\n",
    "         \"yeast\":\"SNF2\"\n",
    "}\n",
    "\n",
    "misc_custom_design = {\n",
    "            \"GSEPN\":\"GIPF\",\n",
    "            \"breast_basher\": \"BASHER\", # Basal vs HER2+\n",
    "            \"breast_basluma\": \"BASLUMA\", # Basal vs Luminal A\n",
    "            \"breast_baslumb\": \"BASLUMB\", # Basal vs Luminal B\n",
    "            \"breast_herluma\": \"HERLUMA\", # HER2 vs Luminal A\n",
    "            \"breast_herlumb\": \"HERLUMB\", # HER2 vs Luminal B\n",
    "            \"breast_lumab\": \"LUMAB\" # LumA vs LumB\n",
    "}\n",
    "\n",
    "sites = cancer_sites_paired | misc_unpaired | misc_custom_design\n",
    "sites = {k:{\"data\":v,\"confounders\":None} for k,v in sites.items()}\n",
    "\n",
    "for site in misc_custom_design:\n",
    "    if site in [\"GSEPN\"]:\n",
    "        sites[site][\"confounders\"] = [\"age\",\"ever_smoked\",\"Sex\"]\n",
    "    else:\n",
    "        sites[site][\"confounders\"] = [\"TumorPurity\", \"days_to_birth\"]\n",
    "    sites[site][\"paramset\"] = \"p2c\"\n",
    "    sites[site][\"design\"] = \"custom\"\n",
    "    sites[site][\"lfc\"] = 1\n",
    "\n",
    "for site in cancer_sites_paired:\n",
    "    sites[site][\"paramset\"] = \"p2\"\n",
    "    sites[site][\"design\"] = \"paired\"\n",
    "    sites[site][\"lfc\"] = 1\n",
    "\n",
    "for site in misc_unpaired:\n",
    "    sites[site][\"paramset\"] = \"p3\"\n",
    "    sites[site][\"design\"] = \"unpaired\"\n",
    "    sites[site][\"lfc\"] = 1\n",
    "\n",
    "alt_data_names = {\"LWPL\":\"GATB\",\"LUMAB\":\"LMAB\", \"HERLUMA\":\"HRLA\",\"HERLUMB\":\"HRLB\", \"BASHER\":\"BSHR\",\"BASLUMA\":\"BSLA\", \"BASLUMB\":\"BSLB\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cbadfa-6543-4f87-8370-117974cbbfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perpare(selected_site,verbose=False):\n",
    "    meta = None\n",
    "    metafile = None\n",
    "    confounders = None\n",
    "    #selected_site = \"breast_basher\"\n",
    "    data = sites[selected_site][\"data\"]\n",
    "    design = sites[selected_site][\"design\"]\n",
    "    lfc = sites[selected_site][\"lfc\"]\n",
    "    paramset = sites[selected_site][\"paramset\"]\n",
    "    \n",
    "    print(\"Data:\", data, \"\\nDesign:\", design, \"\\nFormal fold change threshold:\", lfc)\n",
    "    \n",
    "    dffile = f\"../data/{selected_site}/{data}/{data}.csv\"\n",
    "    confounders = sites[selected_site][\"confounders\"]\n",
    "    if confounders:\n",
    "        metafile = dffile.replace(\".csv\",\".meta.csv\")\n",
    "    \n",
    "    data = dffile.split(\".csv\")[0].split(\"/\")[-1]\n",
    "    \n",
    "    # Load the full, unsubsampled dataset (later reduced to cohort)\n",
    "    df = pd.read_csv(dffile, index_col=0)\n",
    "    \n",
    "    # We can shuffle the genes to perform a control experiment\n",
    "    shuffle = False\n",
    "    if shuffle:\n",
    "        ix = list(df.columns.values)\n",
    "        np.random.shuffle(ix)\n",
    "        df.columns = ix\n",
    "        df = df[sorted(df.columns)]\n",
    "    \n",
    "    # Load meta data with confoundes to contol for if available\n",
    "    if metafile:\n",
    "        meta = pd.read_csv(metafile, index_col=0)\n",
    "        meta = meta.loc[df.columns]\n",
    "        if confounders:\n",
    "            meta = meta[confounders + [\"Condition\"]]\n",
    "            metafile = metafile.replace(\".csv\",\".sub.csv\")\n",
    "            #meta.rename({condition_col: \"Condition\"}, inplace=True, axis=1)\n",
    "            meta.index.name = \"Sample\"\n",
    "            meta.to_csv(metafile)#, index=False)\n",
    "\n",
    "        if verbose:\n",
    "            display(meta.head())\n",
    "            print(meta.shape)\n",
    "\n",
    "    if verbose:\n",
    "        display(df.head())\n",
    "        print(df.shape)\n",
    "\n",
    "    return df, meta, data, design, lfc, paramset\n",
    "\n",
    "selected_site = \"GSEPN\"\n",
    "df, meta, data, design, lfc, paramset = perpare(selected_site=selected_site,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1400cb-0f3f-4171-b6e2-82017c70b546",
   "metadata": {},
   "source": [
    "# Run bootstrap trials\n",
    "\n",
    "We will re-use the already subsampled cohorts from the main experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fe149e-57c7-4de8-9571-ce0630b297c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DEA import run_dea\n",
    "\n",
    "def prepare2(df,selected_site,data,method,lfc,design,N,cohort,paramset):\n",
    "    # Load subsampled cohort DEA results\n",
    "    cohort_path = f\"../data/{selected_site}/{data}/{data}_N{N}/{data}_N{N}_{cohort:04}\"\n",
    "    cohortfile = f\"{cohort_path}/tab.none.{method}.{paramset}\"\n",
    "    tab_sub = open_table(cohortfile)\n",
    "    \n",
    "    # Load DEA method truth\n",
    "    truthfile = f\"../data/{selected_site}/{data}/{data}.{method}.lfc{lfc}.csv\"\n",
    "    tab_truth = open_table(truthfile)\n",
    "        \n",
    "    def open_df_cohort(cohort_path):\n",
    "        with open(f\"{cohort_path}/config.json\", \"r+\") as f:\n",
    "            configdict = json.load(f)\n",
    "            cohort_samples = configdict[\"samples_i\"]\n",
    "            return df[cohort_samples]\n",
    "    \n",
    "    df_sub = open_df_cohort(cohort_path)\n",
    "    print(cohort_path)\n",
    "    return df_sub, cohort_path, tab_truth, tab_sub\n",
    "\n",
    "\n",
    "def open_bootstrap_results(cohort_path, method, paramset, return_df=True):\n",
    "    results_file = f\"{cohort_path}/tab.bagged.trials*.{method}.{paramset}.csv\"\n",
    "    matched_files = glob.glob(results_file)\n",
    "    if matched_files:\n",
    "        results_file = matched_files[0]\n",
    "        existing_trials = int(results_file.split(\".trials\")[1].split(\".\")[0])\n",
    "        if return_df and existing_trials > 0:\n",
    "            return open_table(results_file), results_file, existing_trials\n",
    "        else:\n",
    "            return None, results_file, existing_trials\n",
    "            \n",
    "    print(\"No bootstrap results file found\")\n",
    "    results_file = f\"{cohort_path}/tab.bagged.trials0.{method}.{paramset}.csv\"\n",
    "    return None, results_file, 0\n",
    "\n",
    "def bootstrap_data(df, N, lfc, design, method, paramset, cohort_path, trials, meta=None, logfile=None):\n",
    "\n",
    "    results = None\n",
    "    \n",
    "    # If exists, read results file where trial results will be concatenated to\n",
    "    results, results_file, existing_trials = open_bootstrap_results(cohort_path, method, paramset)\n",
    "    \n",
    "    if results is None:\n",
    "        print(\"Initializing resultsfile\")\n",
    "        results_file = results_file.replace('trials*','trials0')\n",
    "        os.system(f\"touch {results_file}\")\n",
    "        existing_trials = 0\n",
    "\n",
    "    if existing_trials >= trials :\n",
    "        print(f\"Already have {existing_trials} trials, returning\")\n",
    "        return \"returned_early\"\n",
    "\n",
    "    # Store dea output file in temporary file that will be overwritten in next trial\n",
    "    outfile_dea = f\"../data/tmp/bagg.tmp.{cohort_path.split('/')[-1]}.csv\"\n",
    "            \n",
    "    for trial in range(existing_trials+1, trials+1):\n",
    "        \n",
    "        reps = len(df.columns) // 2\n",
    "        np.random.seed(trial) # in case of miltiprocessing\n",
    "        \n",
    "        for a in range(1,6): # max 5 attempts if DEA fails for small N\n",
    "            try:\n",
    "                bootstrap_samples_N = np.random.choice(df.columns[:reps], N)\n",
    "                bootstrap_samples_T = np.random.choice(df.columns[reps:], N)\n",
    "                bs = list(bootstrap_samples_N)+list(bootstrap_samples_T)\n",
    "                print(f\"Running trial: {trial}, samples: {bs}\")\n",
    "                df_bag = df[bs]\n",
    "        \n",
    "                if design == \"custom\":\n",
    "                    meta_sub = meta.loc[df_bag.columns]\n",
    "                    meta_sub.copy()\n",
    "                    # add suffix to filename avoid multiprocess conflict\n",
    "                    design_sub = f\"../data/tmp/design.{cohort_path.split('/')[-1]}.csv\" \n",
    "                    meta_sub.index = [col+str(i) for i, col in enumerate(meta_sub.index)]\n",
    "                    meta_sub.to_csv(design_sub)\n",
    "                elif design in [\"paired\", \"unpaired\"]:\n",
    "                    design_sub = design\n",
    "            \n",
    "                df_bag.columns = [col+str(i) for i, col in enumerate(df_bag.columns)]\n",
    "        \n",
    "                edgerqlf_kwargs = {\"filter_expr\": True, \"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"], \"lfc\": lfc, \"design\": design_sub,\n",
    "                           \"check_gof\": False, \"verbose\": False}\n",
    "                edgerlrt_kwargs = {\"filter_expr\": True, \"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"], \"lfc\": lfc, \"design\": design_sub,\n",
    "                           \"check_gof\": False, \"verbose\": False}\n",
    "                deseq2_kwargs = {\"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"],\"lfc\": lfc, \"design\": design_sub}\n",
    "\n",
    "\n",
    "                match method:\n",
    "                    case \"edgerqlf\":\n",
    "                        edgerqlf_kwargs[\"design\"] = design_sub\n",
    "                        run_dea(df_bag, outfile_dea, \"edgerqlf\", True, verbose=False, **edgerqlf_kwargs)\n",
    "                    case \"edgerlrt\":\n",
    "                        edgerlrt_kwargs[\"design\"] = design_sub\n",
    "                        run_dea(df_bag, outfile_dea, \"edgerlrt\", True, verbose=False, **edgerlrt_kwargs)\n",
    "                    case \"deseq2\":\n",
    "                        deseq2_kwargs[\"design\"] = design_sub\n",
    "                        run_dea(df_bag, outfile_dea, \"deseq2\", True, verbose=False, **deseq2_kwargs)\n",
    "                if a > 2 and logfile is not None:\n",
    "                    log = f\"{cohort_path} N{N} {paramset} attempts: {a}\"\n",
    "                    os.system(f\"echo {log} >> {logfile}\")\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        trial_results = open_table(outfile_dea)\n",
    "\n",
    "        if results is None:\n",
    "            results = trial_results            \n",
    "        else:\n",
    "            results = pd.concat([results,trial_results])\n",
    "            \n",
    "\n",
    "        # Increment file name, save new bagged result, rm old\n",
    "        results_file_p1 = re.sub(r\"trials(\\d+)\", lambda m: f\"trials{int(m.group(1)) + 1}\", results_file)\n",
    "        results.to_csv(results_file_p1)\n",
    "        os.system(f\"rm {results_file}\")\n",
    "        results_file = results_file_p1\n",
    "\n",
    "    if logfile is not None:\n",
    "        now = datetime.datetime.now()\n",
    "        log = f\"{cohort_path} N{N} {paramset} trials: {trials} {now}\"\n",
    "        os.system(f\"echo {log} >> {logfile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a837b9a-7fd1-43dd-b8f7-3d767ff50b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run single cohort\n",
    "\n",
    "#Select subsample size\n",
    "N = 5\n",
    "\n",
    "# Select one of the 100 cohorts already subsampled\n",
    "cohort = 9\n",
    "\n",
    "method = \"deseq2\" #  one in [\"deseq2\", \"edgerqlf\", \"edgerlrt\"]\n",
    "\n",
    "df_sub, cohort_path, tab_truth, tab_sub = prepare2(df,selected_site,data,method,lfc,design,N,cohort,paramset)\n",
    "\n",
    "bootstrap_data(df_sub, N, lfc, design, method, paramset, cohort_path, trials=25, meta=meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5445624a-6aed-41b5-bf93-24518230c00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multiple cohorts in parallel\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "cohorts = 10\n",
    "all_N = [5]#,10]\n",
    "trials = 25\n",
    "method = \"deseq2\" #  one in [\"deseq2\", \"edgerqlf\", \"edgerlrt\"]\n",
    "logfile = \"../data/multi/log.bag.txt\"\n",
    "cores = int(os.getenv(\"SLURM_CPUS_PER_TASK\"))\n",
    "print(\"Cores:\", cores)\n",
    "\n",
    "def bootstrap_multi(df,selected_site,data,method,lfc,design,N,paramset,trials,meta,logfile,cohort):\n",
    "\n",
    "    # Check if trials already exist\n",
    "    cohort_path = f\"../data/{selected_site}/{data}/{data}_N{N}/{data}_N{N}_{cohort:04}\"\n",
    "    _, _, existing_trials = open_bootstrap_results(cohort_path, method, paramset, return_df=False)\n",
    "    if existing_trials >= trials: \n",
    "        print(f\"{trials} already exist, returning...\")\n",
    "        return\n",
    "    \n",
    "    df_sub, cohort_path, tab_truth, tab_sub = prepare2(df,selected_site,data,method,lfc,design,N,cohort,paramset)\n",
    "    bootstrap_data(df_sub, N, lfc, design, method, paramset, cohort_path, trials=trials, meta=meta, logfile=logfile)\n",
    "      \n",
    "for selected_site in sites:\n",
    "    if selected_site != \"GSEPN\": continue\n",
    "    df, meta, data, design, lfc, paramset = perpare(selected_site=selected_site)\n",
    "    for N in all_N:\n",
    "        with mp.Pool(processes=cores) as pool:\n",
    "            args = df,selected_site,data,method,lfc,design,N,paramset,trials,meta,logfile\n",
    "            pool.starmap(bootstrap_multi, [(*args, i) for i in range(1,1+cohorts)])\n",
    "\n",
    "# Clean up\n",
    "os.system(f\"rm ../data/tmp/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f054f660-47f9-4e4c-a559-dec26815178c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results, _, trials = open_bootstrap_results(cohort_path, method, paramset)\n",
    "genes = len(results) // trials\n",
    "print(genes)\n",
    "assert genes == len(df_sub)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b705956-4984-4718-857e-6270a84f4d65",
   "metadata": {},
   "source": [
    "# Inspect results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92dc8eb-8d4d-4894-a02b-e2cb1a53407e",
   "metadata": {},
   "source": [
    "## Divergence\n",
    "\n",
    "Calculate Kullback-Leibler divergence between bootstrap samples, subsampled cohort, and ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e78be8a-ea5f-42f1-b3e2-ea860a958b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc import get_kl_div\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def kls_box(kls_df, ax):\n",
    "    sns.boxplot(kls_df, ax=ax)\n",
    "    sns.stripplot(kls_df, color=\"black\", ax=ax)\n",
    "    ax.set(ylabel=\"KL Divergence\")    \n",
    "\n",
    "def get_kls_lists(tab_truth, tab_sub, results, trials, ax=None):\n",
    "    kls_sub, kls_truth = [], []\n",
    "    for trial in range(trials):\n",
    "        ix = np.arange(trial*len(results)//trials, (trial+1)*len(results)//trials)\n",
    "        bag = results.iloc[ix][\"logFC\"]\n",
    "        if ax:\n",
    "            sns.kdeplot(bag,color=\"grey\", ax=ax, label=\"Bootstrapped\" if trial==0 else None)\n",
    "        kl = get_kl_div(tab_sub[\"logFC\"], bag, bins=np.linspace(-4,4,50))\n",
    "        kls_sub.append(kl)\n",
    "        kl = get_kl_div(tab_truth[\"logFC\"], bag, bins=np.linspace(-4,4,50))\n",
    "        kls_truth.append(kl)\n",
    "    return kls_truth, kls_sub\n",
    "\n",
    "def get_spearman_lists(tab_truth, tab_sub, results, trials):\n",
    "    spearman_sub, spearman_truth = [], []\n",
    "    genes = len(results)//trials\n",
    "    tab_sub_rank = tab_sub[\"logFC\"].rank()\n",
    "    tab_truth_rank = tab_truth[\"logFC\"].rank()\n",
    "\n",
    "    if len(results) % genes != 0:\n",
    "        print(f\"Unequal lengths, spearman no calculated\")\n",
    "        return [], []\n",
    "\n",
    "    for trial in range(trials):\n",
    "        ix = np.arange(trial*genes, (trial+1)*genes)\n",
    "        bag_rank = results.iloc[ix][\"logFC\"].rank()\n",
    "        spearman = spearmanr(tab_sub_rank, bag_rank).statistic\n",
    "        spearman_sub.append(spearman)\n",
    "        spearman = spearmanr(tab_truth_rank, bag_rank).statistic\n",
    "        spearman_truth.append(spearman)\n",
    "    return spearman_truth, spearman_sub\n",
    "\n",
    "def results_logfc_wide(results, trials):\n",
    "    t = results[\"logFC\"]\n",
    "    return pd.DataFrame(np.array(t).reshape(len(t)//trials, trials, order='F'), index=t.index[:len(t)//trials])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cb7913-f14c-4179-9f39-10ce19b94ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "kls_truth, kls_sub = get_kls_lists(tab_truth, tab_sub, results, trials, ax=ax[0])\n",
    "\n",
    "sns.kdeplot(tab_truth[\"logFC\"], alpha=1, ax=ax[0], label=\"Truth\",color=\"cyan\")\n",
    "sns.kdeplot(tab_sub[\"logFC\"], alpha=1, ls=\"--\", color=\"red\",ax=ax[0],label=f\"N{N} Cohort {cohort}\")\n",
    "\n",
    "kls_df = pd.DataFrame(np.array([kls_truth,kls_sub]).T, columns=[\"Truth\", \"Cohort\"])\n",
    "\n",
    "kls_box(kls_df, ax=ax[1])\n",
    "kl_truth_vs_sub = get_kl_div(tab_truth[\"logFC\"], tab_sub[\"logFC\"], bins=np.linspace(-4,4,50))\n",
    "ax[1].axhline(kl_truth_vs_sub, label=\"Truh vs Cohort\", color=\"green\")\n",
    "\n",
    "for a in ax:\n",
    "    a.legend(loc=\"best\")\n",
    "\n",
    "fig.suptitle(f\"Data: {data} | Trials: {trials}\")\n",
    "fig.tight_layout()\n",
    "figpath = f\"../figures/boot.kl.{data}.N{N}.pdf\"\n",
    "#fig.savefig(figpath)\n",
    "#print(figpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08607af-bae4-4be3-83a8-38b8ae4ac817",
   "metadata": {},
   "source": [
    "# Multidata plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23df60d-9d6e-42ed-b31c-38d3b62e20f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_sites = [\"yeast\", \"GSETB\",\"GSEPN\",\"breast_lumab\", \"breast_herluma\",\"breast_herlumb\",\"breast_basher\",\"breast_basluma\",\"breast_baslumb\",\"thyroid\",\"lung\",\"breast\",\"prostate\",\"kidney\",\"colorectal\",\"liver\",\"lung2\"]\n",
    "# N = 5\n",
    "# cohort = 1\n",
    "# cols = 4\n",
    "# rows = len(selected_sites) / cols\n",
    "# rows = int(np.ceil(rows))\n",
    "# fig, axes = plt.subplots(rows, cols, figsize=(cols*5,rows*5), sharey=True)\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# for ax, site in zip(axes, selected_sites):\n",
    "#     data_site = sites[site]['data']\n",
    "#     paramset_site = sites[site][\"paramset\"]\n",
    "#     cohort_path_site = f\"../data/{site}/{data_site}/{data_site}_N{N}/{data_site}_N{N}_{cohort:04}\"\n",
    "#     results_site, _, trials_site = open_bootstrap_results(cohort_path_site, method, paramset_site)\n",
    "#     if results_site is None: continue\n",
    "#     print(site, trials_site, len(results_site) // trials_site)\n",
    "\n",
    "#     cohortfile_site = f\"{cohort_path_site}/tab.none.{method}.{paramset_site}\"\n",
    "#     tab_sub_site = open_table(cohortfile_site)\n",
    "#     truthfile_site = f\"../data/{site}/{data_site}/{data_site}.{method}.lfc{lfc}.csv\"\n",
    "#     tab_truth_site = open_table(truthfile_site)\n",
    "#     kls_truth_site, kls_sub_site = get_kls_lists(tab_truth_site, tab_sub_site, results_site, trials_site)\n",
    "#     kls_df_site = pd.DataFrame(np.array([kls_truth_site,kls_sub_site]).T, columns=[\"Truth\", \"Cohort\"])\n",
    "    \n",
    "#     kls_box(kls_df_site, ax)\n",
    "#     ax.set(title=f\"Data: {data_site} N{N} | Trials: {trials_site}\")\n",
    "\n",
    "#     truthfile_site = f\"../data/{site}/{data_site}/{data_site}.{method}.lfc{lfc}.csv\"\n",
    "#     tab_truth_site = open_table(truthfile_site)\n",
    "\n",
    "#     cohortfile_site = f\"{cohort_path_site}/tab.none.{method}.{sites[site][\"paramset\"]}\"\n",
    "#     tab_sub_site = open_table(cohortfile_site)\n",
    "\n",
    "#     kl_truth_vs_sub_site = get_kl_div(tab_truth_site[\"logFC\"], tab_sub_site[\"logFC\"], bins=np.linspace(-4,4,50))\n",
    "#     ax.axhline(kl_truth_vs_sub_site, label=\"Truh vs Cohort\", color=\"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb98cdd2-4093-4872-a765-6190c8f4b4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_long_df(all_N, cohorts):\n",
    "\n",
    "    df_long = []\n",
    "    \n",
    "    for site in sites:\n",
    "        for N in all_N:\n",
    "            for cohort in cohorts:\n",
    "                data_site = sites[site]['data']\n",
    "                paramset_site = sites[site][\"paramset\"]\n",
    "                cohort_path_site = f\"../data/{site}/{data_site}/{data_site}_N{N}/{data_site}_N{N}_{cohort:04}\"\n",
    "                results_site, _, trials_site = open_bootstrap_results(cohort_path_site, method, paramset_site)\n",
    "                if results_site is None: continue\n",
    "                print(site, N, \"cohort\", cohort, \"tials:\", trials_site, len(results_site) // trials_site)\n",
    "    \n",
    "                cohortfile_site = f\"{cohort_path_site}/tab.none.{method}.{paramset_site}\"\n",
    "                tab_sub_site = open_table(cohortfile_site)\n",
    "                truthfile_site = f\"../data/{site}/{data_site}/{data_site}.{method}.lfc{lfc}.csv\"\n",
    "                tab_truth_site = open_table(truthfile_site)\n",
    "\n",
    "                # Compute metrics\n",
    "                kls_truth_site, kls_sub_site = get_kls_lists(tab_truth_site, tab_sub_site, results_site, trials_site)\n",
    "                spear_truth_site, spear_sub_site = get_spearman_lists(tab_truth_site, tab_sub_site, results_site, trials_site)\n",
    "    \n",
    "        \n",
    "                kls_df_site = pd.DataFrame(np.array([kls_truth_site,kls_sub_site]).T, columns=[\"Truth\", \"Cohort\"])\n",
    "                spear_df_site = pd.DataFrame(np.array([spear_truth_site,spear_sub_site]).T, columns=[\"Truth\", \"Cohort\"])\n",
    "                kls_df_site = kls_df_site.melt(var_name='Reference', value_name='KL')\n",
    "                spear_df_site = spear_df_site.melt(var_name='Reference', value_name='Spearman')\n",
    "                kls_df_site[\"Data\"] = data_site\n",
    "                kls_df_site[\"N\"] = N\n",
    "                kls_df_site[\"Cohort\"] = cohort\n",
    "                kls_df_site = pd.concat([kls_df_site, spear_df_site[\"Spearman\"]], axis=1)\n",
    "                df_long.append(kls_df_site)\n",
    "\n",
    "\n",
    "    df_long = pd.concat(df_long)\n",
    "    df_long.replace({\"Data\": alt_data_names}, inplace=True)\n",
    "    return df_long\n",
    "\n",
    "reload = True\n",
    "all_N = [5]#,10]\n",
    "cohorts = list(range(1,11))\n",
    "\n",
    "if reload:\n",
    "    print(\"Reloading df\")\n",
    "    df_long = load_long_df(all_N, cohorts)\n",
    "    #df_long.to_csv(\"../data/multi/df_boot_long.csv\")\n",
    "else:\n",
    "    df_long = pd.read_csv(\"../data/multi/df_boot_long.csv\", index_col=0)\n",
    "    print(\"Loaded saved df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b4738-e84b-4986-93f9-f9ff86ab2b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# site = \"GSEPN\"\n",
    "# data_site = sites[site][\"data\"]\n",
    "# paramset_site = sites[site][\"paramset\"]\n",
    "# cohort_path_site = f\"../data/{site}/{data_site}/{data_site}_N{N}/{data_site}_N{N}_{cohort:04}\"\n",
    "# cohortfile_site = f\"{cohort_path_site}/tab.none.{method}.{paramset_site}\"\n",
    "# tab_sub_site = open_table(cohortfile_site)\n",
    "# print(len(tab_sub_site))\n",
    "# results_site, _, trials_site = open_bootstrap_results(cohort_path_site, method, paramset_site)\n",
    "# len(results_site) // trials_site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f19e32-61e2-4b3f-a9cd-75642ba382a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all for duplicates\n",
    "reference = \"Cohort\"\n",
    "all_N = [5]\n",
    "\n",
    "rm_duplicates = False\n",
    "\n",
    "for site in sites:\n",
    "    data_site = sites[site][\"data\"]\n",
    "    data_alt = alt_data_names[data_site] if data_site in alt_data_names else data_site\n",
    "\n",
    "    paramset_site = sites[site][\"paramset\"]\n",
    "    \n",
    "    for N in all_N:\n",
    "        for cohort in cohorts:\n",
    "\n",
    "            cohort_path_site = f\"../data/{site}/{data_site}/{data_site}_N{N}/{data_site}_N{N}_{cohort:04}\"\n",
    "            cohortfile_site = f\"{cohort_path_site}/tab.none.{method}.{paramset_site}\"\n",
    "            tab_sub_site = open_table(cohortfile_site)\n",
    "            _, results_file_site, _ = open_bootstrap_results(cohort_path_site, method, paramset_site, return_df=False)\n",
    "        \n",
    "            k = df_long\n",
    "            k = k[(k[\"Data\"]==data_alt) & (k[\"Reference\"]==reference) & (k[\"N\"]==N) & (k[\"Cohort\"]==cohort)]\n",
    "            dupes = k.duplicated().sum()\n",
    "            if dupes > 0:\n",
    "                print(data_site, f\"N{N:<2} Cohort {cohort}:\", dupes)\n",
    "                print(results_file_site)\n",
    "                if rm_duplicates:\n",
    "                    os.system(f\"rm {results_file_site}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ea5dc7-b272-4ded-8b35-6e86fb7fa4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check individual for duplicates\n",
    "site = \"GSEPN\"\n",
    "cohort = 3\n",
    "N = 5\n",
    "\n",
    "data_site = sites[site]['data']\n",
    "paramset_site = sites[site][\"paramset\"]\n",
    "\n",
    "if data_site in alt_data_names: data_site = alt_data_names[data_site]\n",
    "k = df_long\n",
    "k = k[(k[\"Data\"]==data_site) & (k[\"Reference\"]==reference) & (k[\"N\"]==N)]\n",
    "print(data_site, f\"N{N:<2}\", \"Duplicates:\", k.duplicated().sum())\n",
    "cohort_path_site = f\"../data/{site}/{data_site}/{data_site}_N{N}/{data_site}_N{N}_{cohort:04}\"\n",
    "results_site, _, trials_site = open_bootstrap_results(cohort_path_site, method, paramset_site)\n",
    "results_logfc_wide(results_site, trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a173b-6b5f-4693-80e1-12133b437e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = \"Cohort\"\n",
    "N = 5\n",
    "cohort = 5\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,4))\n",
    "k = df_long\n",
    "df_ref = k[(k[\"Reference\"]==reference) & (k[\"N\"]==N) & (k[\"Cohort\"]==cohort)]\n",
    "sns.boxplot(data=df_ref, x=\"Data\", y=\"KL\", ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811b0deb-b1d8-49d8-9ecd-f5934322135d",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "Create wide df with different metrics (precision, KL, spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92eeffc-1e11-4abf-b963-b78669c2158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_all = pd.read_csv(\"../data/multi/combined_all.csv\", index_col=0)\n",
    "combined_all = combined_all[~combined_all[\"isSynthetic\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fd96cf-5925-4489-b31e-cbc1b0ca795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_N = [5,10]\n",
    "dfm = pd.DataFrame(index = list(set(combined_all[\"Data\"])))\n",
    "for N_ in all_N:\n",
    "    c = combined_all\n",
    "    c = c[(c[\"N\"]==N_)&(c[\"DEA\"]==\"DESeq2 Wald\")&(c[\"logFC\"]==1)&(c[\"lfc_mode\"]==\"formal\")]\n",
    "    c.set_index(\"Data\", inplace=True)\n",
    "    dfm[f\"Prec_N{N_}\"] = c[\"median_prec\"]\n",
    "\n",
    "k = df_long\n",
    "for ref in [\"Truth\",\"Cohort\"]:\n",
    "    for N in all_N:\n",
    "        df_ref = k[(k[\"Reference\"]==ref) & (k[\"N\"]==N)]\n",
    "        dfm[f\"KL_{ref}_N{N}_mean\"] = df_ref.groupby(\"Data\")[\"KL\"].mean()\n",
    "        dfm[f\"KL_{ref}_N{N}_std\"] = df_ref.groupby(\"Data\")[\"KL\"].std()\n",
    "        dfm[f\"Spear_{ref}_N{N}_mean\"] = df_ref.groupby(\"Data\")[\"Spearman\"].mean()\n",
    "        dfm[f\"Spear_{ref}_N{N}_std\"] = df_ref.groupby(\"Data\")[\"Spearman\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59253a0-97fd-474b-8cbd-a60406a96997",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"GIPF\"\n",
    "reference = \"Cohort\"\n",
    "N = 5\n",
    "k = df_long\n",
    "k = k[(k[\"Data\"]==data) & (k[\"Reference\"]==reference) & (k[\"N\"]==N)]\n",
    "sns.boxplot(data=k, x=\"Cohort\",y=\"KL\")\n",
    "plt.title(f\"{data} N{N}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2febef2-4855-47d0-bc7e-985791dba745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "reference = \"Cohort\"\n",
    "metric = f\"mean\"\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10,4),sharex=False)\n",
    "df_ref = ksl_df_all_sites[ksl_df_all_sites[\"Reference\"]==reference]\n",
    "sns.scatterplot(data=dfm, y=\"Prec_N5\", x=f\"KL_{reference}_N5_{metric}\", hue=dfm.index, style=dfm.index, s=200, ax=ax[0])\n",
    "sns.regplot(data=dfm, y=\"Prec_N5\", x=f\"KL_{reference}_N5_{metric}\", ax=ax[0], scatter_kws={'s':0})\n",
    "    \n",
    "sns.scatterplot(data=dfm, y=\"Prec_N10\", x=f\"KL_{reference}_N10_{metric}\", hue=dfm.index, style=dfm.index, s=200, ax=ax[1])\n",
    "sns.regplot(data=dfm, y=\"Prec_N10\", x=f\"KL_{reference}_N10_{metric}\", scatter_kws={'s':0}, ax=ax[1])\n",
    "\n",
    "for N, a in zip([5,10], ax):\n",
    "    r_val, p_val = stats.pearsonr(dfm[f\"KL_{reference}_N10_{metric}\"], dfm[f\"Prec_N{N}\"])\n",
    "    r2_val = r_val ** 2\n",
    "    a.text(0.05, 0.05, f\"r = {r_val:.2f}\\nr² = {r2_val:.2f}\\np = {p_val:.3g}\", \n",
    "           transform=a.transAxes, fontsize=10, verticalalignment='bottom')\n",
    "\n",
    "ax[0].legend().remove()\n",
    "ax[1].legend(bbox_to_anchor=(1,1.06))\n",
    "ax[0].set(ylabel=\"Median Precision (N=5)\")\n",
    "ax[1].set(ylabel=\"Median Precision (N=10)\")\n",
    "for a in ax:\n",
    "    a.set(xlabel=(f\"{metric.split('_')[-1].capitalize()} KL Divergence\"))\n",
    "    a.set(ylim=(-0.05,1.05))\n",
    "fig.suptitle(\"KL of 25 Bootstrap trials relative to 1 Cohort\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e7f85e-353e-4bc5-a817-ee196e24ea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_N = [5,10]\n",
    "cohorts = list(range(1,11))\n",
    "\n",
    "site = \"GSEPN\"\n",
    "N = 5\n",
    "cohort = 1\n",
    "\n",
    "data_site = sites[site]['data']\n",
    "paramset_site = sites[site][\"paramset\"]\n",
    "cohort_path_site = f\"../data/{site}/{data_site}/{data_site}_N{N}/{data_site}_N{N}_{cohort:04}\"\n",
    "results_site, _, trials_site = open_bootstrap_results(cohort_path_site, method, paramset_site)\n",
    "\n",
    "cohortfile_site = f\"{cohort_path_site}/tab.none.{method}.{paramset_site}\"\n",
    "tab_sub_site = open_table(cohortfile_site)\n",
    "truthfile_site = f\"../data/{site}/{data_site}/{data_site}.{method}.lfc{lfc}.csv\"\n",
    "tab_truth_site = open_table(truthfile_site)\n",
    "\n",
    "genes = len(results_site)//trials\n",
    "print(\"Genes:\", genes)\n",
    "\n",
    "assert np.all(results_site.index.value_counts() == trials)\n",
    "assert len(tab_sub_site) == genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec317f44-2039-402d-882b-7c9064f81542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def get_spearman(aa,bb):\n",
    "        aa = aa.dropna()\n",
    "        bb = bb.dropna()\n",
    "        common = aa.index.intersection(bb.index)\n",
    "        aa = aa.loc[common].rank()\n",
    "        bb = bb.loc[common].rank()\n",
    "        return spearmanr(aa,bb)\n",
    "    \n",
    "def get_pairwise_spearman(results_wide):\n",
    "    spearmans = []\n",
    "    for a, b in combinations(results_wide.columns, 2):\n",
    "        aa = results_wide[a]\n",
    "        bb = results_wide[b]\n",
    "        spearmans.append(np.array(get_spearman(aa, bb)))\n",
    "    return pd.DataFrame(spearmans, columns=[\"Statistic\",\"pval\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2046bf6f-c08b-4f9c-ab8a-9a75878dbb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_wide = results_logfc_wide(results_site, trials)\n",
    "spearmans = get_pairwise_spearman(results_wide)\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(8,4))\n",
    "spearmans[\"Statistic\"].hist(ax=ax[0])\n",
    "ax[0].set_title(f\"Mean spearman: {spearmans[\"Statistic\"].mean():.2f}\")\n",
    "\n",
    "a=results_wide[0]\n",
    "b=results_wide[1]\n",
    "ax[1].scatter(a.rank(), b.rank(), alpha=0.05)\n",
    "ax[1].set_title(f\"Spearman: {get_spearman(a, b).statistic:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2419f447-0ce7-4a6d-a214-2404eda9ad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iqr(tab, cutoff, CI=0.5):\n",
    "    mean_lfc = tab.median(axis=1).sort_values(ascending=False)\n",
    "    x = range(len(mean_lfc))\n",
    "    \n",
    "    # not really a confidence interval\n",
    "    up_lim = (1+CI)/2\n",
    "    low_lim = (1-CI)/2\n",
    "    cutoff = 1\n",
    "    \n",
    "    #std_lfc = tab.std(axis=1).loc[mean_lfc.index]\n",
    "    up = tab.quantile(up_lim,axis=1).loc[mean_lfc.index]\n",
    "    low = tab.quantile(low_lim,axis=1).loc[mean_lfc.index]\n",
    "    \n",
    "    crossing = mean_lfc[ ((up>-cutoff) & (low<-cutoff)) | ((up>cutoff) & (low<cutoff)) ]\n",
    "    cross_ind = np.array(x)[mean_lfc.index.isin(crossing.index)]\n",
    "    \n",
    "    mean_pass_cutoff = mean_lfc[mean_lfc.abs()>cutoff]\n",
    "\n",
    "    return up, low, crossing, cross_ind, mean_pass_cutoff, x, mean_lfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49719284-80b5-4c61-a01e-6c51cff15164",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(20,10))\n",
    "cutoff = 1\n",
    "CI = 0.5\n",
    "up, low, crossing, cross_ind, mean_pass_cutoff, x, mean_lfc = get_iqr(results_wide, cutoff=cutoff, CI=CI)\n",
    "    \n",
    "#ax.plot(x, mean_lfc,lw=4,label=\"Mean\")\n",
    "ax.scatter(x, mean_lfc,label=\"Mean\")\n",
    "ax.scatter(cross_ind, crossing, label=f\"# Crossing: {len(crossing)} ({len(crossing)/len(x):.2%})\")\n",
    "\n",
    "#ax.scatter(x, tab_truth_site.loc[mean_lfc.index, \"logFC\"], label=f\"Truth\")\n",
    "#ax.scatter(x, tab_sub_site.loc[mean_lfc.index, \"logFC\"], label=f\"Original cohort\")\n",
    "\n",
    "ax.axhline(cutoff,ls=\"--\",c=\"red\",label=f\"Cutoff = {cutoff}\")\n",
    "ax.axhline(-cutoff,ls=\"--\",c=\"red\")\n",
    "ax.fill_between(x, up, low, edgecolor=\"none\",color=\"grey\",alpha=0.5,label=f\"{CI:.0%} IQR\")\n",
    "#ax.fill_between(cross_ind, up.iloc[cross_ind], low.iloc[cross_ind], edgecolor=\"none\",color=\"pink\",alpha=0.5,label=\"Crossing\")\n",
    "ax.set_xlabel(\"Gene Rank\")\n",
    "ax.set_ylabel(r\"log$_2$FC\")\n",
    "ax.set_title(f\"Bootstrapped with {trials} trials\")\n",
    "ax.legend(framealpha=1,title=f\"{sites[site]['data']} N{N} {method}\\n|Mean|>{cutoff} = {len(mean_pass_cutoff)}\",title_fontsize=16)\n",
    "#ax.set_xlim(8360,8400)\n",
    "figpath = f\"../figures/iqr.boot.{data_site}.N{N}.cohort{cohort}.png\"\n",
    "fig.savefig(figpath)\n",
    "print(figpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeb3ca4-3db5-4d41-ae87-9bed0d7addde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "X1 = dfm[f\"KL_{reference}_N10_mean\"]\n",
    "X2 = dfm[f\"KL_{reference}_N10_std\"]\n",
    "y = dfm[\"Prec_N10\"]\n",
    "\n",
    "# Fit model\n",
    "X = np.column_stack((X1, X2))\n",
    "model = LinearRegression().fit(X, y)\n",
    "\n",
    "# Generate grid for contour plot\n",
    "X1_grid, X2_grid = np.meshgrid(np.linspace(0, .07, 100), np.linspace(0, .07, 100))\n",
    "y_pred = model.intercept_ + model.coef_[0] * X1_grid + model.coef_[1] * X2_grid\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "norm = mcolors.Normalize(vmin=0, vmax=1)\n",
    "mappable = cm.ScalarMappable(norm=norm, cmap='inferno')\n",
    "cbar = fig.colorbar(mappable, ax=a)\n",
    "\n",
    "contour = ax.contourf(X1_grid, X2_grid, y_pred, levels=40, cmap=\"inferno\", norm=norm)\n",
    "sc = ax.scatter(X1, X2, c=y, cmap=\"inferno\", edgecolors='k', norm=norm)\n",
    "\n",
    "# Color bar\n",
    "cbar = fig.colorbar(contour, ax=ax)\n",
    "cbar.set_label(\"Predicted y\")\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel(\"KL mean\")\n",
    "ax.set_ylabel(\"KL Std\")\n",
    "ax.set_title(\"Multiple Linear Regression - Contour Plot\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e0f584-9ecf-4741-b161-6ef2a0137fa3",
   "metadata": {},
   "source": [
    "# How many trials?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8bc0db-a8ba-41a0-b4fb-8a8f424cfbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import comb\n",
    "\n",
    "def comb_with_replace(n):\n",
    "    return comb(2*n-1, n)\n",
    "\n",
    "for i in range(1,11):\n",
    "    y = comb_with_replace(i)\n",
    "    plt.scatter(i,y,color=\"cornflowerblue\")\n",
    "    plt.text(i,2*y,y,ha=\"center\",va=\"center\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Cohort Size (N)\")\n",
    "plt.ylabel(\"Combinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3546bbb-32ae-4cc8-bf09-9d9211e66c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations_with_replacement\n",
    "\n",
    "a = [0,1,2,3,4]\n",
    "print(len(list(combinations_with_replacement(a,5))))\n",
    "for c in combinations_with_replacement(a,5):\n",
    "    print(c)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7384c9-1cf5-4141-9d56-1c408ce01170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x):\n",
    "    N = len(x)\n",
    "    running_mean = np.cumsum(x) / np.arange(1, N + 1)\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(np.arange(1, N + 1), running_mean, label=\"Running Mean\", color='b')\n",
    "    plt.axhline(y=np.mean(x), color='r', linestyle='--', label=\"Final Mean\")\n",
    "    plt.xlabel(\"Bootstrap Trial Number (i)\")\n",
    "    plt.ylabel(\"Mean of First i Trials\")\n",
    "    plt.title(\"Running Mean of Bootstrap Estimates\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "d=df_ref\n",
    "d=d[d[\"Data\"]==\"LMAB\"]\n",
    "\n",
    "running_mean(d[\"KL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bce4e0-728b-4699-8813-6325cb75e7dd",
   "metadata": {},
   "source": [
    "# Misc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987bd3a7-e6c3-46a9-96a2-4568e893408e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "importlib.reload(sys.modules[\"misc\"])\n",
    "from DEA import run_dea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3616c6-b13d-46af-aa43-252e9ea52320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dda57f-0cbc-43f3-aef2-296659057802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c406befc-7015-4958-a411-f5445a4de7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0795f5-85ac-4731-a439-5f36ca870e15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rna-rep)",
   "language": "python",
   "name": "rna-rep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
