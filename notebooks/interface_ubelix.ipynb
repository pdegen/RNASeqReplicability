{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce994fa7-ad3c-4162-b2ff-ce5d4d95fa3b",
   "metadata": {},
   "source": [
    "Notebook to send jobs to the Ubelix HPC cluster at the University of Bern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45066980-1b1d-4b28-8217-caffb9ddfd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import glob\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "import rpy2.robjects as ro\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "logging.basicConfig(filename='example.log', \n",
    "                    encoding='utf-8', level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "datapath = Path(\"../data\")\n",
    "#datapath = Path(\"/storage/homefs/pd21v747/datanew\")\n",
    "\n",
    "modpath = Path(\"../scripts\")\n",
    "sys.path.append(os.path.relpath(modpath))\n",
    "\n",
    "from misc import Timer, pickler, open_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa06e64-3add-4b07-ad2b-4cf6a6eaad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = {\"liver\": \"LIHC\",\n",
    "         \"thyroid\": \"THCA\",\n",
    "         \"lung\": \"LUAD\",\n",
    "         \"kidney\": \"KIRC\",\n",
    "         \"colorectal\": \"COAD\",\n",
    "         \"breast\": \"BRCA\",\n",
    "         \"prostate\": \"PRAD\"}\n",
    "\n",
    "datasets = {sites[s]: {} for s in sites}\n",
    "\n",
    "for s in sites:\n",
    "    f = Path(f\"{datapath}/{s}/{sites[s]}/{sites[s]}.csv\")\n",
    "    df = pd.read_csv(f, index_col=0)\n",
    "    datasets[sites[s]][\"genes\"] = len(df)\n",
    "    datasets[sites[s]][\"site\"] = s\n",
    "    datasets[sites[s]][\"datapath\"] = f\n",
    "    datasets[sites[s]][\"outpath\"] = f.parent\n",
    "    datasets[sites[s]][\"patients\"] = len(df.columns)//2\n",
    "    print(f\"{s:<10}\", datasets[sites[s]][\"genes\"], datasets[sites[s]][\"patients\"])\n",
    "    \n",
    "# Pretty names\n",
    "cleanout = {\"jk\": \"ReBoost\",\n",
    "            \"pcah\": \"rPCA\",\n",
    "            \"none\": \"None\"}\n",
    "cleandea = {\"edger\": \"edgeR QLF\",\n",
    "            \"edgerlrt\": \"edgeR LRT\",\n",
    "            \"deseq2\": \"DESeq2\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b4ca6b-3492-4182-8d33-cb32f8a3d942",
   "metadata": {},
   "source": [
    "# Differential expression analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34570dc0-6cb6-41f1-9fff-12cf46bd124d",
   "metadata": {},
   "source": [
    "## Define ground truth\n",
    "\n",
    "Define ground truth DEGs for a given FDR, logFC cutoff as the intersection of DEGs from all three DEA tests (Wald, LRT, QLF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d9bb32-f841-4f65-be03-2343c4a3d3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DEA import run_dea_on_full_data\n",
    "from process import find_ground_truth\n",
    "\n",
    "DEAs = [\"edgerlrt\", \"edger\", \"deseq2\"]\n",
    "FDRs = [0.1,0.05,0.01,0.001]\n",
    "logFCs = [0, 1] # formal lfc threhsold in edger or deseq2\n",
    "logFCs_post = [0,0.5,1,1.5,2] # post hoc thresholds\n",
    "\n",
    "run_dea_on_full_data(datasets, DEAs, overwrite = False, lfcs = logFCs)\n",
    "\n",
    "datasets = find_ground_truth(datasets, DEAs, FDRs, logFCs_post, lfc_test = 0)\n",
    "datasets = find_ground_truth(datasets, DEAs, FDRs, [1], lfc_test = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abd85c8-d1f3-4bd0-96bd-5361cbc77d7a",
   "metadata": {},
   "source": [
    "## Send batch jobs for selected data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9fa9cf-ee8f-4e5b-b287-d707de00dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = \"LIHC\"\n",
    "outpath = datasets[selected_data][\"outpath\"]\n",
    "outname = outpath.name\n",
    "outpath, outname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbd4af2-f0d5-4a7b-922c-e8b0f1255529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ubelix import run_multi_batch\n",
    "\n",
    "script_path = Path(\"../scripts/send_batch.sh\")\n",
    "DEA_methods = [\"edgerqlf\"]#,\"edgerlrt\", \"deseq2\"] # finish edgerqlf jobs before sending other jobs\n",
    "outlier_methods = [\"none\"]#, \"pcah\", \"jk\"] # only use none for p2 and p3\n",
    "all_N = [3,7,15]#,4,5,6,7,8,9,10,12,15]\n",
    "n_cohorts = 100\n",
    "\n",
    "assert outname in str(outpath)\n",
    "\n",
    "config_params_1 = {\n",
    "    \n",
    "    \"param_set\": \"p1\", # id for this set of parameters\n",
    "    \n",
    "    \"overwrite\": False, # overwrite existing tabs\n",
    "    \"data\": str(outpath) + \"/\" + outname + \".csv\",\n",
    "    \"outpath\": str(outpath),\n",
    "    \"outname\": outname,\n",
    "    \n",
    "    \"DEA_methods\": DEA_methods,\n",
    "    \"outlier_methods\": outlier_methods,\n",
    "    \n",
    "    \"outlier_kwargs\": {\n",
    "        \"none\": {},\n",
    "        \"jk\": {\n",
    "            \"FDR\": 0.01,\n",
    "            \"overwrite\": False, # overwrite existing jk tab\n",
    "            \"max_removed_frac\": 0.5, # fraction of patients; after 1st iteration, don't jackknife bottom frac patients\n",
    "            \"efficient\": True,\n",
    "            \"cols_to_keep\": [\"FDR\"],\n",
    "            \"cleanup\": True # remove individual jk tabs and iterations after merger\n",
    "        },\n",
    "        \"pcah\": {\"k\": 2}\n",
    "    },\n",
    "    \n",
    "    \"DEA_kwargs\": {\n",
    "        \"edgerqlf\": {\"filter_expr\": False, \"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"], \"design\": \"paired\"},\n",
    "        \"edgerlrt\": {\"filter_expr\": False, \"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"], \"test\":\"lrt\", \"design\": \"paired\"},\n",
    "        \"deseq2\": {\"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"], \"design\": \"paired\"}\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "# lfc = 1 threshold\n",
    "config_params_2 = {\n",
    "    \n",
    "    \"param_set\": \"p2\", # id for this set of parameters\n",
    "    \n",
    "    \"overwrite\": False, # overwrite existing tabs\n",
    "    \"data\": str(outpath) + \"/\" + outname + \".csv\",\n",
    "    \"outpath\": str(outpath),\n",
    "    \"outname\": outname,\n",
    "    \n",
    "    \"DEA_methods\": DEA_methods,\n",
    "    \"outlier_methods\": outlier_methods,\n",
    "    \n",
    "    \"outlier_kwargs\": {\n",
    "        \"none\": {},\n",
    "        \"jk\": {\n",
    "            \"FDR\": 0.01,\n",
    "            \"overwrite\": False, # overwrite existing jk tab\n",
    "            \"max_removed_frac\": 0.5, # fraction of patients; after 1st iteration, don't jackknife bottom frac patients\n",
    "            \"efficient\": True,\n",
    "            \"cols_to_keep\": [\"FDR\"],\n",
    "            \"cleanup\": True # remove individual jk tabs and iterations after merger\n",
    "        },\n",
    "        \"pcah\": {\"k\": 2}\n",
    "    },\n",
    "    \n",
    "    \"DEA_kwargs\": {\n",
    "        \"edgerqlf\": {\"filter_expr\": False, \"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"], \"lfc\": 1, \"design\": \"paired\"},\n",
    "        \"edgerlrt\": {\"filter_expr\": False, \"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"], \"test\":\"lrt\", \"lfc\": 1, \"design\": \"paired\"},\n",
    "        \"deseq2\": {\"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"],\"lfc\": 1, \"design\": \"paired\"}\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "# lfc = 1 threshold, unpaired\n",
    "config_params_3 = {\n",
    "    \n",
    "    \"param_set\": \"p3\", # id for this set of parameters\n",
    "    \n",
    "    \"overwrite\": False, # overwrite existing tabs\n",
    "    \"data\": str(outpath) + \"/\" + outname + \".csv\",\n",
    "    \"outpath\": str(outpath),\n",
    "    \"outname\": outname,\n",
    "    \n",
    "    \"DEA_methods\": DEA_methods,\n",
    "    \"outlier_methods\": outlier_methods,\n",
    "    \n",
    "    \"outlier_kwargs\": {\n",
    "        \"none\": {},\n",
    "        \"jk\": {},\n",
    "        \"pcah\": {}\n",
    "    },\n",
    "    \n",
    "    \"DEA_kwargs\": {\n",
    "        \"edgerqlf\": {\"filter_expr\": False, \"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"], \"lfc\": 1, \"design\": \"unpaired\"},\n",
    "        \"edgerlrt\": {\"filter_expr\": False, \"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"], \"test\":\"lrt\", \"lfc\": 1, \"design\": \"unpaired\"},\n",
    "        \"deseq2\": {\"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"],\"lfc\": 1, \"design\": \"unpaired\"}\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "import subprocess as sp\n",
    "output = sp.getoutput('squeue -u pd21v747')\n",
    "jobs_running = output.find(\"send_bat\") > 0\n",
    "\n",
    "# mode = \"send jobs\" # does not work in newer version of slurm\n",
    "# https://harvardmed.atlassian.net/wiki/spaces/O2/pages/1586793613/Troubleshooting+Slurm+Jobs#Jobs-fail-with-the-message%3A-Unable-to-satisfy-CPU-bind-request\n",
    "# workaround: use mode=just testing, copy the command and send job from terminal in submit node; wd must be notebooks folder, must load environment beforehand\n",
    "\n",
    "#mode = \"test main terminal\"\n",
    "mode = \"just testing\"\n",
    "\n",
    "do_nothing = False\n",
    "config_params = config_params_3\n",
    "\n",
    "if not jobs_running and not do_nothing:\n",
    "    run_multi_batch(config_params, all_N, n_cohorts, script_path, mode = mode)\n",
    "elif jobs_running:\n",
    "    print(\"Jobs running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18caec7-0af6-4022-80c8-b2d03ce198de",
   "metadata": {},
   "outputs": [],
   "source": [
    "!squeue -u pd21v747"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9452b65b-ce89-4a2e-89bf-7a6a4000f5bb",
   "metadata": {},
   "source": [
    "## Process jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9b36f1-7d5d-4fe7-a047-8e006c6cfd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEAs = [\"edgerqlf\"]#, \"edgerlrt\", \"deseq2\"]\n",
    "outlier_methods = [\"none\", \"pcah\", \"jk\"]\n",
    "FDRs = [0.1,0.05,0.01,0.001]\n",
    "logFCs = [0, 0.5, 1, 1.5, 2]\n",
    "all_N = [3]#,4,5,6,7,8,9,10,12,15]\n",
    "lfc_test = 0\n",
    "param_set = \"p1\"\n",
    "\n",
    "# DEAs = [\"edgerqlf\"]#\"deseq2\", \"edgerlrt\"]\n",
    "# outlier_methods = [\"none\"]#, \"pcah\", \"jk\"]\n",
    "# FDRs = [0.1,0.05,0.01,0.001]\n",
    "# logFCs = [1]\n",
    "# all_N = [3]#,4,5,6,7,8,9,10,12,15]\n",
    "# lfc_test = 1\n",
    "# param_set = \"p2\"\n",
    "\n",
    "DEAs = [\"edgerqlf\"]#, \"edgerlrt\", \"deseq2\"]\n",
    "outlier_methods = [\"none\"]\n",
    "FDRs = [0.05] #[0.1,0.05,0.01,0.001]\n",
    "logFCs = [1]\n",
    "all_N = [3,7,15]\n",
    "lfc_test = 1\n",
    "param_set = \"p3\"\n",
    "\n",
    "param_sets = [\"p1\",\"p2\",\"p3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52512662-3f83-4dca-b5f9-faac1df7d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from process import process_pipeline\n",
    "from misc import profile_func\n",
    "import pstats\n",
    "\n",
    "kwargs = {\"outpath\":outpath, \"outname\":outname, \"all_N\": all_N, \"DEAs\":DEAs, \"outlier_methods\": outlier_methods, \n",
    "          \"FDRs\":FDRs, \"logFCs\":logFCs, \"lfc_test\": lfc_test, \"param_set\":param_set, \"overwrite\": 1, \"overwrite_merged\": 1, \"n_cohorts\": 10}\n",
    "\n",
    "do_process = True\n",
    "if do_process:\n",
    "    prof = profile_func(process_pipeline, kwargs)\n",
    "    stats = pstats.Stats(prof).strip_dirs().sort_stats(\"cumtime\")\n",
    "    stats.print_stats(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d348c626-a45b-456a-b227-09539090c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc import open_table\n",
    "site = \"liver\"\n",
    "f=f\"../data/{site}/{sites[site]}/{sites[site]}_N3/all.logFC.none.edgerqlf.p2.feather\"\n",
    "tab = open_table(f)\n",
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f35b6e-a705-41a1-8462-99f6f3d2556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Multi process\n",
    "# import process, sys, importlib\n",
    "# importlib.reload(sys.modules[\"process\"])\n",
    "\n",
    "# from process import process_pipeline\n",
    "\n",
    "# for data in datasets:\n",
    "#     #if data == \"PRAD\": continue\n",
    "#     print(data)\n",
    "    \n",
    "#     outpath = datasets[data][\"outpath\"]\n",
    "#     outname = outpath.split(\"/\")[-1]\n",
    "#     kwargs = {\"outpath\":outpath, \"outname\":outname, \"all_N\": all_N, \"DEAs\":DEAs, \"outlier_methods\": outlier_methods, \n",
    "#               \"FDRs\":FDRs, \"logFCs\":logFCs, \"lfc_test\": lfc_test, \"param_set\":param_set, \"overwrite\": 0, \"overwrite_merged\": 0, \"n_cohorts\": 100}\n",
    "#     process_pipeline(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b374aeae-9288-4cd5-8d86-b6fdb3c5e6a2",
   "metadata": {},
   "source": [
    "### Merge processed data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf41be7c-cda5-42d1-8cbb-a571aa318963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(path, site, name, param_set):\n",
    "    resultsfile = f\"{path}/{site}/{name}/results.{param_set}.txt\"\n",
    "    with open(resultsfile, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "for s in sites:\n",
    "    \n",
    "    #if s not in [\"colorectal\",\"prostate\",\"breast\",\"thyroid\",\"liver\"]: continue\n",
    "\n",
    "    for ps in param_sets:\n",
    "        res = load_results(datapath, s, sites[s], ps)\n",
    "        if ps not in datasets[sites[s]]:\n",
    "            datasets[sites[s]][ps] = {}\n",
    "        for key in res.keys():\n",
    "            datasets[sites[s]][ps][key] = res[key]\n",
    "\n",
    "assert \"truth_stats\" in datasets[list(datasets.keys())[0]] # don't forget to load ground truth\n",
    "datasetsfile = Path(datapath, \"multi/datasets.txt\")\n",
    "pickler(datasets, datasetsfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879ba2b4-9da4-4e72-a2d5-d4e1849d6008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tidy dataframe\n",
    "\n",
    "def tidy_df(param_set,logFCs):\n",
    "    quantity = [\"median_rep\", \"median_deg\", \"median_rep_adj\", \"median_deg_adj\",\n",
    "                \"median_mcc\", \"median_prec\", \"median_rec\", \"median_mcc_adj\", \"median_prec_adj\", \"median_rec_adj\"]\n",
    "    iterables = [datasets,all_N,outlier_methods,DEAs,FDRs,logFCs,quantity]\n",
    "    multi_cols = pd.MultiIndex.from_product(iterables, names=[\"Data\", \"N\", \"Out\", \"DEA\", \"FDR\", \"logFC\", \"Val\"])\n",
    "    combined = pd.DataFrame(columns=multi_cols)\n",
    "\n",
    "    ids = [] # id connecting samples from same dataset and cohort size, used for paired-sample testing pre vs. post outlier removal\n",
    "    for i, d in enumerate(datasets):\n",
    "        #if d not in [\"COAD\",\"PRAD\",\"BRCA\",\"THCA\",\"LIHC\"]: continue\n",
    "        for j, N in enumerate(all_N):\n",
    "            k = i*len(all_N)+j \n",
    "            for out in outlier_methods:\n",
    "                for dea in DEAs:\n",
    "                    for fdr in FDRs:\n",
    "                        for logFC in logFCs:\n",
    "                            for quant in quantity:\n",
    "                                #print(d,N,param_set,out,dea,quant,fdr,logFC,datasets[d][param_set][N][out][dea][quant][fdr][logFC])\n",
    "                                col = (d,N,out,dea,fdr,logFC,quant)\n",
    "                                try:\n",
    "                                    combined.loc[0,col] = datasets[d][param_set][N][out][dea][quant][fdr][logFC]\n",
    "                                except KeyError:\n",
    "                                    if \"syn_hom\" in d and out != \"None\": pass\n",
    "                                    else: raise Exception(\"KeyError\")\n",
    "                                if quant == \"median_rep\": ids.append(k)\n",
    "\n",
    "    combined_td = combined.unstack().unstack(level=\"Val\").reset_index(level=[\"Data\",\"N\",\"Out\",\"DEA\",\"FDR\",\"logFC\"], drop=False)\n",
    "    combined_td[\"id\"] = ids\n",
    "    combined_td.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # For outlier_method == \"none\", no adjustment is necessary, hence copy unadjusted values\n",
    "    none_ix = combined_td[combined_td[\"Out\"] == \"none\"].index # avoid setting with copy warning\n",
    "    combined_td.loc[none_ix,\"median_deg_adj\"] = combined_td.loc[none_ix,\"median_deg\"]\n",
    "    combined_td.loc[none_ix,\"median_rep_adj\"] = combined_td.loc[none_ix,\"median_rep\"]\n",
    "    combined_td.loc[none_ix,\"median_mcc_adj\"] = combined_td.loc[none_ix,\"median_mcc\"]\n",
    "    combined_td.loc[none_ix,\"median_prec_adj\"] = combined_td.loc[none_ix,\"median_prec\"]\n",
    "    combined_td.loc[none_ix,\"median_rec_adj\"] = combined_td.loc[none_ix,\"median_rec\"]\n",
    "\n",
    "\n",
    "    for clean in cleanout:\n",
    "        combined_td.loc[(combined_td[combined_td[\"Out\"] == clean]).index, \"Out\"] = cleanout[clean]\n",
    "    for clean in cleandea:\n",
    "        combined_td.loc[(combined_td[combined_td[\"DEA\"] == clean]).index, \"DEA\"] = cleandea[clean]\n",
    "    combined_td.to_csv(Path(datapath, f\"multi/combined_td.{param_set}.csv\"))\n",
    "    return combined_td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a7e256-7739-4de2-a0d4-0ac9c3805011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier_methods = [\"none\",\"jk\",\"pcah\"]\n",
    "# combined_td = tidy_df(\"p1\",[0,1])\n",
    "# outlier_methods = [\"none\"]\n",
    "# combined_td2 = tidy_df(\"p2\",[1])\n",
    "# combined_td.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cb0e55-27a5-4ea7-ac78-3d8f365985c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_td3 = tidy_df(\"p3\",[1])\n",
    "combined_td3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480dd957-2f60-40ef-9993-1e15bff03d17",
   "metadata": {},
   "source": [
    "## Inspect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba7373-d457-469d-aaa0-ee4bf5f917ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc import get_grid_size\n",
    "\n",
    "x = \"median_deg\"\n",
    "y = \"median_rep\"\n",
    "\n",
    "a  = combined_td3[combined_td3[\"logFC\"]==1]\n",
    "a = a[a[\"DEA\"]==\"edgerqlf\"]\n",
    "hues = [\"Data\",\"logFC\",\"DEA\",\"Out\",\"N\",\"FDR\"]\n",
    "grid = get_grid_size(len(hues), k=0, fill=True)\n",
    "fig, ax = plt.subplots(grid[0],grid[1],figsize=(6*grid[0],3*grid[1]), sharex=True,sharey=True)\n",
    "ax=ax.flatten()\n",
    "cube = sns.cubehelix_palette(as_cmap=False, n_colors=5)\n",
    "\n",
    "for i, hue in enumerate(hues):\n",
    "    sns.scatterplot(data=a, x=x, y=y, hue=hue, ax=ax[i])\n",
    "for axx in ax: axx.invert_yaxis()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcb59eb-60cb-4f66-a713-690d6f901bdd",
   "metadata": {},
   "source": [
    "# Enrichment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a144b136-7267-4925-a0ff-fc5162605f8a",
   "metadata": {},
   "source": [
    "## Ground truth definition\n",
    "\n",
    "Run GSEA on ground truth logFC estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99e6a7d-12fd-4833-8568-a19367cb53c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enrichment import prepare_gsea, run_gseapy_libraries, convert_ids_biomart, find_conv_table_all, clean_tab\n",
    "\n",
    "libraries = [\n",
    "  \"GO_Biological_Process_2021\",\n",
    "  \"KEGG_2021_Human\"\n",
    "  # \"MSigDB_Oncogenic_Signatures\",\n",
    "  # \"Cancer_Cell_Line_Encyclopedia\",\n",
    "  # \"GO_Molecular_Function_2021\",\n",
    "  # \"GeneSigDB\",\n",
    "  # \"GO_Cellular_Component_2021\",\n",
    "  # \"MSigDB_Hallmark_2020\",\n",
    "  # \"MSigDB_Computational\",\n",
    "  # \"WikiPathway_2021_Human\"\n",
    "]\n",
    "\n",
    "datasetsfile = Path(datapath, \"multi/datasets.txt\")\n",
    "with open(datasetsfile, \"rb\") as f:\n",
    "    datasets = pickle.load(f)\n",
    "    \n",
    "if \"KIRC_syn_hom\" in datasets:\n",
    "    del datasets[\"KIRC_syn_hom\"]\n",
    "\n",
    "# Create table for converting ENSG to Gene Symbols and Entrez IDs\n",
    "conv_file = Path(datapath, \"multi/conv_table.csv\")\n",
    "find_conv_table_all(datasets, conv_file, overwrite=False)\n",
    "conv_table = pd.read_csv(conv_file, index_col=0)\n",
    "conv_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d33dec-e7f3-4d8c-97c8-4fe3a6a95d92",
   "metadata": {},
   "source": [
    "### GSEApy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2faeeeb-98fa-4024-a428-1d29f558a01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enrichment import prepare_gsea, run_gseapy_libraries, convert_ids_biomart, find_conv_table_all, clean_tab\n",
    "from process import signal_to_noise\n",
    "from DEA import normalize_counts\n",
    "            \n",
    "overwrite_all_gsea = True\n",
    "\n",
    "for k, data in enumerate(datasets):\n",
    "    \n",
    "    outpath = datasets[data][\"outpath\"]\n",
    "    gseapath = f\"{outpath}/gsea\"   \n",
    "    \n",
    "    if not overwrite_all_gsea: continue\n",
    "\n",
    "    #os.system(f\"mkdir {gseapath}\")\n",
    "    tab = pd.read_csv(f\"{outpath}/truth_lfc.csv\", index_col=0)\n",
    "\n",
    "    counts = pd.read_csv(datasets[data][\"datapath\"], index_col=0)\n",
    "    counts = normalize_counts(counts)\n",
    "    tab.loc[counts.index.intersection(tab.index), \"|S2N|\"] = signal_to_noise(counts)\n",
    "\n",
    "    tab_cleaned = tab.loc[tab.index.intersection(conv_table.index)]\n",
    "    tab_cleaned[\"Symbol\"] = conv_table.loc[tab_cleaned.index,\"Symbol\"]\n",
    "    logging.info(f\"{data}\\nOriginal tab: {len(tab)} genes\\nCleaned tab: {len(tab_cleaned)} genes\\n\")\n",
    "    \n",
    "    with Timer(name=\"context manager\"):\n",
    "        run_gseapy_libraries(tab_cleaned, gseapath, libraries, overwrite_all_gsea, permutation_num=1000, save_full_results=True,\n",
    "                        ranking=\"logFC\", min_size=15, max_size=500)\n",
    "        run_gseapy_libraries(tab_cleaned, gseapath, libraries, overwrite_all_gsea, permutation_num=1000, save_full_results=True,\n",
    "                            ranking=\"|S2N|\", min_size=15, max_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1f340a-b9ff-4f2c-be32-435b2592b6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect results\n",
    "\n",
    "gsea_out = f\"{gseapath}/gseapy.{libraries[1]}.txt\"\n",
    "with open(gsea_out, \"rb\") as fp:\n",
    "    gsea_results = pickle.load(fp)\n",
    "    \n",
    "print(gsea_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8f3767-d1a5-48f5-93f2-3a9e13d21bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gseapy\n",
    "\n",
    "terms = gsea_results.res2d.sort_values(by=\"FDR q-val\")\n",
    "display(gsea_results.res2d.head(10))\n",
    "top_term = terms[\"Term\"][0]\n",
    "print(f\"Total gene sets tested: {len(terms)}\")\n",
    "print(f\"Significant gene sets at 5% FDR: {len(terms[terms['FDR q-val']<0.05])}\\n\")\n",
    "gseapy.gseaplot(rank_metric=gsea_results.ranking, term=top_term, **gsea_results.results[top_term])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36953680-c75a-44e0-842b-a47a7e2decae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make results dictionary\n",
    "\n",
    "FDR = 0.05\n",
    "rankings = [\"logFC\", \"|S2N|\"]\n",
    "gsea_dict = {data: {\"truth\": {\"gseapy\": {rnk: {lib: {} for lib in libraries} for rnk in rankings}}} for data in datasets}\n",
    "\n",
    "for data in datasets:\n",
    "    \n",
    "    outpath = datasets[data][\"outpath\"]\n",
    "    gseapath = f\"{outpath}/gsea\"\n",
    "    \n",
    "    for rnk in rankings:\n",
    "    \n",
    "        for library in libraries:\n",
    "\n",
    "            suffix = \"\" if rnk == \"logFC\" else \"_s2n\"\n",
    "            reportfile = f\"{gseapath}/gseapy{suffix}.{library}.feather\"\n",
    "            terms = open_table(reportfile).sort_values(by=\"FDR\")\n",
    "            gsea_dict[data][\"truth\"][\"gseapy\"][rnk][library] = terms\n",
    "            print(data, library, rnk, len(terms), len(terms[terms['FDR']<FDR]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854a4297-ae85-40f0-9009-178cc63c6804",
   "metadata": {},
   "source": [
    "### clusterProfiler ORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fe3328-cb7d-4923-bea0-f940961f8e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enrichment import run_clusterORA, convert_ensg\n",
    "\n",
    "overwrite_clusterORA = False\n",
    "FDRs = [0.05]\n",
    "logFCs = [0,1] # formal lfc threshold\n",
    "\n",
    "ORA_kwargs = {\"FDRs\": [0.05], \"logFCs\": [0,1], \"minGSSize\": 15, \"maxGSSize\": 500,\n",
    "               \"use_internal_data\": True, \"internal_data_path\": \"../data/clusterORA/KEGG_DATA.RData\"}\n",
    "\n",
    "for k, data in enumerate(datasets):\n",
    "    print(data)\n",
    "    \n",
    "    outpath = datasets[data][\"outpath\"]\n",
    "    gseapath = f\"{outpath}/gsea\"\n",
    "    #os.system(f\"mkdir {gseapath}\")\n",
    "    universe = pd.read_csv(f\"{outpath}/{data}.csv\", usecols=[\"Unnamed: 0\"], index_col=0)\n",
    "    universe = list(convert_ensg(universe,conv_table,target=\"Entrez\").index)\n",
    "\n",
    "    for fdr in FDRs:\n",
    "        for logFC in logFCs:\n",
    "            degs = pd.read_csv(f\"{outpath}/truth.fdr{fdr}.post_lfc{logFC}.lfc{logFC}.csv\", usecols=[\"Unnamed: 0\"], index_col=0)\n",
    "            degs = list(convert_ensg(degs,conv_table,target=\"Entrez\").index)\n",
    "    \n",
    "            s = \"_lfc\" if logFC > 0 else \"\"\n",
    "            prefix = f\"{gseapath}/clusterORA{s}.fdr{fdr}.post_lfc{logFC}.lfc{logFC}\"\n",
    "            run_clusterORA(degs, universe, file_id=\"\", go_ont=\"BP\", prefix=prefix, overwrite=overwrite_clusterORA, **ORA_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe458879-8df2-4943-8399-ca7e2615afe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in datasets:\n",
    "    \n",
    "    outpath = datasets[data][\"outpath\"]\n",
    "    gseapath = f\"{outpath}/gsea\"\n",
    "        \n",
    "    for fdr in FDRs:\n",
    "        for logFC in logFCs:\n",
    "            \n",
    "            s = \"_lfc\" if logFC > 0 else \"\"\n",
    "            method = f\"clusterORA{s}.fdr{fdr}.post_lfc{logFC}.lfc{logFC}\"\n",
    "            gsea_dict[data][\"truth\"][method] = {lib: None for lib in libraries}\n",
    "            \n",
    "            for library in libraries:\n",
    "                #if \"KEGG\" not in library: continue\n",
    "                    \n",
    "                reportfile = f\"{gseapath}/{method}.{library}.feather\"         \n",
    "                terms = open_table(reportfile).sort_values(by=\"FDR\")\n",
    "                \n",
    "                ## for KEGG: switch term ID and description for index\n",
    "                if terms.index[0].startswith(\"hsa\") and \"Term\" in terms:\n",
    "                    terms[\"Term ID\"] = terms.index\n",
    "                    terms = terms.set_index(\"Term\")\n",
    "                \n",
    "                gsea_dict[data][\"truth\"][method][library] = terms\n",
    "                print(data, method, library, len(terms), len(terms[terms['FDR']<FDR]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafb40bf-9937-46cc-a836-9a7dcc2d565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For KEGG ORA,set term name as index instead of term ID\n",
    "\n",
    "for site in sites:\n",
    "    for fdr in FDRs:\n",
    "        for lfc in logFCs:\n",
    "            s = \"_lfc\" if lfc > 0 else \"\"\n",
    "            method = f\"clusterORA{s}.fdr{fdr}.post_lfc{lfc}.lfc{lfc}\"\n",
    "            f = f\"../data/{site}/{sites[site]}/gsea/{method}.KEGG_2021_Human.feather\"\n",
    "            t=open_table(f)\n",
    "            if \"Term ID\" in t or t.index.name == \"Term\": continue\n",
    "            t[\"Term ID\"] = t.index\n",
    "            t.set_index(\"Term\",inplace=True)\n",
    "            t = t.reset_index()\n",
    "            t.to_feather(f)\n",
    "            display(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29ac9ea-b871-4623-b775-90b18c96f5a4",
   "metadata": {},
   "source": [
    "### Common terms\n",
    "\n",
    "We will define an additional, common ground truth, restricted to terms to terms that are shared between GSEApy, clusterProfiler ORA and all data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a5d6e2-4829-4938-a411-f527d5d1c5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_terms():\n",
    "    common_kegg, common_gobp = set(), set()\n",
    "    for data in gsea_dict:\n",
    "        for lfc in [0,1]:\n",
    "            s = \"_lfc\" if lfc == 1 else \"\"\n",
    "            # KEGG\n",
    "            gseapy_terms = gsea_dict[data][\"truth\"][\"gseapy\"][\"logFC\"][\"KEGG_2021_Human\"].index\n",
    "            clusterORA_terms = set(gsea_dict[data][\"truth\"][f\"clusterORA{s}.fdr0.05.post_lfc{lfc}.lfc{lfc}\"][\"KEGG_2021_Human\"].index)\n",
    "\n",
    "            if len(common_kegg)<1: common_kegg = gseapy_terms.intersection(clusterORA_terms)\n",
    "            else: common_kegg = common_kegg.intersection(gseapy_terms).intersection(clusterORA_terms)\n",
    "\n",
    "            # GO BP\n",
    "            gseapy_terms = gsea_dict[data][\"truth\"][\"gseapy\"][\"logFC\"][\"GO_Biological_Process_2021\"].index\n",
    "            clusterORA_terms = gsea_dict[data][\"truth\"][f\"clusterORA{s}.fdr0.05.post_lfc{lfc}.lfc{lfc}\"][\"GO_Biological_Process_2021\"].index    \n",
    "\n",
    "            if len(common_gobp)<1: common_gobp = gseapy_terms.intersection(clusterORA_terms)\n",
    "            else: common_gobp = common_gobp.intersection(gseapy_terms).intersection(clusterORA_terms)\n",
    "\n",
    "    return common_kegg, common_gobp\n",
    "    \n",
    "file_gobp = Path(\"../data/multi/common_gobp.txt\")\n",
    "file_kegg = Path(\"../data/multi/common_kegg.txt\")\n",
    "if (not file_gobp.is_file() or not file_kegg.is_file()):\n",
    "    common_kegg, common_gobp = get_common_terms()\n",
    "    pickler(common_gobp, file_gobp)\n",
    "    pickler(common_kegg, file_kegg)\n",
    "else:\n",
    "    with open(file_gobp, \"rb\") as f:\n",
    "        common_gobp = pickle.load(f)\n",
    "    with open(file_kegg, \"rb\") as f:\n",
    "        common_kegg = pickle.load(f)\n",
    "        \n",
    "print(\"KEGG Terms:\", len(common_kegg))\n",
    "print(\"GO BP Terms:\", len(common_gobp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba96f9dc-ed8d-484f-affb-4f332165e117",
   "metadata": {},
   "source": [
    "As we have restricted the number of terms (hypotheses), we need to recalculate the adjusted pvalues for appropriate FDR control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afbd45c-c38c-4f7c-adbe-6dfcab90f493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "redo_common_fdr = True\n",
    "FDRs = [0.05]\n",
    "logFCs = [0,1]\n",
    "rankings = [\"logFC\", \"|S2N|\"]\n",
    "\n",
    "if redo_common_fdr:\n",
    "\n",
    "    for data in datasets:\n",
    "\n",
    "        outpath = datasets[data][\"outpath\"]\n",
    "        gseapath = f\"{outpath}/gsea\"\n",
    "        \n",
    "        for library in libraries:\n",
    "            \n",
    "            common = common_gobp if library == \"GO_Biological_Process_2021\" else common_kegg\n",
    "    \n",
    "            ### GSEA\n",
    "            for rnk in rankings:\n",
    "                suffix = \"\" if rnk == \"logFC\" else \"_s2n\"\n",
    "                reportfile = f\"{gseapath}/gseapy{suffix}.{library}.feather\"\n",
    "                terms = open_table(reportfile).sort_values(by=\"FDR\")\n",
    "                terms[\"FDR.common\"] = np.full(len(terms),np.nan)\n",
    "                terms.loc[common, \"FDR.common\"] = multipletests(terms.loc[common, \"NOM p-val\"], method=\"fdr_bh\")[1]\n",
    "                terms.reset_index().to_feather(reportfile)\n",
    "\n",
    "\n",
    "            ### ORA\n",
    "            for fdr in FDRs:\n",
    "                for logFC in logFCs:\n",
    "                    s = \"_lfc\" if logFC > 0 else \"\"\n",
    "                    method = f\"clusterORA{s}.fdr{fdr}.post_lfc{logFC}.lfc{logFC}\"\n",
    "\n",
    "                    reportfile = f\"{gseapath}/{method}.{library}.feather\"         \n",
    "                    terms = open_table(reportfile).sort_values(by=\"FDR\")\n",
    "                    #assert terms.index.duplicated().sum() == 0\n",
    "                    terms[\"FDR.common\"] = np.full(len(terms),np.nan)\n",
    "                    \n",
    "                    if terms.index[0].startswith(\"hsa\"):\n",
    "                        terms[\"hsa\"] = terms.index\n",
    "                        terms.set_index(\"Term\", inplace=True)\n",
    "                    \n",
    "                    ix = common #if library == \"GO_Biological_Process_2021\" else terms[terms[\"Term\"].isin(common)].index\n",
    "                    print(data,library,fdr,logFC,method)\n",
    "                    terms.loc[ix, \"FDR.common\"] = multipletests(terms.loc[ix, \"pvalue\"], method=\"fdr_bh\")[1]\n",
    "                    terms.reset_index().to_feather(reportfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b738f-1675-46ee-8629-5336a7e0e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsea_methods = ['gseapy', 'gseapy_s2n',\n",
    "               'clusterORA.fdr0.05.post_lfc0.lfc0',\n",
    "               'clusterORA_lfc.fdr0.05.post_lfc1.lfc1']\n",
    "\n",
    "\n",
    "from process import get_n_gsea_truth\n",
    "FDRs=[0.05]\n",
    "gsea_param_set = \"p1\"\n",
    "gsea_truth = {data: {out: {dea: {gsea: {lib: {\"truth\"+mode: {fdr: None for fdr in FDRs} for mode in [\"\",\"_common\"]} for lib in libraries} for gsea in gsea_methods} for dea in DEA_methods} for out in outlier_methods} for data in datasets if \"syn\" not in data}\n",
    "\n",
    "for data in datasets:\n",
    "    print(data)\n",
    "    outpath_d = datasets[data][\"outpath\"]\n",
    "    outname_d = str(outpath_d).split(\"/\")[-1]\n",
    "    gsea_truth[data] = get_n_gsea_truth(gsea_truth[data], outpath_d, outname_d, all_N, DEA_methods, outlier_methods, gsea_methods, libraries, FDRs, gsea_param_set, overwrite=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2063bb1e-858d-4193-8cc6-4499f2c6f3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsea_datasets = {sites[s]: {} for s in sites}\n",
    "\n",
    "DEAs = DEA_methods\n",
    "FDRs = [0.05]\n",
    "all_N=[3]#,5,7,9,15]\n",
    "    \n",
    "quantity = [\"truth\"]\n",
    "quantity += [q+\"_common\" for q in quantity]\n",
    "\n",
    "iterables = [gsea_datasets,outlier_methods,DEAs,gsea_methods,libraries,FDRs,quantity]\n",
    "multi_cols = pd.MultiIndex.from_product(iterables, names=[\"Data\", \"Out\", \"DEA\", \"Enrichment\", \"Library\", \"FDR\", \"Val\"])\n",
    "gsea_truth_df = pd.DataFrame(columns=multi_cols)\n",
    "\n",
    "ids = [] # id connecting samples from same dataset and cohort size, used for paired-sample testing pre vs. post outlier removal\n",
    "for d in gsea_datasets:\n",
    "    for out in outlier_methods:\n",
    "        for dea in DEAs:\n",
    "            for gsea in gsea_methods:\n",
    "                #if dea != \"edger\" and gsea_methods == \"gsea_s2n\": continue\n",
    "                for fdr in FDRs:\n",
    "                    for lib in libraries:\n",
    "                        for quant in quantity:\n",
    "                            #print(d,N,out,dea,fdr)\n",
    "                            col = (d,out,dea,gsea,lib,fdr,quant)\n",
    "                            if dea != \"edgerqlf\" and \"s2n\" in gsea: dea_source = \"edgerqlf\"\n",
    "                            else: dea_source = dea\n",
    "                            gsea_truth_df.loc[0,col] = gsea_truth[d][out][dea_source][gsea][lib][quant][fdr]\n",
    "                            \n",
    "gsea_truth_df = gsea_truth_df.unstack().unstack(level=\"Val\").reset_index(level=[\"Data\",\"Out\",\"DEA\",\"Enrichment\",\"Library\",\"FDR\"], drop=False)\n",
    "gsea_truth_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# For outlier_method == \"none\", no adjustment is necessary, hence copy unadjusted values\n",
    "#none_ix = combined_gsea_td[combined_gsea_td[\"Out\"] == \"none\"].index # avoid setting with copy warning\n",
    "#combined_gsea_td.loc[none_ix,\"median_terms_adj\"] = combined_gsea_td.loc[none_ix,\"median_terms\"]\n",
    "#combined_gsea_td.loc[none_ix,\"median_rep_adj\"] = combined_gsea_td.loc[none_ix,\"median_rep\"]\n",
    "\n",
    "for clean in cleanout:\n",
    "    gsea_truth_df.loc[(gsea_truth_df[gsea_truth_df[\"Out\"] == clean]).index, \"Out\"] = cleanout[clean]\n",
    "for clean in cleandea:\n",
    "    gsea_truth_df.loc[(gsea_truth_df[gsea_truth_df[\"DEA\"] == clean]).index, \"DEA\"] = cleandea[clean]\n",
    "gsea_truth_df.to_csv(f\"../data/multi/gsea_truth_df.csv\")\n",
    "gsea_truth_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a35d57-76e3-4e07-b1ec-18959c8681a6",
   "metadata": {},
   "source": [
    "## Send batch jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f45a598-9b8b-4c71-88c0-a02200243637",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = \"LIHC\"\n",
    "outpath = datasets[selected_data][\"outpath\"]\n",
    "outname = outpath.name\n",
    "outpath, outname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed3f8dc-da22-45f1-89f2-1ce6993427a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ubelix import run_gsea_batch\n",
    "    \n",
    "gsea_script_path = \"../scripts/send_gsea_batch.sh\"\n",
    "\n",
    "n_cohorts = 2\n",
    "all_N = [3]#,5,5,7,9,15]\n",
    "gsea_methods = [\"clusterORA_lfc\",\"clusterORA\",\"gseapy\"] #\"gseapy_s2n\"\n",
    "outlier_methods = [\"none\"]#,\"jk\"] #########,\"pcah\"]\n",
    "DEA_methods = [\"edgerqlf\"]#[\"deseq2\",\"edgerlrt\"] ## reminder: do only edgerqlf for gsea S2N\n",
    "libraries = ['GO_Biological_Process_2021', 'KEGG_2021_Human']\n",
    "\n",
    "gsea_config_params = {\n",
    "    \n",
    "    \"gsea_param_set\": \"p1\", # id for this set of parameters\n",
    "    \"dea_param_set\": \"p1\",\n",
    "    \"dea_param_set_lfc\": \"p2\",\n",
    "    \n",
    "    \"overwrite\": False, # overwrite existing tabs\n",
    "    \"data\": str(outpath) + \"/\" + outname + \".csv\",\n",
    "    \"outpath\": str(outpath),\n",
    "    \"outname\": outname,\n",
    "    \n",
    "    \"DEA_methods\": DEA_methods,\n",
    "    \"outlier_methods\": outlier_methods,\n",
    "    \"gsea_methods\": gsea_methods,\n",
    "    \"libraries\": libraries,\n",
    "    \n",
    "    \"gsea_kwargs\":  {\n",
    "                    \"gseapy_s2n\": {\"permutation_num\": 200, \"save_full_results\": False, \"threads\": 4, \"ranking\":\"|S2N|\", \"min_size\": 15, \"max_size\": 500},\n",
    "                    \"gseapy\": {\"permutation_num\": 200, \"save_full_results\": False, \"threads\": 4, \"ranking\":\"logFC\", \"min_size\": 15, \"max_size\": 500},\n",
    "                    \"clusterORA\": {\"FDRs\": [0.05], \"logFCs\": [0], \"go_ont\": \"BP\", \"ranking\":\"n/a\", \"minGSSize\": 15, \"maxGSSize\": 500, # KIRC/COAD use minGSSize 10, no problem since we use intersection with GSEA terms afterwards\n",
    "                                   \"use_internal_data\": True, \"internal_data_path\": \"../data/clusterORA/KEGG_DATA.RData\"},\n",
    "                    \"clusterORA_lfc\": {\"FDRs\": [0.05], \"logFCs\": [1], \"go_ont\": \"BP\", \"ranking\":\"n/a\", \"minGSSize\": 15, \"maxGSSize\": 500,\n",
    "                                   \"use_internal_data\": True, \"internal_data_path\": \"../data/clusterORA/KEGG_DATA.RData\"}\n",
    "                    } \n",
    "}\n",
    "\n",
    "\n",
    "mode = \"send jobs\"\n",
    "#mode = \"test main\"\n",
    "mode = \"just testing\"\n",
    "sleep_seconds = 0\n",
    "\n",
    "run_gsea_batch(gsea_config_params, all_N, n_cohorts, libraries, gsea_script_path=gsea_script_path, mode=mode, sleep_seconds=sleep_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49c8bd2-101e-4903-bda9-a82e7f63f427",
   "metadata": {},
   "outputs": [],
   "source": [
    "!squeue -u pd21v747"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf1efd1-aef6-42f8-93cd-157a34b116a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"LIHC\"\n",
    "N = 3\n",
    "library = libraries[0]\n",
    "cohort = 1\n",
    "dea = \"edgerqlf\"\n",
    "out = \"none\"\n",
    "gsea_method = \"clusterORA_lfc.fdr0.05.post_lfc1.lfc1\"\n",
    "param_set = \"p1\"\n",
    "site = datasets[data][\"site\"]\n",
    "p=f\"../data/{site}/{data}/{data}_N{N}/{data}_N{N}_{cohort:04}/gsea/{gsea_method}.{library}.{dea}.{out}.{param_set}.feather\"\n",
    "t=open_table(p)\n",
    "print(len(t[t[\"FDR\"]<0.05]))\n",
    "t.sort_values(by=\"FDR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa320d0-62d3-475d-b2c8-b7099e6bbcc8",
   "metadata": {},
   "source": [
    "## Process jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d574df-c15a-4f6c-ac88-8a4337e433e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "importlib.reload(sys.modules[\"process\"])\n",
    "\n",
    "from process import gsea_process_pipeline\n",
    "gFDRs = [0.05]\n",
    "gsea_methods = [\"clusterORA_lfc.fdr0.05.post_lfc1.lfc1\", \"gseapy\",\"clusterORA.fdr0.05.post_lfc0.lfc0\"] #gseapy_s2n, \"clusterORA.fdr0.05.post_lfc1.lfc0\"\n",
    "DEA_methods = [\"edgerqlf\"]#[\"deseq2\", \"edgerlrt\"]\n",
    "all_N = [3]#,5,7,9,15] \n",
    "\n",
    "import subprocess as sp\n",
    "output = sp.getoutput('squeue -u pd21v747')\n",
    "jobs_running = output.find(\"send_gse\") > 0\n",
    "\n",
    "if not jobs_running:\n",
    "    gsea_process_pipeline(outpath, outname, all_N, DEA_methods, outlier_methods, gsea_methods, libraries, \n",
    "                          gFDRs, \"p1\", overwrite=1, overwrite_merged=1, n_cohorts=50, calculate_common=1)\n",
    "    # when adding new method: overwrite merged and calculcate common only with new method, then only overwrite with all emthods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39962ef8-000d-427c-ace5-c20c385f6a83",
   "metadata": {},
   "source": [
    "## Merge processed data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a24dac9-1328-4c0b-a7ad-abcd6775d1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsea_datasets = {sites[s]: {} for s in sites}\n",
    "\n",
    "def load_gsea_results(path, site, name):\n",
    "    resultsfile = f\"{path}/{site}/{name}/gsea_results.txt\"\n",
    "    with open(resultsfile, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "for s in sites:\n",
    "    #if s not in [\"breast\",\"colorectal\",\"kidney\",\"lung\",\"liver\"]: continue\n",
    "    gsea_datasets[sites[s]][\"site\"] = s\n",
    "    res = load_gsea_results(datapath, s, sites[s])\n",
    "    for key in res.keys():\n",
    "        gsea_datasets[sites[s]][key] = res[key]\n",
    "\n",
    "gsea_datasetsfile = \"/storage/homefs/pd21v747/datanew/multi/gsea_datasets.txt\"\n",
    "pickler(gsea_datasets, gsea_datasetsfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc43205b-6b44-4ce2-a9f1-c639f73d4968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tidy dataframe\n",
    "\n",
    "DEAs = DEA_methods\n",
    "FDRs = [0.05]\n",
    "all_N=[3]#,5,7,9,15]\n",
    "\n",
    "    \n",
    "quantity = [\"median_rep\", \"median_terms\",\n",
    "            \"median_mcc\", \"median_prec\", \"median_rec\"]\n",
    "quantity += [q+\"_common\" for q in quantity]\n",
    "\n",
    "iterables = [gsea_datasets,all_N,outlier_methods,DEAs,gsea_methods,libraries,FDRs,quantity]\n",
    "multi_cols = pd.MultiIndex.from_product(iterables, names=[\"Data\", \"N\", \"Out\", \"DEA\", \"Enrichment\", \"Library\", \"FDR\", \"Val\"])\n",
    "combined = pd.DataFrame(columns=multi_cols)\n",
    "\n",
    "ids = [] # id connecting samples from same dataset and cohort size, used for paired-sample testing pre vs. post outlier removal\n",
    "for i, d in enumerate(gsea_datasets):\n",
    "    for j, N in enumerate(all_N):\n",
    "        k = i*len(all_N)+j \n",
    "        for out in outlier_methods:\n",
    "            for dea in DEAs:\n",
    "                for gsea in gsea_methods:\n",
    "                    #if dea != \"edger\" and gsea_methods == \"gsea_s2n\": continue\n",
    "                    for fdr in FDRs:\n",
    "                        for lib in libraries:\n",
    "                            for quant in quantity:\n",
    "                                #print(d,N,out,dea,fdr)\n",
    "                                col = (d,N,out,dea,gsea,lib,fdr,quant)\n",
    "                                combined.loc[0,col] = gsea_datasets[d][N][out][dea][gsea][lib][quant][fdr]\n",
    "                                if quant == \"median_rep\": ids.append(k)\n",
    "                            \n",
    "combined_gsea_td = combined.unstack().unstack(level=\"Val\").reset_index(level=[\"Data\",\"N\",\"Out\",\"DEA\",\"Enrichment\",\"Library\",\"FDR\"], drop=False)\n",
    "combined_gsea_td[\"id\"] = ids\n",
    "combined_gsea_td.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# For outlier_method == \"none\", no adjustment is necessary, hence copy unadjusted values\n",
    "#none_ix = combined_gsea_td[combined_gsea_td[\"Out\"] == \"none\"].index # avoid setting with copy warning\n",
    "#combined_gsea_td.loc[none_ix,\"median_terms_adj\"] = combined_gsea_td.loc[none_ix,\"median_terms\"]\n",
    "#combined_gsea_td.loc[none_ix,\"median_rep_adj\"] = combined_gsea_td.loc[none_ix,\"median_rep\"]\n",
    "\n",
    "for clean in cleanout:\n",
    "    combined_gsea_td.loc[(combined_gsea_td[combined_gsea_td[\"Out\"] == clean]).index, \"Out\"] = cleanout[clean]\n",
    "for clean in cleandea:\n",
    "    combined_gsea_td.loc[(combined_gsea_td[combined_gsea_td[\"DEA\"] == clean]).index, \"DEA\"] = cleandea[clean]\n",
    "combined_gsea_td.to_csv(f\"../data/multi/combined_gsea_td.csv\")\n",
    "combined_gsea_td.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05779d0-9125-4fa7-921c-fbdf876d7679",
   "metadata": {},
   "source": [
    "## Inspect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10fdd80-f92c-4360-ad17-e89cb851bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc import get_grid_size\n",
    "\n",
    "x = \"median_terms_common\"\n",
    "y = \"median_rep_common\"\n",
    "\n",
    "a  = combined_gsea_td\n",
    "#a = a[a[\"Library\"]==\"KEGG_2021_Human\"]\n",
    "hues = [\"Data\",\"Library\",\"DEA\",\"Out\",\"N\", \"Enrichment\"]\n",
    "grid = get_grid_size(len(hues), k=0, fill=True)\n",
    "fig, ax = plt.subplots(grid[0],grid[1],figsize=(6*grid[0],3*grid[1]), sharex=True,sharey=True)\n",
    "ax=ax.flatten()\n",
    "\n",
    "for i, hue in enumerate(hues):\n",
    "    sns.scatterplot(data=a, x=x, y=y, hue=hue, ax=ax[i])    \n",
    "    ax[i].invert_yaxis()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60e983b-7989-4cd1-ad52-5961f0e232ce",
   "metadata": {},
   "source": [
    "# Misc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a43d0f-57b1-4b59-b0d6-6f56a91b55c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from process import delete_redundant_slurmfiles\n",
    "\n",
    "delete_redundant_slurmfiles(outpath, outname, all_N)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1854f49-54b3-47df-9003-ff1dbe844932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "importlib.reload(sys.modules[\"misc\"])\n",
    "importlib.reload(sys.modules[\"DEA\"])\n",
    "importlib.reload(sys.modules[\"enrichment\"])\n",
    "importlib.reload(sys.modules[\"process\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
