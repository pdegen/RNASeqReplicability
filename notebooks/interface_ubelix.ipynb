{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce994fa7-ad3c-4162-b2ff-ce5d4d95fa3b",
   "metadata": {},
   "source": [
    "Notebook to send jobs to the Ubelix HPC cluster at the University of Bern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45066980-1b1d-4b28-8217-caffb9ddfd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import glob\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "logging.basicConfig(filename='example.log', \n",
    "                    encoding='utf-8', level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "datapath = Path(\"../data\")\n",
    "#datapath = Path(\"/storage/homefs/pd21v747/datanew\")\n",
    "\n",
    "modpath = Path(\"../scripts\")\n",
    "sys.path.append(os.path.relpath(modpath))\n",
    "\n",
    "from misc import Timer, pickler, open_table\n",
    "\n",
    "# when using UBELIX on-demand\n",
    "os.environ['R_HOME'] = '/storage/homefs/pd21v747/.conda/rna-rep/lib/R/'\n",
    "import rpy2.robjects as ro\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa06e64-3add-4b07-ad2b-4cf6a6eaad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "include_unpaired_cancer = False\n",
    "include_synthetic = False\n",
    "\n",
    "# 8 cancer types for main results\n",
    "sites = {\"liver\": \"LIHC\",\n",
    "         \"thyroid\": \"THCA\",\n",
    "         \"lung\": \"LUAD\",\n",
    "         \"lung2\": \"LUSC\",\n",
    "         \"kidney\": \"KIRC\",\n",
    "         \"colorectal\": \"COAD\",\n",
    "         \"breast\": \"BRCA\",\n",
    "         \"prostate\": \"PRAD\"}\n",
    "\n",
    "# Misc unpaired only datasets added in revision\n",
    "misc_unpaired = {\n",
    "         \"GSETB\":\"LWPL\",\n",
    "         \"yeast\":\"SNF2\"\n",
    "}\n",
    "\n",
    "misc_custom_design = {\n",
    "            \"GSEPN\":\"GIPF\",\n",
    "            \"breast_basher\": \"BASHER\", # Basal vs HER2+\n",
    "            \"breast_basluma\": \"BASLUMA\", # Basal vs Luminal A\n",
    "            \"breast_baslumb\": \"BASLUMB\", # Basal vs Luminal B\n",
    "            \"breast_herluma\": \"HERLUMA\", # HER2 vs Luminal A\n",
    "            \"breast_herlumb\": \"HERLUMB\", # HER2 vs Luminal B\n",
    "            \"breast_lumab\": \"LUMAB\" # LumA vs LumB\n",
    "}\n",
    "\n",
    "synthetic_sites = {\n",
    "\n",
    "                  ## SMALL LFC VARIANCE\n",
    "                  \"synthetic10psv\": \"SBRCA10psv\", # 10% DEGs\n",
    "                  \"synthetic25psv\": \"SBRCA25psv\", # 25% DEGs\n",
    "    \n",
    "                  ## MEDIUM LFC VARIANCE\n",
    "                  \"synthetic1p\":\"SBRCA1p\", # 1% DEGs\n",
    "                  \"synthetic\":\"SBRCA1\", # 10% DEGS\n",
    "                  \"syntheticl\":\"SBRCAl\", # 25% DEGs\n",
    "\n",
    "                  ## LARGE LFC VARIANCE\n",
    "                  \"synthetic10plv\": \"SBRCA10plv\" # 10% DEGs\n",
    "\n",
    "                  # Superfluous\n",
    "                  # \"synthetic5\":\"SBRCA5\", # 5% DEGs\n",
    "                  # \"synthetic2p\":\"SBRCA2p\", # 2% DEGs\n",
    "                  }\n",
    "\n",
    "sites = sites | misc_unpaired | misc_custom_design\n",
    "\n",
    "# Investigate unpaired testing for supplementary figure\n",
    "if include_unpaired_cancer:\n",
    "    sites = sites | {k+\"_unpaired\":v+\"_unpaired\" for k,v in sites.items()}\n",
    "\n",
    "if include_synthetic:\n",
    "    sites = sites | synthetic_sites\n",
    "\n",
    "datasets = {sites[s]: {} for s in sites}\n",
    "unpaired_data = list(misc_unpaired.values()) + [s for s in sites.keys() if \"unpaired\" in s] + list(synthetic_sites.values())\n",
    "\n",
    "for s in sites:\n",
    "    f = Path(f\"{datapath}/{s}/{sites[s]}/{sites[s]}.csv\")\n",
    "    df = pd.read_csv(f, index_col=0)\n",
    "    datasets[sites[s]][\"genes\"] = len(df)\n",
    "    datasets[sites[s]][\"site\"] = s\n",
    "    datasets[sites[s]][\"datapath\"] = f\n",
    "    datasets[sites[s]][\"metafile\"] = f.parent / (f.stem + \".meta.csv\")\n",
    "    datasets[sites[s]][\"outpath\"] = f.parent\n",
    "    datasets[sites[s]][\"patients\"] = len(df.columns)//2\n",
    "    datasets[sites[s]][\"isSynthetic\"] = sites[s] in synthetic_sites.values()\n",
    "    print(f\"{s:<10}\", datasets[sites[s]][\"genes\"], datasets[sites[s]][\"patients\"])\n",
    "    \n",
    "# Pretty names\n",
    "cleanout = {\"jk\": \"ReBoost\",\n",
    "            \"pcah\": \"rPCA\",\n",
    "            \"none\": \"None\"}\n",
    "cleandea = {\"edger\": \"edgeR QLF\",\n",
    "            \"edgerlrt\": \"edgeR LRT\",\n",
    "            \"deseq2\": \"DESeq2\",\n",
    "            \"wilcox\": \"Wilcoxon rank-sum\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b4ca6b-3492-4182-8d33-cb32f8a3d942",
   "metadata": {},
   "source": [
    "# Differential expression analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34570dc0-6cb6-41f1-9fff-12cf46bd124d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Define ground truth\n",
    "\n",
    "Define ground truth DEGs for a given FDR, logFC cutoff as the intersection of DEGs from all three DEA tests (Wald, LRT, QLF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d9bb32-f841-4f65-be03-2343c4a3d3b8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sys, importlib\n",
    "# importlib.reload(sys.modules[\"DEA\"])\n",
    "\n",
    "from DEA import run_dea_on_full_data\n",
    "from process import find_ground_truth\n",
    "\n",
    "DEAs = [\"edgerlrt\", \"edgerqlf\", \"deseq2\", \"wilcox\"]\n",
    "\n",
    "# Wilcox was added during revision; truth is defined using original three methods\n",
    "truth_defining_DEAs = [\"edgerlrt\", \"edgerqlf\", \"deseq2\"]\n",
    "\n",
    "FDRs = [0.1,0.05,0.01,0.001]\n",
    "logFCs = [0, 0.5, 1]#, 2] # formal lfc threhsold in edger or deseq2\n",
    "logFCs_post = [0,0.5,1,1.5,2] # post hoc thresholds\n",
    "\n",
    "paired = {key:value for key, value in datasets.items() if key not in unpaired_data}\n",
    "print(f\"Running {len(paired)} paired\")\n",
    "#run_dea_on_full_data(paired, DEAs, overwrite = False, lfcs = logFCs, design=\"paired\")\n",
    "\n",
    "unpaired = {key:value for key, value in datasets.items() if key in unpaired_data}\n",
    "print(f\"Running {len(unpaired)} unpaired\")\n",
    "run_dea_on_full_data(unpaired, DEAs, overwrite = False, lfcs = logFCs, design=\"unpaired\")\n",
    "\n",
    "custom = {key:value for key, value in datasets.items() if key in misc_custom_design.values()}\n",
    "print(f\"Running {len(custom)} custom designs\")\n",
    "#run_dea_on_full_data(custom, DEAs, overwrite = False, lfcs = logFCs, design=\"custom\")\n",
    "\n",
    "print(\"Finding ground truth\")\n",
    "# overwrite True if new dataset added\n",
    "datasets = find_ground_truth(datasets, truth_defining_DEAs, FDRs, logFCs_post, lfc_tests = logFCs, save=True, overwrite=0) \n",
    "#datasets = find_ground_truth(datasets, truth_defining_DEAs, FDRs, [1], lfc_tests = [1])\n",
    "\n",
    "# Overwrite if new dataset added\n",
    "#pickler(datasets,\"../data/multi/datasets.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64d138f-60d3-426b-b2df-1366dce33c72",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tab = pd.read_csv(\"/storage/homefs/pd21v747/RNASeqReplicability/data/breast/BRCA/BRCA.edgerqlf.lfc2.csv\", index_col=0)\n",
    "# tab[tab[\"FDR\"]<0.05]\n",
    "\n",
    "#datasets[\"LUAD\"][\"truth_stats\"][0][0.05][0], datasets[\"LUAD\"][\"truth_stats\"][1][0.05][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10132553-f115-40a9-a516-0fb7f404fa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from process import find_ground_truth\n",
    "\n",
    "# # Calcualte ground truth stats with with Wilcoxon just for one figure\n",
    "# DEAs_wilcox = [\"edgerlrt\", \"edgerqlf\", \"deseq2\", \"wilcox\"]\n",
    "# logFCs_post_wilcox = [0,1]\n",
    "# datasets_with_wilcox = find_ground_truth(datasets, DEAs_wilcox, FDRs, logFCs_post_wilcox, \n",
    "#                                          lfc_tests = [0,1], save=False, overwrite=1) # don't save\n",
    "# pickler(datasets_with_wilcox, \"../data/multi/datasets_wilcox.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abd85c8-d1f3-4bd0-96bd-5361cbc77d7a",
   "metadata": {},
   "source": [
    "## Send batch jobs for selected data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9fa9cf-ee8f-4e5b-b287-d707de00dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = \"HERLUMB\"\n",
    "outpath = datasets[selected_data][\"outpath\"]\n",
    "outname = outpath.name\n",
    "outpath, outname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbd4af2-f0d5-4a7b-922c-e8b0f1255529",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from ubelix import run_multi_batch\n",
    "\n",
    "script_path = Path(\"../scripts/send_batch.sh\")\n",
    "DEA_methods = [\"edgerqlf\",\"edgerlrt\", \"deseq2\"]#, \"wilcox\"] # finish edgerqlf jobs before sending other jobs\n",
    "outlier_methods = [\"none\"]#, \"pcah\", \"jk\"] # only use none for p2 and p3\n",
    "all_N = [3,4,5,6,7,8,9,10,12,15]\n",
    "n_cohorts = 100\n",
    "\n",
    "assert outname in str(outpath)\n",
    "\n",
    "# lfc 0 threshold, paired\n",
    "config_params_1 = {\n",
    "    \n",
    "    \"param_set\": \"p1\", # id for this set of parameters\n",
    "    \"sampler\": \"paired\",\n",
    "    \n",
    "    \"overwrite\": False, # overwrite existing tabs\n",
    "    \"data\": str(outpath) + \"/\" + outname + \".csv\",\n",
    "    \"outpath\": str(outpath),\n",
    "    \"outname\": outname,\n",
    "    \n",
    "    \"DEA_methods\": DEA_methods,\n",
    "    \"outlier_methods\": outlier_methods,\n",
    "    \n",
    "    \"outlier_kwargs\": {\n",
    "        \"none\": {},\n",
    "        \"jk\": {\n",
    "            \"FDR\": 0.01,\n",
    "            \"overwrite\": False, # overwrite existing jk tab\n",
    "            \"max_removed_frac\": 0.5, # fraction of patients; after 1st iteration, don't jackknife bottom frac patients\n",
    "            \"efficient\": True,\n",
    "            \"cols_to_keep\": [\"FDR\"],\n",
    "            \"cleanup\": True # remove individual jk tabs and iterations after merger\n",
    "        },\n",
    "        \"pcah\": {\"k\": 2}\n",
    "    },\n",
    "    \n",
    "    \"DEA_kwargs\": {\n",
    "        \"edgerqlf\": {\"filter_expr\": False, \"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"], \"design\": \"paired\"},\n",
    "        \"edgerlrt\": {\"filter_expr\": False, \"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"], \"test\":\"lrt\", \"design\": \"paired\"},\n",
    "        \"deseq2\": {\"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"], \"design\": \"paired\"},\n",
    "        \"wilcox\": {\"design\": \"paired\"}\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "# lfc = 0 threshold, unpaired\n",
    "config_params_1u = deepcopy(config_params_1)\n",
    "config_params_1u[\"param_set\"] = \"p10\"\n",
    "config_params_1u[\"DEA_kwargs\"][\"edgerqlf\"][\"design\"] = \"unpaired\"\n",
    "config_params_1u[\"DEA_kwargs\"][\"edgerlrt\"][\"design\"] = \"unpaired\"\n",
    "config_params_1u[\"DEA_kwargs\"][\"deseq2\"][\"design\"] = \"unpaired\"\n",
    "config_params_1u[\"DEA_kwargs\"][\"wilcox\"][\"design\"] = \"unpaired\"\n",
    "\n",
    "# lfc = 0 threshold, custom\n",
    "config_params_1c = deepcopy(config_params_1)\n",
    "config_params_1c[\"param_set\"] = \"p1c\"\n",
    "config_params_1c[\"DEA_kwargs\"][\"edgerqlf\"][\"design\"] = \"custom\"\n",
    "config_params_1c[\"DEA_kwargs\"][\"edgerlrt\"][\"design\"] = \"custom\"\n",
    "config_params_1c[\"DEA_kwargs\"][\"deseq2\"][\"design\"] = \"custom\"\n",
    "config_params_1c[\"DEA_kwargs\"][\"wilcox\"][\"design\"] = \"custom\"\n",
    "\n",
    "# lfc = 1 threshold, paired\n",
    "config_params_2 = {\n",
    "    \n",
    "    \"param_set\": \"p2\", # id for this set of parameters\n",
    "    \"sampler\": \"paired\",\n",
    "    \n",
    "    \"overwrite\": False, # overwrite existing tabs\n",
    "    \"data\": str(outpath) + \"/\" + outname + \".csv\",\n",
    "    \"outpath\": str(outpath),\n",
    "    \"outname\": outname,\n",
    "    \n",
    "    \"DEA_methods\": DEA_methods,\n",
    "    \"outlier_methods\": outlier_methods,\n",
    "    \n",
    "    \"outlier_kwargs\": {\n",
    "        \"none\": {},\n",
    "        \"jk\": {\n",
    "            \"FDR\": 0.01,\n",
    "            \"overwrite\": False, # overwrite existing jk tab\n",
    "            \"max_removed_frac\": 0.5, # fraction of patients; after 1st iteration, don't jackknife bottom frac patients\n",
    "            \"efficient\": True,\n",
    "            \"cols_to_keep\": [\"FDR\"],\n",
    "            \"cleanup\": True # remove individual jk tabs and iterations after merger\n",
    "        },\n",
    "        \"pcah\": {\"k\": 2}\n",
    "    },\n",
    "    \n",
    "    \"DEA_kwargs\": {\n",
    "        \"edgerqlf\": {\"filter_expr\": False, \"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"], \"lfc\": 1, \"design\": \"paired\"},\n",
    "        \"edgerlrt\": {\"filter_expr\": False, \"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"], \"test\":\"lrt\", \"lfc\": 1, \"design\": \"paired\"},\n",
    "        \"deseq2\": {\"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"],\"lfc\": 1, \"design\": \"paired\"}\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "# lfc = 1 threshold, custom\n",
    "config_params_2c = deepcopy(config_params_2)\n",
    "config_params_2c[\"param_set\"] = \"p2c\"\n",
    "config_params_2c[\"DEA_kwargs\"][\"edgerqlf\"][\"design\"] = \"custom\"\n",
    "config_params_2c[\"DEA_kwargs\"][\"edgerlrt\"][\"design\"] = \"custom\"\n",
    "config_params_2c[\"DEA_kwargs\"][\"deseq2\"][\"design\"] = \"custom\"\n",
    "config_params_2c[\"sampler\"] = \"unpaired\"\n",
    "\n",
    "# lfc = 1 threshold, unpaired analysis (for data that is unpaired, such as synthetic data)\n",
    "config_params_3 = {\n",
    "    \n",
    "    \"param_set\": \"p3\", # id for this set of parameters\n",
    "    \"sampler\": \"unpaired\",\n",
    "    \n",
    "    \"overwrite\": False, # overwrite existing tabs\n",
    "    \"data\": str(outpath) + \"/\" + outname + \".csv\",\n",
    "    \"outpath\": str(outpath),\n",
    "    \"outname\": outname,\n",
    "    \n",
    "    \"DEA_methods\": DEA_methods,\n",
    "    \"outlier_methods\": outlier_methods,\n",
    "    \n",
    "    \"outlier_kwargs\": {\n",
    "        \"none\": {},\n",
    "        \"jk\": {},\n",
    "        \"pcah\": {}\n",
    "    },\n",
    "    \n",
    "    \"DEA_kwargs\": {\n",
    "        \"edgerqlf\": {\"filter_expr\": False, \"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"], \"lfc\": 1, \"design\": \"unpaired\"},\n",
    "        \"edgerlrt\": {\"filter_expr\": False, \"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"], \"test\":\"lrt\", \"lfc\": 1, \"design\": \"unpaired\"},\n",
    "        \"deseq2\": {\"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"],\"lfc\": 1, \"design\": \"unpaired\"}\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "# lfc = 0.5, unpaired\n",
    "config_params_35 = deepcopy(config_params_3)\n",
    "config_params_35[\"param_set\"] = \"p35\"\n",
    "config_params_35[\"DEA_kwargs\"][\"edgerqlf\"][\"lfc\"] = 0.5\n",
    "config_params_35[\"DEA_kwargs\"][\"edgerlrt\"][\"lfc\"] = 0.5\n",
    "config_params_35[\"DEA_kwargs\"][\"deseq2\"][\"lfc\"] = 0.5\n",
    "\n",
    "# lfc = 2 threshold, paired\n",
    "config_params_5 = {\n",
    "    \n",
    "    \"param_set\": \"p5\", # id for this set of parameters\n",
    "    \"sampler\": \"paired\",\n",
    "    \n",
    "    \"overwrite\": False, # overwrite existing tabs\n",
    "    \"data\": str(outpath) + \"/\" + outname + \".csv\",\n",
    "    \"outpath\": str(outpath),\n",
    "    \"outname\": outname,\n",
    "    \n",
    "    \"DEA_methods\": DEA_methods,\n",
    "    \"outlier_methods\": outlier_methods,\n",
    "    \n",
    "    \"outlier_kwargs\": {\n",
    "        \"none\": {},\n",
    "        \"jk\": {\n",
    "            \"FDR\": 0.01,\n",
    "            \"overwrite\": False, # overwrite existing jk tab\n",
    "            \"max_removed_frac\": 0.5, # fraction of patients; after 1st iteration, don't jackknife bottom frac patients\n",
    "            \"efficient\": True,\n",
    "            \"cols_to_keep\": [\"FDR\"],\n",
    "            \"cleanup\": True # remove individual jk tabs and iterations after merger\n",
    "        },\n",
    "        \"pcah\": {\"k\": 2}\n",
    "    },\n",
    "    \n",
    "    \"DEA_kwargs\": {\n",
    "        \"edgerqlf\": {\"filter_expr\": False, \"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"], \"lfc\": 2, \"design\": \"paired\"},\n",
    "        \"edgerlrt\": {\"filter_expr\": False, \"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"], \"test\":\"lrt\", \"lfc\": 2, \"design\": \"paired\"},\n",
    "        \"deseq2\": {\"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"],\"lfc\": 2, \"design\": \"paired\"}\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "import subprocess as sp\n",
    "output = sp.getoutput('squeue -u pd21v747')\n",
    "jobs_running = output.find(\"send_bat\") > 0\n",
    "\n",
    "#mode = \"send jobs\" \n",
    "\n",
    "# SBATCH with srun does not work from interactive session in newer version of slurm\n",
    "# https://harvardmed.atlassian.net/wiki/spaces/O2/pages/1586793613/Troubleshooting+Slurm+Jobs#Jobs-fail-with-the-message%3A-Unable-to-satisfy-CPU-bind-request\n",
    "# workaround: use mode=just testing, copy the command and send job from terminal in submit node\n",
    "# must set job time/mem manually in shell script\n",
    "\n",
    "###########################################################################\n",
    "#### wd must be notebooks folder, must load environment beforehand!!!!#####\n",
    "###########################################################################\n",
    "\n",
    "mode = \"test main terminal\"\n",
    "mode = \"just testing\"\n",
    "\n",
    "import sys, importlib\n",
    "importlib.reload(sys.modules[\"ubelix\"])\n",
    "from ubelix import run_multi_batch\n",
    "\n",
    "do_nothing = False\n",
    "config_params = config_params_2c\n",
    "\n",
    "if config_params != config_params_1 and \"wilcox\" in DEA_methods:\n",
    "    DEA_methods.remove(\"wilcox\")\n",
    "\n",
    "if not jobs_running and not do_nothing:\n",
    "    run_multi_batch(config_params, all_N, n_cohorts, script_path, mode = mode, trysubsample=True)\n",
    "elif jobs_running:\n",
    "    print(\"Jobs running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2e8f2a-82b5-47dc-b361-caab2a575fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!squeue -u pd21v747"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2ef946-de4b-43ce-973a-5b800a6a3a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tab = open_table(\"/storage/homefs/pd21v747/RNASeqReplicability/data/liver/LIHC/LIHC_N15/LIHC_N15_0001/tab.none.deseq2.p5.feather\")\n",
    "# tab[tab[\"FDR\"]<0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9452b65b-ce89-4a2e-89bf-7a6a4000f5bb",
   "metadata": {},
   "source": [
    "## Process jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9b36f1-7d5d-4fe7-a047-8e006c6cfd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#post hoc\n",
    "DEAs = [\"wilcox\", \"edgerqlf\", \"edgerlrt\", \"deseq2\"]\n",
    "outlier_methods = [\"none\"]#, \"pcah\", \"jk\"]\n",
    "FDRs = [0.1,0.05,0.01,0.001]\n",
    "logFCs = [0, 0.5, 1, 1.5, 2]\n",
    "all_N = [3,4,5,6,7,8,9,10,12,15]\n",
    "lfc_test = 0\n",
    "param_set = \"p1\"\n",
    "\n",
    "# #formal\n",
    "DEAs = [\"edgerqlf\",\"deseq2\", \"edgerlrt\"]\n",
    "outlier_methods = [\"none\"]#, \"pcah\", \"jk\"]\n",
    "FDRs = [0.1,0.05,0.01,0.001]\n",
    "logFCs = [1]\n",
    "all_N = [3,4,5,6,7,8,9,10,12,15]\n",
    "lfc_test = 1\n",
    "param_set = \"p2\"\n",
    "\n",
    "# # #formal\n",
    "# DEAs = [\"edgerqlf\",\"deseq2\", \"edgerlrt\"]\n",
    "# outlier_methods = [\"none\"]#, \"pcah\", \"jk\"]\n",
    "# FDRs = [0.1,0.05,0.01,0.001]\n",
    "# logFCs = [2]\n",
    "# all_N = [3,4,5,6,7,8,9,10,12,15]\n",
    "# lfc_test = 2\n",
    "# param_set = \"p5\"\n",
    "\n",
    "#unpaired\n",
    "DEAs = [\"edgerqlf\", \"edgerlrt\", \"deseq2\"]\n",
    "outlier_methods = [\"none\"]\n",
    "FDRs = [0.05]#[0.1,0.05,0.01,0.001]\n",
    "logFCs = [1]\n",
    "all_N = [3,4,5,6,7,8,9,10,12,15]\n",
    "lfc_test = 1\n",
    "param_set = \"p3\"\n",
    "\n",
    "# #custom\n",
    "DEAs = [\"edgerqlf\", \"edgerlrt\", \"deseq2\"]\n",
    "outlier_methods = [\"none\"]\n",
    "FDRs = [0.05]#[0.1,0.05,0.01,0.001]\n",
    "logFCs = [1]\n",
    "all_N = [3,4,5,6,7,8,9,10,12,15]\n",
    "lfc_test = 1\n",
    "param_set = \"p2c\"\n",
    "\n",
    "# DEAs = [\"edgerqlf\", \"edgerlrt\", \"deseq2\"]\n",
    "# outlier_methods = [\"none\"]\n",
    "# FDRs = [0.05]#[0.1,0.05,0.01,0.001]\n",
    "# logFCs = [0]\n",
    "# all_N = [3,4,5,6,7,8,9,10,12,15]\n",
    "# lfc_test = 0\n",
    "# param_set = \"p1c\"\n",
    "\n",
    "# #unpaired lfc 0.5\n",
    "# logFCs = [0.5]\n",
    "# lfc_test = 0.5\n",
    "# param_set = \"p35\"\n",
    "\n",
    "# #unpaired\n",
    "# DEAs = [\"edgerqlf\", \"edgerlrt\", \"deseq2\"]\n",
    "# outlier_methods = [\"none\"]\n",
    "# FDRs = [0.05] #[0.1,0.05,0.01,0.001]\n",
    "# logFCs = [1]\n",
    "# all_N = [3,7,15]\n",
    "# lfc_test = 1\n",
    "# param_set = \"p4\"\n",
    "\n",
    "param_sets = [\"p1\",\"p1c\",\"p2\",\"p2c\",\"p3\",\"p35\",\"p4\",\"p5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52512662-3f83-4dca-b5f9-faac1df7d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, message='All-NaN slice encountered')\n",
    "\n",
    "\n",
    "from process import process_pipeline\n",
    "from misc import profile_func\n",
    "import pstats\n",
    "\n",
    "isSynthetic = outname.startswith(\"SBRCA\")\n",
    "\n",
    "kwargs = {\"outpath\":outpath, \"outname\":outname, \"all_N\": all_N, \"DEAs\":DEAs, \"outlier_methods\": outlier_methods, \n",
    "          \"FDRs\":FDRs, \"logFCs\":logFCs, \"lfc_test\": lfc_test, \"param_set\":param_set, \"overwrite\": 1, \"overwrite_merged\": 0, \"n_cohorts\": 100, \"isSynthetic\": isSynthetic}\n",
    "\n",
    "do_process = True\n",
    "do_profile = False\n",
    "\n",
    "if do_process:\n",
    "    if do_profile:\n",
    "        prof = profile_func(process_pipeline, kwargs)\n",
    "        stats = pstats.Stats(prof).strip_dirs().sort_stats(\"cumtime\")\n",
    "        stats.print_stats(50)\n",
    "    else:\n",
    "        process_pipeline(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f35b6e-a705-41a1-8462-99f6f3d2556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Process multiple data sets\n",
    "# import process, sys, importlib\n",
    "# importlib.reload(sys.modules[\"process\"])\n",
    "\n",
    "# from process import process_pipeline\n",
    "\n",
    "# for data in datasets:\n",
    "#     print(data)\n",
    "#     #if not data.startswith(\"THCA\"): continue\n",
    "\n",
    "#     for key in datasets[data].keys():\n",
    "        \n",
    "#         if not isinstance(datasets[data][key], dict):\n",
    "#             continue\n",
    "            \n",
    "#         is_valid_param_set = True\n",
    "        \n",
    "#         for N in all_N:\n",
    "#             if N not in datasets[data][key]:\n",
    "#                 is_valid_param_set = False\n",
    "#                 break\n",
    "                \n",
    "#         if not is_valid_param_set:\n",
    "#             continue\n",
    "\n",
    "#         if key != \"p1\": continue\n",
    "\n",
    "#         print(key)\n",
    "\n",
    "#         if key in [\"p1\"]:\n",
    "#             logFCs_k = [0,1] \n",
    "#             lfc_test_k = 0\n",
    "#         elif key in [\"p2\",\"p3\",\"p2c\",\"p4\"]:\n",
    "#             logFCs_k = [1]\n",
    "#             lfc_test_k = 1\n",
    "#         elif key in [\"p35\"]:\n",
    "#             logFCs_k = [0.5]\n",
    "#             lfc_test_k = 0.5\n",
    "#         elif key in [\"p5\"]:\n",
    "#             logFCs_k = [2]\n",
    "#             lfc_test_k = 2\n",
    "#         else:\n",
    "#             print(\"Skipping unknown key:\", key, data)\n",
    "#             continue\n",
    "        \n",
    "#         outpath = datasets[data][\"outpath\"]\n",
    "#         outname = str(outpath).split(\"/\")[-1]\n",
    "#         kwargs = {\"outpath\":outpath, \"outname\":outname, \"all_N\": all_N, \"DEAs\":DEAs, \"outlier_methods\": outlier_methods, \n",
    "#                   \"FDRs\":FDRs, \"logFCs\":logFCs_k, \"lfc_test\": lfc_test_k, \"param_set\":key, \"overwrite\": 1, \"overwrite_merged\": 0, \"n_cohorts\": 100, \"isSynthetic\": isSynthetic}\n",
    "#         process_pipeline(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b374aeae-9288-4cd5-8d86-b6fdb3c5e6a2",
   "metadata": {},
   "source": [
    "### Merge processed data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf41be7c-cda5-42d1-8cbb-a571aa318963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(path, site, name, param_set):\n",
    "    resultsfile = f\"{path}/{site}/{name}/results.{param_set}.txt\"\n",
    "    try:\n",
    "        with open(resultsfile, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        pass#print(f\"File not found: {resultsfile}\")\n",
    "    \n",
    "for s in sites:\n",
    "    #if s not in [\"colorectal\",\"prostate\",\"breast\",\"thyroid\",\"liver\"]: continue\n",
    "\n",
    "    for ps in param_sets:\n",
    "        res = load_results(datapath, s, sites[s], ps)\n",
    "        if ps not in datasets[sites[s]]:\n",
    "            datasets[sites[s]][ps] = {}\n",
    "        if res == None: continue\n",
    "        for key in res.keys():\n",
    "            datasets[sites[s]][ps][key] = res[key]\n",
    "\n",
    "assert \"truth_stats\" in datasets[list(datasets.keys())[0]] # don't forget to load ground truth\n",
    "datasetsfile = Path(datapath, \"multi/datasets.txt\")\n",
    "pickler(datasets, datasetsfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879ba2b4-9da4-4e72-a2d5-d4e1849d6008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tidy dataframe\n",
    "\n",
    "def tidy_df(datasets, param_set, logFCs, all_N, include_sd=False, include_adj=False):\n",
    "        \n",
    "    quantity = [\"median_rep\", \"median_deg\",\"median_mcc0\", \"median_prec0\", \"median_mcc\", \"median_prec\", \"median_rec\"]\n",
    "    \n",
    "    if include_adj:\n",
    "        quantity += [q+\"_adj\" for q in quantity]\n",
    "    if include_sd:\n",
    "        quantity += [q+(\"_sd\" if \"rep\" in q else \"_sem\") for q in quantity]\n",
    "    \n",
    "    quantity += [q+\"_syn\" for q in quantity]\n",
    "    quantity += [q+\"_method\" for q in quantity]\n",
    "        \n",
    "    iterables = [datasets,all_N,outlier_methods,DEAs,FDRs,logFCs,quantity]\n",
    "    multi_cols = pd.MultiIndex.from_product(iterables, names=[\"Data\", \"N\", \"Out\", \"DEA\", \"FDR\", \"logFC\", \"Val\"])\n",
    "    combined = pd.DataFrame(columns=multi_cols)\n",
    "\n",
    "    ids = [] # id connecting samples from same dataset and cohort size, used for paired-sample testing pre vs. post outlier removal\n",
    "    for i, d in enumerate(datasets):\n",
    "        #if d not in [\"COAD\",\"PRAD\",\"BRCA\",\"THCA\",\"LIHC\"]: continue\n",
    "        isSynthetic = datasets[d][\"isSynthetic\"]\n",
    "        for j, N in enumerate(all_N):\n",
    "            k = i*len(all_N)+j \n",
    "            for out in outlier_methods:\n",
    "                for dea in DEAs:\n",
    "                    for fdr in FDRs:\n",
    "                        for logFC in logFCs:\n",
    "                            for quant in quantity:\n",
    "                                if \"_syn\" in quant:# and not isSynthetic: \n",
    "                                    continue\n",
    "                                col = (d,N,out,dea,fdr,logFC,quant)\n",
    "                                try:\n",
    "                                    combined.loc[0,col] = datasets[d][param_set][N][out][dea][quant][fdr][logFC]\n",
    "                                except KeyError:\n",
    "                                    if \"syn_hom\" in d and out != \"None\": pass\n",
    "                                    else: \n",
    "                                        print(d,N,param_set,out,dea,quant,fdr,logFC)\n",
    "                                        combined.loc[0,col] = datasets[d][param_set][N][out][dea][quant][fdr][logFC]\n",
    "                                        raise Exception(\"KeyError\")\n",
    "                                if quant == \"median_rep\": ids.append(k)\n",
    "\n",
    "    combined_td = combined.unstack().unstack(level=\"Val\").reset_index(level=[\"Data\",\"N\",\"Out\",\"DEA\",\"FDR\",\"logFC\"], drop=False)\n",
    "    combined_td[\"id\"] = ids\n",
    "    combined_td.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # For outlier_method == \"none\", no adjustment is necessary, hence copy unadjusted values\n",
    "    if include_adj:\n",
    "        none_ix = combined_td[combined_td[\"Out\"] == \"none\"].index # avoid setting with copy warning\n",
    "        combined_td.loc[none_ix,\"median_deg_adj\"] = combined_td.loc[none_ix,\"median_deg\"]\n",
    "        combined_td.loc[none_ix,\"median_rep_adj\"] = combined_td.loc[none_ix,\"median_rep\"]\n",
    "        combined_td.loc[none_ix,\"median_mcc_adj\"] = combined_td.loc[none_ix,\"median_mcc\"]\n",
    "        combined_td.loc[none_ix,\"median_mcc0_adj\"] = combined_td.loc[none_ix,\"median_mcc0\"]\n",
    "        combined_td.loc[none_ix,\"median_prec_adj\"] = combined_td.loc[none_ix,\"median_prec\"]\n",
    "        combined_td.loc[none_ix,\"median_prec0_adj\"] = combined_td.loc[none_ix,\"median_prec0\"]\n",
    "        combined_td.loc[none_ix,\"median_rec_adj\"] = combined_td.loc[none_ix,\"median_rec\"]\n",
    "\n",
    "\n",
    "    for clean in cleanout:\n",
    "        combined_td.loc[(combined_td[combined_td[\"Out\"] == clean]).index, \"Out\"] = cleanout[clean]\n",
    "    for clean in cleandea:\n",
    "        combined_td.loc[(combined_td[combined_td[\"DEA\"] == clean]).index, \"DEA\"] = cleandea[clean]\n",
    "    return combined_td.infer_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a7e256-7739-4de2-a0d4-0ac9c3805011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier_methods = [\"none\",\"jk\",\"pcah\"]\n",
    "# combined_td = tidy_df(\"p1\",[0,1])\n",
    "# outlier_methods = [\"none\"]\n",
    "# combined_td2 = tidy_df(\"p2\",[1])\n",
    "# combined_td.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cb0e55-27a5-4ea7-ac78-3d8f365985c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = {k: datasets[k] for k in (\"PRAD_unpaired\",\"BRCA_unpaired\",\"THCA_unpaired\",\"LIHC_unpaired\",\"LUAD_unpaired\",\"COAD_unpaired\",\"KIRC_unpaired\")}\n",
    "#d = {k: datasets[k] for k in (\"GIPF\",\"LWPL\",\"PRAD\",\"BRCA\",\"THCA\",\"LIHC\",\"LUAD\",\"COAD\",\"KIRC\")}\n",
    "#d = datasets\n",
    "\n",
    "#d = {k: datasets[k] for k in (\"PRAD\",\"BRCA\",\"THCA\",\"LIHC\",\"LUAD\",\"LUSC\",\"COAD\",\"KIRC\")} # p1, p2\n",
    "#d = {k: datasets[k] for k in [\"SBRCA1\",\"SBRCAs\",\"SBRCAl\",\"SBRCA5\",\"SBRCA2p\",\"SBRCA1p\"]}\n",
    "d = {k: datasets[k] for k in [\"SBRCA1\",\"SBRCAl\",\"SBRCA1p\",\"SBRCA10plv\", \"LWPL\",\"SNF2\"]} # p3 # \"LUMAB\"\n",
    "d = {k: datasets[k] for k in [\"HERLUMA\",\"BASHER\",\"BASLUMA\",\"BASLUMB\",\"GIPF\",\"LUMAB\",\"HERLUMB\"]} # p2c\n",
    "#d = {k: datasets[k] for k in [\"LUMAB\"]} # p1c\n",
    "#d = {k: datasets[k] for k in [\"SBRCA10psv\",\"SBRCA25psv\"]} # p35\n",
    "\n",
    "##### Post hoc fold change threshold\n",
    "\n",
    "# param_set = \"p1\"\n",
    "# combined_td = tidy_df(d, param_set, all_N=all_N, logFCs=[0,1], include_sd=False)\n",
    "\n",
    "# param_set = \"p1c\"\n",
    "# combined_td = tidy_df(d, param_set, all_N=all_N, logFCs=[0], include_sd=False)\n",
    "\n",
    "##### Formal fold change threshold\n",
    "\n",
    "#param_set = \"p2\"\n",
    "#combined_td = tidy_df(d, param_set, all_N=all_N, logFCs=[1])\n",
    "\n",
    "# param_set = \"p5\"\n",
    "# #combined_td = tidy_df(d, param_set, all_N=all_N,, logFCs=[2])\n",
    "\n",
    "#### Formal unpaired\n",
    "\n",
    "# param_set = \"p3\"\n",
    "# combined_td = tidy_df(d, param_set, all_N=all_N, logFCs=[1], include_sd=False)\n",
    "\n",
    "#param_set = \"p35\"\n",
    "#combined_td = tidy_df(d, param_set, all_N=all_N, logFCs=[0.5])\n",
    "\n",
    "#### Formal custom\n",
    "\n",
    "param_set = \"p2c\"\n",
    "combined_td = tidy_df(d, param_set, all_N=all_N, logFCs=[1], include_sd=False)\n",
    "\n",
    "\n",
    "##### Save\n",
    "\n",
    "combined_td.to_csv(Path(datapath, f\"multi/combined_td.{param_set}.csv\"))\n",
    "combined_td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbd2c15-5aac-428e-93c1-580f774b376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {k: datasets[k] for k in [\"GIPF\",\"LWPL\"]}\n",
    "param_set = \"p3\"\n",
    "combined_td_gse = tidy_df(d, param_set, logFCs=[1], all_N_alt=[3,7,15],include_sd=False)\n",
    "combined_td_gse.to_csv(Path(datapath, f\"multi/combined_td.gse.{param_set}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e63a815-9d48-4a87-a0c3-28f0eaa407d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_td2 = pd.read_csv(\"../data/multi/combined_td.p2.csv\", index_col=0) # Formal fold change thresholds, paired\n",
    "combined_td3 = pd.read_csv(\"../data/multi/combined_td.p3.csv\", index_col=0) # Formal fold change thresholds, unpaired"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480dd957-2f60-40ef-9993-1e15bff03d17",
   "metadata": {},
   "source": [
    "## Inspect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843472b9-8e71-45de-a67d-d5bec6710948",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"/storage/homefs/pd21v747/RNASeqReplicability/data/kidney/KIRC/KIRC_N15/KIRC_N15_0005/tab.none.edgerlrt.p3.feather\"\n",
    "f = \"/storage/homefs/pd21v747/RNASeqReplicability/data/GSETB/LWPL/LWPL_N3/LWPL_N3_0005/tab.none.edgerlrt.p3.feather\"\n",
    "f = \"/storage/homefs/pd21v747/RNASeqReplicability/data/prostate/PRAD/PRAD_N3/PRAD_N3_0007/tab.none.edgerlrt.p3.feather\"\n",
    "f = \"/storage/homefs/pd21v747/RNASeqReplicability/data/GSEPN/GIPF/GIPF_N3/LWPL_N3_0005/tab.none.edgerlrt.p3.feather\"\n",
    "f = \"/storage/homefs/pd21v747/RNASeqReplicability/data/lung2/LUSC/LUSC_N3/LUSC_N3_0007/tab.none.edgerlrt.p3.feather\"\n",
    "\n",
    "tab = open_table(f)\n",
    "sig = tab[tab[\"FDR\"]<0.05]\n",
    "print(len(sig))\n",
    "order = tab.sort_values(by=\"logFC\").index\n",
    "tab.loc[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8052c20-609a-491c-8384-ae1438921cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"/storage/homefs/pd21v747/RNASeqReplicability/data/GSEBP/BPLT/BPLT.edgerlrt.lfc0.csv\"\n",
    "f = \"/storage/homefs/pd21v747/RNASeqReplicability/data/GSEBP/BPLT/BPLT.edgerlrt.lfc0.csv\"\n",
    "f = \"/storage/homefs/pd21v747/RNASeqReplicability/data/prostate/PRAD/PRAD.edgerlrt.lfc0.csv\"\n",
    "f = \"/storage/homefs/pd21v747/RNASeqReplicability/data/lung2/LUSC/LUSC.edgerlrt.lfc0.csv\"\n",
    "truth = open_table(f)\n",
    "sig_truth = truth[truth[\"FDR\"]<0.05]\n",
    "print(len(sig_truth))\n",
    "truth.loc[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024f4d78-66f3-404b-b4f1-22cb899bfaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(truth[\"logFC\"],bins=30, range=(-3,3),alpha=0.5,label=\"Truth\")\n",
    "plt.hist(tab[\"logFC\"],bins=30, range=(-3,3),alpha=0.5,label=\"Cohort\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5b1e4c-3149-48ef-a51a-fe1d3796e9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=tab.loc[order,\"logFC\"], y=truth.loc[order,\"logFC\"], kind=\"reg\", line_kws=dict(color=\"r\"))\n",
    "plt.plot((-3,3),(-3,3),ls=\"--\",c=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed03c24-4e06-4c99-8130-5488b9200aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"combined_td3\" not in globals():\n",
    "    combined_td3 = pd.read_csv(\"../data/multi/combined_td.p3.csv\", index_col=0) # Unpaired formal lfc 1\n",
    "    #combined_td3[\"DEA\"] = combined_td3[\"DEA\"].str.replace(\"edgerqlf\",\"edgeR QLF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4dc3f6-e93f-411d-84d3-9eb3fb990d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_td3[\"DEA\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1062626-69b1-41c1-b67f-1513e9b81245",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_set = tidy_df({\"THCA\": datasets[\"THCA\"]} | {\"BRCA\": datasets[\"BRCA\"]} | {\"LUSC\":datasets[\"LUSC\"]} \n",
    "                   | {\"LIHC\":datasets[\"LIHC\"]} | {\"PRAD\":datasets[\"PRAD\"]}\n",
    "                    | {\"LUAD\":datasets[\"LUAD\"]} | {\"COAD\": datasets[\"COAD\"]} \n",
    "                   | {\"KIRC\":datasets[\"KIRC\"]}, \"p1\", logFCs=[0,1])\n",
    "\n",
    "#plot_set.to_csv(\"../data/multi/combined_td_wilcox.p1.csv\")\n",
    "#plot_set = tidy_df(datasets, \"p1\", [0,1])\n",
    "#plot_set = combined_td3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d445635-ce06-4836-b118-141997f808f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = pd.read_csv(\"/storage/homefs/pd21v747/RNASeqReplicability/data/breast_lumab/LUMAB/LUMAB.edgerqlf.lfc1.csv\", index_col=0)\n",
    "sigt = tab[tab[\"FDR\"]<0.05]\n",
    "len(sigt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c886ab7-27fb-47db-8582-c886187e824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "c = 4\n",
    "f = f\"/storage/homefs/pd21v747/RNASeqReplicability/data/breast_lumab/LUMAB/LUMAB_N{N}/LUMAB_N{N}_{c:04}/tab.none.edgerqlf.p3.feather\"\n",
    "\n",
    "df = open_table(f)\n",
    "sig = df[df[\"FDR\"]<0.05]\n",
    "print(len(sig))\n",
    "\n",
    "sig.index.intersection(sigt.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba7373-d457-469d-aaa0-ee4bf5f917ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc import get_grid_size\n",
    "\n",
    "plot_set = combined_td\n",
    "\n",
    "x = \"N\"\n",
    "y = \"median_prec_method\"\n",
    "y = \"median_rec\"\n",
    "\n",
    "a  = plot_set#[plot_set[\"logFC\"]==1]\n",
    "#a = a[a[\"Data\"].str.startswith(\"LUSC\")]\n",
    "a = a[a[\"FDR\"]==0.05]\n",
    "a = a[a[\"Out\"]==\"None\"]\n",
    "a = a[a[\"Data\"]==\"SNF2\"]\n",
    "\n",
    "hues = [\"Data\",\"logFC\",\"DEA\",\"Out\",\"N\",\"FDR\"]\n",
    "grid = (2,3)#get_grid_size(len(hues), k=0, fill=True)\n",
    "fig, ax = plt.subplots(grid[0],grid[1],figsize=(6*grid[0],3*grid[1]), sharex=True,sharey=True)\n",
    "ax=ax.flatten()\n",
    "cube = sns.cubehelix_palette(as_cmap=False, n_colors=5)\n",
    "\n",
    "for i, hue in enumerate(hues):\n",
    "    sns.scatterplot(data=a, x=x, y=y, hue=hue, ax=ax[i])\n",
    "    #ax[i].plot((0.8,1),(0.8,1),ls=\"--\")\n",
    "#for axx in ax: axx.invert_yaxis()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093b8a20-a20f-49b9-a372-aec8723bda77",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.7)\n",
    "\n",
    "fig, ax = plt.subplots(2,3,figsize = (24,16))\n",
    "ax = ax.flatten()\n",
    "\n",
    "plot_set = combined_td\n",
    "\n",
    "a = plot_set#[plot_set[\"logFC\"]==0]\n",
    "a = a[a[\"FDR\"]==0.05]\n",
    "a = a[a[\"Out\"]==\"None\"]\n",
    "\n",
    "sns.boxplot(data=a, x=\"N\", y=\"median_mcc\",hue=\"DEA\", ax=ax[0])\n",
    "sns.boxplot(data=a, x=\"N\", y=\"median_prec\",hue=\"DEA\", ax=ax[1])\n",
    "sns.boxplot(data=a, x=\"N\", y=\"median_rec\",hue=\"DEA\", ax=ax[2])\n",
    "\n",
    "\n",
    "plot_set2 = combined_td2\n",
    "a  = plot_set2[plot_set2[\"logFC\"]==1]\n",
    "a = a[a[\"FDR\"]==0.05]\n",
    "a = a[a[\"Out\"].isin([\"None\",np.nan])]\n",
    "\n",
    "sns.boxplot(data=a, x=\"N\", y=\"median_mcc0\",hue=\"DEA\", ax=ax[3])\n",
    "sns.boxplot(data=a, x=\"N\", y=\"median_prec\",hue=\"DEA\", ax=ax[4])\n",
    "sns.boxplot(data=a, x=\"N\", y=\"median_rec\",hue=\"DEA\", ax=ax[5])\n",
    "\n",
    "for i in range(len(ax)):\n",
    "    if i != 3:\n",
    "         ax[i].legend().remove()\n",
    "\n",
    "sns.set(font_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec20caba-f948-4b71-bae9-15c83de4d389",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.7)\n",
    "\n",
    "fig, ax = plt.subplots(2,3,figsize = (24,16))\n",
    "ax = ax.flatten()\n",
    "\n",
    "plot_set = combined_td\n",
    "\n",
    "a = plot_set[plot_set[\"logFC\"]==1]\n",
    "a = a[a[\"FDR\"]==0.05]\n",
    "a = a[a[\"Out\"]==\"None\"]\n",
    "\n",
    "sns.boxplot(data=a, x=\"N\", y=\"median_mcc\",hue=\"DEA\", ax=ax[0])\n",
    "sns.boxplot(data=a, x=\"N\", y=\"median_prec\",hue=\"DEA\", ax=ax[1])\n",
    "sns.boxplot(data=a, x=\"N\", y=\"median_rec\",hue=\"DEA\", ax=ax[2])\n",
    "\n",
    "\n",
    "plot_set2 = combined_td\n",
    "a  = plot_set2[plot_set2[\"logFC\"]==1]\n",
    "a = a[a[\"FDR\"]==0.05]\n",
    "a = a[a[\"Out\"].isin([\"None\",np.nan])]\n",
    "\n",
    "sns.boxplot(data=a, x=\"N\", y=\"median_mcc_syn\",hue=\"DEA\", ax=ax[3])\n",
    "sns.boxplot(data=a, x=\"N\", y=\"median_prec_syn\",hue=\"DEA\", ax=ax[4])\n",
    "sns.boxplot(data=a, x=\"N\", y=\"median_rec_syn\",hue=\"DEA\", ax=ax[5])\n",
    "\n",
    "for i in range(len(ax)):\n",
    "    if i != 3:\n",
    "         ax[i].legend().remove()\n",
    "\n",
    "sns.set(font_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ee631e-ed10-4b1b-ae9a-338c59b85b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_td[[c for c in combined_td.columns if combined_td[c].iloc[0] not in [\"None\",None]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6299a0d-7d8d-4a7f-898d-a327d0535017",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_set = pd.read_csv(\"../data/multi/combined_td.p3.csv\", index_col=0) # UNpaired, synthetic data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12630832-e813-482e-a6d1-b1f45b102145",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=2)\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "plot_set = combined_td\n",
    "plot_set[\"Out\"].fillna(\"None\", inplace=True)\n",
    "plot_set[\"Data\"].replace({\"SBRCAl\": \"Synthetic, 25% DEGs\",\n",
    "                          \"SBRCA1\": \"Synthetic, 10% DEGs\", \n",
    "                          \"SBRCAs\": \"Synthetic, 1% DEGs\"}, inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(4,3,figsize = (24,32), sharey=\"row\", sharex=True)\n",
    "sns.despine()\n",
    "ax = ax.flatten()\n",
    "\n",
    "\n",
    "a = plot_set[plot_set[\"logFC\"]==1]\n",
    "a = a[a[\"FDR\"]==0.05]\n",
    "#a = a[a[\"DEA\"]==\"edgerqlf\"]\n",
    "#a = a[a[\"DEA\"]==\"edgeR LRT\"]\n",
    "a = a[a[\"Out\"]==\"None\"]\n",
    "\n",
    "m = np.array(range(12)).reshape((4,3)).T.flatten() # transpose plot grid\n",
    "deas = [\"DESeq2\",\"edgerqlf\",\"edgeR LRT\"]\n",
    "for i, dea in enumerate(deas):\n",
    "    b = a[a[\"DEA\"]==dea]\n",
    "    sns.lineplot(data=b, x=\"N\", y=\"median_mcc\",hue=\"Data\", marker=\"o\", ms=20, ax=ax[m[0+i*4]])#ax=ax[0+i*3])\n",
    "    sns.lineplot(data=b, x=\"N\", y=\"median_prec\",hue=\"Data\", marker=\"o\", ms=20, ax=ax[m[1+i*4]])#ax=ax[1+i*3])\n",
    "    sns.lineplot(data=b, x=\"N\", y=\"median_rec\",hue=\"Data\", marker=\"o\", ms=20, ax=ax[m[2+i*4]])#ax=ax[2+i*3])\n",
    "    sns.lineplot(data=b, x=\"N\", y=\"median_rep\",hue=\"Data\", marker=\"o\", ms=20, ax=ax[m[3+i*4]])#ax=ax[3+i*3])\n",
    "    ax[i].set(title=prdea[dea] if \"prdea\" in globals() and dea in prdea else dea)\n",
    "\n",
    "ax[0].set_ylabel(\"Median MCC\")\n",
    "ax[3].set_ylabel(\"Median Precision\")\n",
    "ax[6].set_ylabel(\"Median Recall\")\n",
    "ax[9].set_ylabel(\"Median Replicability\")\n",
    "\n",
    "for i, a in enumerate(ax):\n",
    "    a.legend(title=None)\n",
    "    if i % 3 == 0:\n",
    "        #a.set_xticks(ticks=all_N, labels=all_N)\n",
    "        a.set_xticks(ticks=range(3,16), labels=range(3,16))\n",
    "        \n",
    "fig.tight_layout()\n",
    "figpath = f\"../figures/sfig28_simulated_data_lfc1.pdf\"\n",
    "fig.savefig(figpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1d1e9f-4a84-493b-9890-faff29cd8107",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.7)\n",
    "\n",
    "fig, ax = plt.subplots(2,3,figsize = (24,16))\n",
    "ax = ax.flatten()\n",
    "\n",
    "plot_set = combined_td\n",
    "\n",
    "a = plot_set#[plot_set[\"logFC\"]==0]\n",
    "a = a[a[\"FDR\"]==0.05]\n",
    "a = a[a[\"Out\"]==\"None\"]\n",
    "\n",
    "sns.boxplot(data=a, x=\"N\", y=\"median_mcc\",hue=\"DEA\", ax=ax[0])\n",
    "sns.boxplot(data=a, x=\"N\", y=\"median_prec\",hue=\"DEA\", ax=ax[1])\n",
    "sns.boxplot(data=a, x=\"N\", y=\"median_rec\",hue=\"DEA\", ax=ax[2])\n",
    "\n",
    "\n",
    "plot_set2 = combined_td2\n",
    "a  = plot_set2[plot_set2[\"logFC\"]==1]\n",
    "a = a[a[\"FDR\"]==0.05]\n",
    "a = a[a[\"Out\"].isin([\"None\",np.nan])]\n",
    "\n",
    "sns.boxplot(data=a, x=\"N\", y=\"median_mcc\",hue=\"DEA\", ax=ax[3])\n",
    "sns.boxplot(data=a, x=\"N\", y=\"median_prec\",hue=\"DEA\", ax=ax[4])\n",
    "sns.boxplot(data=a, x=\"N\", y=\"median_rec\",hue=\"DEA\", ax=ax[5])\n",
    "\n",
    "for i in range(len(ax)):\n",
    "    if i != 3:\n",
    "         ax[i].legend().remove()\n",
    "\n",
    "sns.set(font_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28125dd9-3746-4c37-b1a8-05857bf132f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=combined_td\n",
    "c=c[(c[\"FDR\"]==0.05)]\n",
    "c\n",
    "\n",
    "# Function to calculate weighted mean and CI for each sample size\n",
    "def calculate_weighted_mean(group, col):\n",
    "    vals = group[col].values\n",
    "    sems = group[col+(\"_sd\" if \"rep\" in col else \"_sem\")].values\n",
    "    \n",
    "    # Calculate variances from SEMs\n",
    "    variances = sems ** 2\n",
    "    \n",
    "    # Calculate weights as the inverse of variances\n",
    "    weights = 1 / variances\n",
    "    \n",
    "    # Calculate weighted mean recall\n",
    "    weighted_mean = np.sum(weights * vals) / np.sum(weights)\n",
    "    \n",
    "    # Calculate the variance of the weighted mean\n",
    "    summary_variance = 1 / np.sum(weights)\n",
    "    \n",
    "    # Calculate the summary CI (95% CI, using 1.96)\n",
    "    summary_CI = 1.96 * np.sqrt(summary_variance)\n",
    "    \n",
    "    return pd.Series({\n",
    "        f\"{col}\": weighted_mean,\n",
    "        \"CI\": summary_CI\n",
    "    })\n",
    "\n",
    "val = \"median_deg\"\n",
    "# Group by \"Sample Size\" and apply the function\n",
    "result = c.groupby([\"DEA\",\"N\"]).apply(lambda x: calculate_weighted_mean(x, val)).reset_index()\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7affea42-570d-45fe-8d19-57f80f38ae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dea in enumerate(set(result[\"DEA\"])):\n",
    "    r = result\n",
    "    r = r[r[\"DEA\"]==dea]\n",
    "\n",
    "    lower_bound = r[val] - r[\"CI\"]\n",
    "    upper_bound = r[val] + r[\"CI\"]\n",
    "    \n",
    "    # Clip the bounds to [0, 1]\n",
    "    lower_bound_clipped = np.clip(lower_bound, 0, (1 if \"deg\" not in val else np.inf))\n",
    "    upper_bound_clipped = np.clip(upper_bound, 0, (1 if \"deg\" not in val else np.inf))\n",
    "    \n",
    "    # Calculate the clipped yerr for plt.errorbar\n",
    "    yerr_clipped = [r[val] - lower_bound_clipped, upper_bound_clipped - r[val]]\n",
    "\n",
    "\n",
    "    offset = -0.3+i*0.3\n",
    "    plt.errorbar(x=r[\"N\"]+offset, y=r[val], \n",
    "                 #yerr=r[\"CI\"],\n",
    "                 #yerr=[r[\"CI\"],r[\"CI\"] - np.max(0,r[val])], \n",
    "                 yerr = yerr_clipped,\n",
    "                 markersize=10,fmt=\"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707c15c0-4db7-41c3-b0ad-33358adcc56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = result\n",
    "r = r[r[\"DEA\"]==\"DESeq2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cfbe8b-4305-4918-a2ac-c6732b6f2b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "def f(x):\n",
    "    print(x)\n",
    "    return(0,0)\n",
    "sns.pointplot(x=\"N\", y=\"Weighted Mean median_prec\", data=r, errorbar=lambda x: f(x))\n",
    "plt.ylabel(\"Weighted Mean Recall\")\n",
    "plt.title(\"Weighted Mean Recall with Summary CI by Sample Size\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22174287-4459-4544-846f-1015837e28f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"PRAD\"][\"p1\"][15][\"none\"][\"wilcox\"][\"median_deg\"][0.05][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcb59eb-60cb-4f66-a713-690d6f901bdd",
   "metadata": {},
   "source": [
    "# Enrichment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a144b136-7267-4925-a0ff-fc5162605f8a",
   "metadata": {},
   "source": [
    "## Ground truth definition\n",
    "\n",
    "Run GSEA on ground truth logFC estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99e6a7d-12fd-4833-8568-a19367cb53c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enrichment import prepare_gsea, run_gseapy_libraries, convert_ids_biomart, find_conv_table_all, clean_tab\n",
    "\n",
    "libraries = [\n",
    "  \"GO_Biological_Process_2021\",\n",
    "  \"KEGG_2021_Human\"\n",
    "  # \"MSigDB_Oncogenic_Signatures\",\n",
    "  # \"Cancer_Cell_Line_Encyclopedia\",\n",
    "  # \"GO_Molecular_Function_2021\",\n",
    "  # \"GeneSigDB\",\n",
    "  # \"GO_Cellular_Component_2021\",\n",
    "  # \"MSigDB_Hallmark_2020\",\n",
    "  # \"MSigDB_Computational\",\n",
    "  # \"WikiPathway_2021_Human\"\n",
    "]\n",
    "\n",
    "#cancers = [\"PRAD\",\"COAD\",\"BRCA\",\"KIRC\",\"LIHC\",\"LUAD\",\"THCA\",\"LUSC\"]\n",
    "\n",
    "datasetsfile = Path(datapath, \"multi/datasets.txt\")\n",
    "with open(datasetsfile, \"rb\") as f:\n",
    "    datasets = pickle.load(f)\n",
    "\n",
    "# Create table for converting ENSG to Gene Symbols and Entrez IDs\n",
    "conv_file = Path(datapath, \"multi/conv_table.csv\")\n",
    "find_conv_table_all(datasets, conv_file, overwrite=False)\n",
    "conv_table = pd.read_csv(conv_file, index_col=0)\n",
    "conv_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d33dec-e7f3-4d8c-97c8-4fe3a6a95d92",
   "metadata": {},
   "source": [
    "### GSEApy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2faeeeb-98fa-4024-a428-1d29f558a01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enrichment import prepare_gsea, run_gseapy_libraries, convert_ids_biomart, find_conv_table_all, clean_tab\n",
    "from process import signal_to_noise\n",
    "from DEA import normalize_counts\n",
    "            \n",
    "overwrite_all_gsea = False\n",
    "\n",
    "# lfc estimates are similar between edegR and deseq2, so we focus on one tool\n",
    "method = \"deseq2\"\n",
    "\n",
    "for k, data in enumerate(datasets):\n",
    "    \n",
    "    if datasets[data][\"isSynthetic\"]: continue\n",
    "\n",
    "    if data == \"SNF2\": \n",
    "        continue # skipping non-human data (yeast)\n",
    "\n",
    "    outpath = datasets[data][\"outpath\"]\n",
    "    gseapath = f\"{outpath}/gsea\"   \n",
    "\n",
    "    #os.system(f\"mkdir {gseapath}\")\n",
    "\n",
    "    ### Load ground truth lfc estimates\n",
    "    #tab = pd.read_csv(f\"{outpath}/truth_lfc.csv\", index_col=0) # truth based on methods consensus\n",
    "    tab = pd.read_csv(f\"{outpath}/{data}.{method}.lfc0.csv\", index_col=0) # method-specific truth\n",
    "\n",
    "    tab.dropna(inplace=True)\n",
    "    \n",
    "    ### Calcualte S2N\n",
    "    #counts = pd.read_csv(datasets[data][\"datapath\"], index_col=0)\n",
    "    #counts = normalize_counts(counts)\n",
    "    #tab.loc[counts.index.intersection(tab.index), \"|S2N|\"] = signal_to_noise(counts)\n",
    "\n",
    "    if tab.index[0].startswith(\"ENSG\"):\n",
    "        tab_cleaned = tab.loc[tab.index.intersection(conv_table.index)]\n",
    "        tab_cleaned[\"Symbol\"] = conv_table.loc[tab_cleaned.index,\"Symbol\"]\n",
    "    else: # assume symbol\n",
    "        tab_cleaned = tab.loc[tab.index.intersection(conv_table.set_index(\"Symbol\").index)]\n",
    "        tab_cleaned[\"Symbol\"] = conv_table.set_index(\"Symbol\").loc[tab_cleaned.index].index\n",
    "        \n",
    "    logging.info(f\"{data}\\nOriginal tab: {len(tab)} genes\\nCleaned tab: {len(tab_cleaned)} genes\\n\")\n",
    "\n",
    "    with Timer(name=\"context manager\"):        \n",
    "        run_gseapy_libraries(tab_cleaned, gseapath, libraries, overwrite_all_gsea, permutation_num=1000, save_full_results=True, ranking=\"logFC\", min_size=15, max_size=500, file_id=method)\n",
    "    \n",
    "        #run_gseapy_libraries(tab_cleaned, gseapath, libraries, overwrite_all_gsea, permutation_num=1000, save_full_results=True, ranking=\"|S2N|\", min_size=15, max_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1f340a-b9ff-4f2c-be32-435b2592b6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect results\n",
    "\n",
    "gsea_out = f\"{gseapath}/gseapy.logFC.{libraries[1]}.{method}.txt\"\n",
    "with open(gsea_out, \"rb\") as fp:\n",
    "    gsea_results = pickle.load(fp)\n",
    "    \n",
    "print(gsea_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8f3767-d1a5-48f5-93f2-3a9e13d21bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gseapy\n",
    "\n",
    "terms = gsea_results.res2d.sort_values(by=\"FDR q-val\")\n",
    "display(gsea_results.res2d.head(10))\n",
    "top_term = terms[\"Term\"][0]\n",
    "print(f\"Total gene sets tested: {len(terms)}\")\n",
    "print(f\"Significant gene sets at 5% FDR: {len(terms[terms['FDR q-val']<0.05])}\\n\")\n",
    "gseapy.gseaplot(rank_metric=gsea_results.ranking, term=top_term, **gsea_results.results[top_term])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36953680-c75a-44e0-842b-a47a7e2decae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make results dictionary\n",
    "\n",
    "FDR = 0.05\n",
    "rankings = [\"logFC\"]#, \"|S2N|\"]\n",
    "gsea_dict = {data: {\"truth\": {\"gseapy\": {rnk: {lib: {} for lib in libraries} for rnk in rankings}}} for data in datasets if not datasets[data][\"isSynthetic\"] and data!=\"SNF2\"}\n",
    "\n",
    "for data in datasets:\n",
    "    \n",
    "    outpath = datasets[data][\"outpath\"]\n",
    "    gseapath = f\"{outpath}/gsea\"\n",
    "    \n",
    "    for rnk in rankings:\n",
    "    \n",
    "        for library in libraries:\n",
    "\n",
    "            reportfile = f\"{gseapath}/gseapy.{rnk}.{library}.{method}.feather\"\n",
    "            try:\n",
    "                terms = open_table(reportfile).sort_values(by=\"FDR\")\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "            gsea_dict[data][\"truth\"][\"gseapy\"][rnk][library] = terms\n",
    "            print(data, library, rnk, len(terms), len(terms[terms['FDR']<FDR]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854a4297-ae85-40f0-9009-178cc63c6804",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### clusterProfiler ORA  (derpecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fe3328-cb7d-4923-bea0-f940961f8e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enrichment import run_clusterORA, convert_ensg\n",
    "\n",
    "overwrite_clusterORA = False\n",
    "FDRs = [0.05]\n",
    "logFCs = [0,1] # formal lfc threshold\n",
    "\n",
    "ORA_kwargs = {\"FDRs\": [0.05], \"logFCs\": [0,1], \"minGSSize\": 15, \"maxGSSize\": 500,\n",
    "               \"use_internal_data\": True, \"internal_data_path\": \"../data/clusterORA/KEGG_DATA.RData\"}\n",
    "\n",
    "for k, data in enumerate(datasets):\n",
    "    print(data)\n",
    "    \n",
    "    outpath = datasets[data][\"outpath\"]\n",
    "    gseapath = f\"{outpath}/gsea\"\n",
    "    #os.system(f\"mkdir {gseapath}\")\n",
    "    universe = pd.read_csv(f\"{outpath}/{data}.csv\", usecols=[\"Unnamed: 0\"], index_col=0)\n",
    "    universe = list(convert_ensg(universe,conv_table,target=\"Entrez\").index)\n",
    "\n",
    "    for fdr in FDRs:\n",
    "        for logFC in logFCs:\n",
    "            degs = pd.read_csv(f\"{outpath}/truth.fdr{fdr}.post_lfc{logFC}.lfc{logFC}.csv\", usecols=[\"Unnamed: 0\"], index_col=0)\n",
    "            degs = list(convert_ensg(degs,conv_table,target=\"Entrez\").index)\n",
    "    \n",
    "            s = \"_lfc\" if logFC > 0 else \"\"\n",
    "            prefix = f\"{gseapath}/clusterORA{s}.fdr{fdr}.post_lfc{logFC}.lfc{logFC}\"\n",
    "            run_clusterORA(degs, universe, file_id=\"\", go_ont=\"BP\", prefix=prefix, overwrite=overwrite_clusterORA, **ORA_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe458879-8df2-4943-8399-ca7e2615afe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in datasets:\n",
    "    \n",
    "    outpath = datasets[data][\"outpath\"]\n",
    "    gseapath = f\"{outpath}/gsea\"\n",
    "        \n",
    "    for fdr in FDRs:\n",
    "        for logFC in logFCs:\n",
    "            \n",
    "            s = \"_lfc\" if logFC > 0 else \"\"\n",
    "            method = f\"clusterORA{s}.fdr{fdr}.post_lfc{logFC}.lfc{logFC}\"\n",
    "            gsea_dict[data][\"truth\"][method] = {lib: None for lib in libraries}\n",
    "            \n",
    "            for library in libraries:\n",
    "                #if \"KEGG\" not in library: continue\n",
    "                    \n",
    "                reportfile = f\"{gseapath}/{method}.{library}.feather\"         \n",
    "                terms = open_table(reportfile).sort_values(by=\"FDR\")\n",
    "                \n",
    "                ## for KEGG: switch term ID and description for index\n",
    "                if terms.index[0].startswith(\"hsa\") and \"Term\" in terms:\n",
    "                    terms[\"Term ID\"] = terms.index\n",
    "                    terms = terms.set_index(\"Term\")\n",
    "                \n",
    "                gsea_dict[data][\"truth\"][method][library] = terms\n",
    "                print(data, method, library, len(terms), len(terms[terms['FDR']<FDR]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafb40bf-9937-46cc-a836-9a7dcc2d565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For KEGG ORA,set term name as index instead of term ID\n",
    "\n",
    "for site in sites:\n",
    "    for fdr in FDRs:\n",
    "        for lfc in logFCs:\n",
    "            s = \"_lfc\" if lfc > 0 else \"\"\n",
    "            method = f\"clusterORA{s}.fdr{fdr}.post_lfc{lfc}.lfc{lfc}\"\n",
    "            f = f\"../data/{site}/{sites[site]}/gsea/{method}.KEGG_2021_Human.feather\"\n",
    "            t=open_table(f)\n",
    "            if \"Term ID\" in t or t.index.name == \"Term\": continue\n",
    "            t[\"Term ID\"] = t.index\n",
    "            t.set_index(\"Term\",inplace=True)\n",
    "            t = t.reset_index()\n",
    "            t.to_feather(f)\n",
    "            display(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29ac9ea-b871-4623-b775-90b18c96f5a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Common terms (derpecated)\n",
    "\n",
    "We will define an additional, common ground truth, restricted to terms to terms that are shared between GSEApy, clusterProfiler ORA and all data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a5d6e2-4829-4938-a411-f527d5d1c5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_terms():\n",
    "    common_kegg, common_gobp = set(), set()\n",
    "    for data in gsea_dict:\n",
    "        for lfc in [0,1]:\n",
    "            s = \"_lfc\" if lfc == 1 else \"\"\n",
    "            # KEGG\n",
    "            gseapy_terms = gsea_dict[data][\"truth\"][\"gseapy\"][\"logFC\"][\"KEGG_2021_Human\"].index\n",
    "            clusterORA_terms = set(gsea_dict[data][\"truth\"][f\"clusterORA{s}.fdr0.05.post_lfc{lfc}.lfc{lfc}\"][\"KEGG_2021_Human\"].index)\n",
    "\n",
    "            if len(common_kegg)<1: common_kegg = gseapy_terms.intersection(clusterORA_terms)\n",
    "            else: common_kegg = common_kegg.intersection(gseapy_terms).intersection(clusterORA_terms)\n",
    "\n",
    "            # GO BP\n",
    "            gseapy_terms = gsea_dict[data][\"truth\"][\"gseapy\"][\"logFC\"][\"GO_Biological_Process_2021\"].index\n",
    "            clusterORA_terms = gsea_dict[data][\"truth\"][f\"clusterORA{s}.fdr0.05.post_lfc{lfc}.lfc{lfc}\"][\"GO_Biological_Process_2021\"].index    \n",
    "\n",
    "            if len(common_gobp)<1: common_gobp = gseapy_terms.intersection(clusterORA_terms)\n",
    "            else: common_gobp = common_gobp.intersection(gseapy_terms).intersection(clusterORA_terms)\n",
    "\n",
    "    return common_kegg, common_gobp\n",
    "    \n",
    "file_gobp = Path(\"../data/multi/common_gobp.txt\")\n",
    "file_kegg = Path(\"../data/multi/common_kegg.txt\")\n",
    "if (not file_gobp.is_file() or not file_kegg.is_file()):\n",
    "    common_kegg, common_gobp = get_common_terms()\n",
    "    pickler(common_gobp, file_gobp)\n",
    "    pickler(common_kegg, file_kegg)\n",
    "else:\n",
    "    with open(file_gobp, \"rb\") as f:\n",
    "        common_gobp = pickle.load(f)\n",
    "    with open(file_kegg, \"rb\") as f:\n",
    "        common_kegg = pickle.load(f)\n",
    "        \n",
    "print(\"KEGG Terms:\", len(common_kegg))\n",
    "print(\"GO BP Terms:\", len(common_gobp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba96f9dc-ed8d-484f-affb-4f332165e117",
   "metadata": {},
   "source": [
    "As we have restricted the number of terms (hypotheses), we need to recalculate the adjusted pvalues for appropriate FDR control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afbd45c-c38c-4f7c-adbe-6dfcab90f493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "redo_common_fdr = True\n",
    "FDRs = [0.05]\n",
    "logFCs = [0,1]\n",
    "rankings = [\"logFC\", \"|S2N|\"]\n",
    "\n",
    "if redo_common_fdr:\n",
    "\n",
    "    for data in datasets:\n",
    "\n",
    "        outpath = datasets[data][\"outpath\"]\n",
    "        gseapath = f\"{outpath}/gsea\"\n",
    "        \n",
    "        for library in libraries:\n",
    "            \n",
    "            common = common_gobp if library == \"GO_Biological_Process_2021\" else common_kegg\n",
    "    \n",
    "            ### GSEA\n",
    "            for rnk in rankings:\n",
    "                suffix = \"\" if rnk == \"logFC\" else \"_s2n\"\n",
    "                reportfile = f\"{gseapath}/gseapy{suffix}.{library}.feather\"\n",
    "                terms = open_table(reportfile).sort_values(by=\"FDR\")\n",
    "                terms[\"FDR.common\"] = np.full(len(terms),np.nan)\n",
    "                terms.loc[common, \"FDR.common\"] = multipletests(terms.loc[common, \"NOM p-val\"], method=\"fdr_bh\")[1]\n",
    "                terms.reset_index().to_feather(reportfile)\n",
    "\n",
    "\n",
    "            ### ORA\n",
    "            for fdr in FDRs:\n",
    "                for logFC in logFCs:\n",
    "                    s = \"_lfc\" if logFC > 0 else \"\"\n",
    "                    method = f\"clusterORA{s}.fdr{fdr}.post_lfc{logFC}.lfc{logFC}\"\n",
    "\n",
    "                    reportfile = f\"{gseapath}/{method}.{library}.feather\"         \n",
    "                    terms = open_table(reportfile).sort_values(by=\"FDR\")\n",
    "                    #assert terms.index.duplicated().sum() == 0\n",
    "                    terms[\"FDR.common\"] = np.full(len(terms),np.nan)\n",
    "                    \n",
    "                    if terms.index[0].startswith(\"hsa\"):\n",
    "                        terms[\"hsa\"] = terms.index\n",
    "                        terms.set_index(\"Term\", inplace=True)\n",
    "                    \n",
    "                    ix = common #if library == \"GO_Biological_Process_2021\" else terms[terms[\"Term\"].isin(common)].index\n",
    "                    print(data,library,fdr,logFC,method)\n",
    "                    terms.loc[ix, \"FDR.common\"] = multipletests(terms.loc[ix, \"pvalue\"], method=\"fdr_bh\")[1]\n",
    "                    terms.reset_index().to_feather(reportfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b738f-1675-46ee-8629-5336a7e0e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsea_methods = ['gseapy', 'gseapy_s2n',\n",
    "               'clusterORA.fdr0.05.post_lfc0.lfc0',\n",
    "               'clusterORA_lfc.fdr0.05.post_lfc1.lfc1']\n",
    "\n",
    "\n",
    "from process import get_n_gsea_truth\n",
    "FDRs=[0.05]\n",
    "gsea_param_set = \"p1\"\n",
    "gsea_truth = {data: {out: {dea: {gsea: {lib: {\"truth\"+mode: {fdr: None for fdr in FDRs} for mode in [\"\",\"_common\"]} for lib in libraries} for gsea in gsea_methods} for dea in DEA_methods} for out in outlier_methods} for data in datasets if \"syn\" not in data}\n",
    "\n",
    "for data in datasets:\n",
    "    print(data)\n",
    "    outpath_d = datasets[data][\"outpath\"]\n",
    "    outname_d = str(outpath_d).split(\"/\")[-1]\n",
    "    gsea_truth[data] = get_n_gsea_truth(gsea_truth[data], outpath_d, outname_d, all_N, DEA_methods, outlier_methods, gsea_methods, libraries, FDRs, gsea_param_set, overwrite=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2063bb1e-858d-4193-8cc6-4499f2c6f3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsea_datasets = {sites[s]: {} for s in sites if sites[s] in cancers}\n",
    "\n",
    "DEAs = DEA_methods\n",
    "FDRs = [0.05]\n",
    "all_N=[3]#,5,7,9,15]\n",
    "    \n",
    "quantity = [\"truth\"]\n",
    "quantity += [q+\"_common\" for q in quantity]\n",
    "\n",
    "iterables = [gsea_datasets,outlier_methods,DEAs,gsea_methods,libraries,FDRs,quantity]\n",
    "multi_cols = pd.MultiIndex.from_product(iterables, names=[\"Data\", \"Out\", \"DEA\", \"Enrichment\", \"Library\", \"FDR\", \"Val\"])\n",
    "gsea_truth_df = pd.DataFrame(columns=multi_cols)\n",
    "\n",
    "ids = [] # id connecting samples from same dataset and cohort size, used for paired-sample testing pre vs. post outlier removal\n",
    "for d in gsea_datasets:\n",
    "    for out in outlier_methods:\n",
    "        for dea in DEAs:\n",
    "            for gsea in gsea_methods:\n",
    "                #if dea != \"edger\" and gsea_methods == \"gsea_s2n\": continue\n",
    "                for fdr in FDRs:\n",
    "                    for lib in libraries:\n",
    "                        for quant in quantity:\n",
    "                            #print(d,N,out,dea,fdr)\n",
    "                            col = (d,out,dea,gsea,lib,fdr,quant)\n",
    "                            if dea != \"edgerqlf\" and \"s2n\" in gsea: dea_source = \"edgerqlf\"\n",
    "                            else: dea_source = dea\n",
    "                            gsea_truth_df.loc[0,col] = gsea_truth[d][out][dea_source][gsea][lib][quant][fdr]\n",
    "                            \n",
    "gsea_truth_df = gsea_truth_df.unstack().unstack(level=\"Val\").reset_index(level=[\"Data\",\"Out\",\"DEA\",\"Enrichment\",\"Library\",\"FDR\"], drop=False)\n",
    "gsea_truth_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# For outlier_method == \"none\", no adjustment is necessary, hence copy unadjusted values\n",
    "#none_ix = combined_gsea_td[combined_gsea_td[\"Out\"] == \"none\"].index # avoid setting with copy warning\n",
    "#combined_gsea_td.loc[none_ix,\"median_terms_adj\"] = combined_gsea_td.loc[none_ix,\"median_terms\"]\n",
    "#combined_gsea_td.loc[none_ix,\"median_rep_adj\"] = combined_gsea_td.loc[none_ix,\"median_rep\"]\n",
    "\n",
    "for clean in cleanout:\n",
    "    gsea_truth_df.loc[(gsea_truth_df[gsea_truth_df[\"Out\"] == clean]).index, \"Out\"] = cleanout[clean]\n",
    "for clean in cleandea:\n",
    "    gsea_truth_df.loc[(gsea_truth_df[gsea_truth_df[\"DEA\"] == clean]).index, \"DEA\"] = cleandea[clean]\n",
    "gsea_truth_df.to_csv(f\"../data/multi/gsea_truth_df.csv\")\n",
    "gsea_truth_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a35d57-76e3-4e07-b1ec-18959c8681a6",
   "metadata": {},
   "source": [
    "## Send batch jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f45a598-9b8b-4c71-88c0-a02200243637",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = \"LUAD\"\n",
    "outpath = datasets[selected_data][\"outpath\"]\n",
    "outname = outpath.name\n",
    "outpath, outname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed3f8dc-da22-45f1-89f2-1ce6993427a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "importlib.reload(sys.modules[\"enrichment\"])\n",
    "importlib.reload(sys.modules[\"ubelix\"])\n",
    "\n",
    "from ubelix import run_gsea_batch\n",
    "    \n",
    "gsea_script_path = \"../scripts/send_gsea_batch.sh\"\n",
    "\n",
    "n_cohorts = 20\n",
    "all_N = [3,7,15]#,5,5,7,9,15]\n",
    "gsea_methods = [\"gseapy\"] #[\"clusterORA_lfc\",\"clusterORA\",\"gseapy\",\"gseapy_s2n\"]\n",
    "outlier_methods = [\"none\"] #,\"jk\"] #########,\"pcah\"]\n",
    "DEA_methods = [\"deseq2\"] #[\"edgerqlf\",\"edgerlrt\"] ## reminder: do only edgerqlf for gsea S2N\n",
    "libraries = ['GO_Biological_Process_2021', 'KEGG_2021_Human']\n",
    "\n",
    "gsea_config_params = {\n",
    "    \n",
    "    \"gsea_param_set\": \"p1\", # id for this set of parameters\n",
    "    \"dea_param_set\": \"p1\",\n",
    "    \"dea_param_set_lfc\": \"p2\",\n",
    "    \n",
    "    \"overwrite\": False, # overwrite existing tabs\n",
    "    \"data\": str(outpath) + \"/\" + outname + \".csv\",\n",
    "    \"outpath\": str(outpath),\n",
    "    \"outname\": outname,\n",
    "    \n",
    "    \"DEA_methods\": DEA_methods,\n",
    "    \"outlier_methods\": outlier_methods,\n",
    "    \"gsea_methods\": gsea_methods,\n",
    "    \"libraries\": libraries,\n",
    "    \"rankings\": [\"logFC\"],\n",
    "    \n",
    "    \"gsea_kwargs\":  {\n",
    "                    \"gseapy\": {\"permutation_num\": 200, \"save_full_results\": False, \"threads\": 4, \"min_size\": 15, \"max_size\": 500}\n",
    "    }\n",
    "}\n",
    "\n",
    "gsea_config_params2 = {\n",
    "    \n",
    "    \"gsea_param_set\": \"p2\", # id for this set of parameters\n",
    "    \"dea_param_set\": \"p1\",\n",
    "    \"dea_param_set_lfc\": \"p2\",\n",
    "    \n",
    "    \"overwrite\": False, # overwrite existing tabs\n",
    "    \"data\": str(outpath) + \"/\" + outname + \".csv\",\n",
    "    \"outpath\": str(outpath),\n",
    "    \"outname\": outname,\n",
    "    \n",
    "    \"DEA_methods\": DEA_methods,\n",
    "    \"outlier_methods\": outlier_methods,\n",
    "    \"gsea_methods\": gsea_methods,\n",
    "    \"libraries\": libraries,\n",
    "    \"rankings\": [\"logFC\"],\n",
    "    \n",
    "    \"gsea_kwargs\":  {\n",
    "                    \"gseapy\": {\"permutation_num\": 200, \"save_full_results\": False, \"threads\": 4, \"min_size\": 15, \"max_size\": 500}\n",
    "    }\n",
    "}\n",
    "\n",
    "gsea_config_params2c = gsea_config_params2.copy()\n",
    "gsea_config_params2c[\"dea_param_set_lfc\"] = \"2pc\"\n",
    "\n",
    "mode = \"send jobs\"\n",
    "mode = \"test main\"\n",
    "mode = \"just testing\"\n",
    "sleep_seconds = 0\n",
    "\n",
    "gsea_config_params = gsea_config_params2\n",
    "\n",
    "run_gsea_batch(gsea_config_params, all_N, n_cohorts, libraries, gsea_script_path=gsea_script_path, mode=mode, sleep_seconds=sleep_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49c8bd2-101e-4903-bda9-a82e7f63f427",
   "metadata": {},
   "outputs": [],
   "source": [
    "!squeue -u pd21v747"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf1efd1-aef6-42f8-93cd-157a34b116a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = \"THCA\"\n",
    "# N = 3\n",
    "# library = libraries[0]\n",
    "# cohort = 1\n",
    "# dea = \"edgerqlf\"\n",
    "# out = \"none\"\n",
    "# gsea_method = \"clusterORA_lfc.fdr0.05.post_lfc1.lfc1\"\n",
    "# param_set = \"p1\"\n",
    "# site = datasets[data][\"site\"]\n",
    "# p=f\"../data/{site}/{data}/{data}_N{N}/{data}_N{N}_{cohort:04}/gsea/{gsea_method}.{library}.{dea}.{out}.{param_set}.feather\"\n",
    "# t=open_table(p)\n",
    "# print(len(t[t[\"FDR\"]<0.05]))\n",
    "# t.sort_values(by=\"FDR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa320d0-62d3-475d-b2c8-b7099e6bbcc8",
   "metadata": {},
   "source": [
    "## Process jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d574df-c15a-4f6c-ac88-8a4337e433e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "importlib.reload(sys.modules[\"process\"])\n",
    "\n",
    "from process import gsea_process_pipeline\n",
    "gFDRs = [0.05]\n",
    "\n",
    "#gsea_methods = [\"clusterORA_lfc.fdr0.05.post_lfc1.lfc1\", \"gseapy\",\"clusterORA.fdr0.05.post_lfc0.lfc0\", \"gseapy_s2n\", \"clusterORA.fdr0.05.post_lfc1.lfc0\"]\n",
    "#DEA_methods = [\"edgerqlf\", \"deseq2\", \"edgerlrt\"]\n",
    "#gsea_process_pipeline(outpath, outname, all_N, DEA_methods, outlier_methods, gsea_methods, libraries, gFDRs, \"p1\", overwrite=1, overwrite_merged=0, n_cohorts=50, calculate_common=1)\n",
    "\n",
    "gsea_methods = [\"gseapy\"]\n",
    "DEA_methods = [\"deseq2\"]\n",
    "all_N = [3,7,15] \n",
    "rankings = [\"logFC\"]\n",
    "\n",
    "import subprocess as sp\n",
    "output = sp.getoutput('squeue -u pd21v747')\n",
    "jobs_running = output.find(\"send_gse\") > 0\n",
    "\n",
    "if not jobs_running:\n",
    "    gsea_process_pipeline(outpath, outname, all_N, DEA_methods, outlier_methods, gsea_methods, libraries, rankings,\n",
    "                          gFDRs, \"p2\", overwrite=1, overwrite_merged=0, n_cohorts=20, calculate_common=False)\n",
    "    # when adding new method: overwrite merged and calculcate common only with new method, then only overwrite with all emthods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb03ecaa-d15e-4dfd-8ddd-b0e4fe36c761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f=\"/storage/homefs/pd21v747/RNASeqReplicability/data/liver/LIHC/gsea_results.txt\"\n",
    "# with open(f, \"rb\") as ff:\n",
    "#     gs = pickle.load(ff)\n",
    "    \n",
    "# gs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39962ef8-000d-427c-ace5-c20c385f6a83",
   "metadata": {},
   "source": [
    "## Merge processed data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a24dac9-1328-4c0b-a7ad-abcd6775d1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "done = [\"lung\"]\n",
    "gsea_datasets = {sites[s]: {} for s in sites if s in done}\n",
    "\n",
    "def load_gsea_results(path, site, name):\n",
    "    resultsfile = f\"{path}/{site}/{name}/gsea_results.txt\"\n",
    "    with open(resultsfile, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "for s in sites:\n",
    "    if s not in done: continue\n",
    "    gsea_datasets[sites[s]][\"site\"] = s\n",
    "    res = load_gsea_results(datapath, s, sites[s])\n",
    "    for key in res.keys():\n",
    "        gsea_datasets[sites[s]][key] = res[key]\n",
    "\n",
    "method = \"deseq2\"\n",
    "gsea_datasetsfile = f\"../data/multi/gsea_datasets.{method}.txt\"\n",
    "pickler(gsea_datasets, gsea_datasetsfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc43205b-6b44-4ce2-a9f1-c639f73d4968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tidy dataframe\n",
    "\n",
    "DEAs = DEA_methods\n",
    "FDRs = [0.05]\n",
    "#all_N=[3,5,7,9,15]\n",
    "\n",
    "    \n",
    "quantity = [\"median_rep\", \"median_terms\",\"median_mcc0\", \"median_prec0\",\n",
    "            \"median_mcc\", \"median_prec\", \"median_rec\"]\n",
    "#quantity += [q+\"_common\" for q in quantity]\n",
    "\n",
    "iterables = [gsea_datasets,all_N,outlier_methods,DEAs,gsea_methods,libraries,rankings,FDRs,quantity]\n",
    "multi_cols = pd.MultiIndex.from_product(iterables, names=[\"Data\", \"N\", \"Out\", \"DEA\", \"Enrichment\", \"Library\", \"Ranking\", \"FDR\", \"Val\"])\n",
    "combined = pd.DataFrame(columns=multi_cols)\n",
    "\n",
    "ids = [] # id connecting samples from same dataset and cohort size, used for paired-sample testing pre vs. post outlier removal\n",
    "for i, d in enumerate(gsea_datasets):\n",
    "    for j, N in enumerate(all_N):\n",
    "        k = i*len(all_N)+j \n",
    "        for out in outlier_methods:\n",
    "            for dea in DEAs:\n",
    "                for gsea in gsea_methods:\n",
    "                    #if dea != \"edger\" and gsea_methods == \"gsea_s2n\": continue\n",
    "                    for fdr in FDRs:\n",
    "                        for lib in libraries:\n",
    "                            for rnk in rankings:\n",
    "                                for quant in quantity:\n",
    "                                    try:\n",
    "                                        col = (d,N,out,dea,gsea,lib,rnk,fdr,quant)\n",
    "                                        combined.loc[0,col] = gsea_datasets[d][N][out][dea][gsea][lib][rnk][quant][fdr]\n",
    "                                        if quant == \"median_rep\": ids.append(k)\n",
    "                                    except KeyError:\n",
    "                                        print(d,N,out,dea,fdr,rnk)\n",
    "                                        assert 0\n",
    "                                \n",
    "combined_gsea_td = combined.unstack().unstack(level=\"Val\").reset_index(level=[\"Data\",\"N\",\"Out\",\"DEA\",\"Enrichment\",\"Library\",\"Ranking\",\"FDR\"], drop=False)\n",
    "combined_gsea_td[\"id\"] = ids\n",
    "combined_gsea_td.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# For outlier_method == \"none\", no adjustment is necessary, hence copy unadjusted values\n",
    "#none_ix = combined_gsea_td[combined_gsea_td[\"Out\"] == \"none\"].index # avoid setting with copy warning\n",
    "#combined_gsea_td.loc[none_ix,\"median_terms_adj\"] = combined_gsea_td.loc[none_ix,\"median_terms\"]\n",
    "#combined_gsea_td.loc[none_ix,\"median_rep_adj\"] = combined_gsea_td.loc[none_ix,\"median_rep\"]\n",
    "\n",
    "for clean in cleanout:\n",
    "    combined_gsea_td.loc[(combined_gsea_td[combined_gsea_td[\"Out\"] == clean]).index, \"Out\"] = cleanout[clean]\n",
    "for clean in cleandea:\n",
    "    combined_gsea_td.loc[(combined_gsea_td[combined_gsea_td[\"DEA\"] == clean]).index, \"DEA\"] = cleandea[clean]\n",
    "combined_gsea_td.to_csv(f\"../data/multi/combined_gsea_td.rev3.csv\")\n",
    "combined_gsea_td.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05779d0-9125-4fa7-921c-fbdf876d7679",
   "metadata": {},
   "source": [
    "## Inspect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10fdd80-f92c-4360-ad17-e89cb851bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc import get_grid_size\n",
    "\n",
    "y = \"median_prec\"\n",
    "x = \"N\"\n",
    "\n",
    "a  = combined_gsea_td\n",
    "#a = a[a[\"Library\"]==\"KEGG_2021_Human\"]\n",
    "hues = [\"Data\",\"Library\",\"Ranking\",\"N\"]\n",
    "grid = get_grid_size(len(hues), k=0, fill=True)\n",
    "fig, ax = plt.subplots(grid[0],grid[1],figsize=(6*grid[0],3*grid[1]), sharex=True,sharey=True)\n",
    "ax=ax.flatten()\n",
    "\n",
    "for i, hue in enumerate(hues):\n",
    "    sns.scatterplot(data=a, x=x, y=y, hue=hue, ax=ax[i])    \n",
    "    ax[i].invert_yaxis()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60e983b-7989-4cd1-ad52-5961f0e232ce",
   "metadata": {},
   "source": [
    "# Misc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfe34ce-99b8-4537-baa7-e044375edd0e",
   "metadata": {},
   "source": [
    "## Median replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7377dec8-4574-4951-a0e7-1e611442a02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data sets:\", len(sites))\n",
    "\n",
    "reps = dict()\n",
    "for site in sites:\n",
    "    f = datasets[sites[site]][\"datapath\"]\n",
    "    reps[site] = (len(pd.read_csv(f, index_col=0).columns)) // 2\n",
    "    print(site, reps[site])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4526deeb-0a59-4f06-9c16-aba7cadaa9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "repsval = list(reps.values())\n",
    "print(repsval)\n",
    "print(np.median(repsval), f\"[{np.min(repsval)}, {np.max(repsval)}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ebe240-8d0d-43dc-943c-eeb1e33ecdbf",
   "metadata": {},
   "source": [
    "## Filter low-expressed genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33662e9e-5fc4-4bd4-af97-52db75e89ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from R_wrappers import filterByExpr_wrapper\n",
    "\n",
    "f = \"/storage/homefs/pd21v747/RNASeqReplicability/data/GSEBP/BPLT/BPLT.csv\"\n",
    "\n",
    "outfile_filtered = f.replace(\".csv\",\"_filtered.csv\")\n",
    "filterByExpr_wrapper(inpath=f, outpath=outfile_filtered, design=\"unpaired\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fa9d7f-0213-459c-aaba-e0e54fb0927d",
   "metadata": {},
   "source": [
    "## Test DEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479e70e3-79a3-45ab-aaaf-ee3797299b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc import paired_replicate_sampler\n",
    "\n",
    "N = 15\n",
    "f = \"/storage/homefs/pd21v747/RNASeqReplicability/data/GSEBP/BPLT/BPLT.csv\"\n",
    "f = \"/storage/homefs/pd21v747/RNASeqReplicability/data/kidney/KIRC/KIRC.csv\"\n",
    "f = \"/storage/homefs/pd21v747/RNASeqReplicability/data/prostate/PRAD/PRAD.csv\"\n",
    "f = \"/storage/homefs/pd21v747/RNASeqReplicability/data/thyroid/THCA/THCA.csv\"\n",
    "#f = \"../data/GSEPN/GIPF/GIPF.csv\"\n",
    "\n",
    "tab = pd.read_csv(f, index_col=0)\n",
    "\n",
    "try:\n",
    "    df = paired_replicate_sampler(tab, N)[0]\n",
    "except:\n",
    "    c = tab.columns.str.startswith(\"control\").sum()\n",
    "    m = min(c, tab.columns.str.startswith(\"ipf\").sum())\n",
    "    tab = tab.iloc[:,list(range(m))+list(range(c,c+m))]\n",
    "    df = paired_replicate_sampler(tab, N)[0]\n",
    "    \n",
    "from DEA import normalize_counts\n",
    "df_norm = normalize_counts(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6365520-a577-4e17-8761-8cdde5807b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# design_file = \"../data/thyroid/thyroid_meta.csv\"\n",
    "\n",
    "# design = pd.read_csv(design_file, index_col=0)\n",
    "# # don't include days_to_birth since it is perfectly confounded with submitter_id\n",
    "# design = design.T.rename({\"case\":\"Condition\"},axis=1)[[\"gender\",\"submitter_id\",\"Condition\"]]\n",
    "# #design[\"gender\"] = [\"M\",\"F\"] * (len(design)//2)\n",
    "\n",
    "\n",
    "# design_file_N = \"../data/test/test.design.csv\"\n",
    "# design = design.loc[df.columns]\n",
    "\n",
    "# design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13868e0-c0a3-45d5-b593-90f4b4671280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_encoded = pd.get_dummies(design, columns=['submitter_id'], drop_first=True).drop([\"gender\",\"Condition\"],axis=1)\n",
    "# male_tumor = (design[\"gender\"] == \"male\") & (design[\"Condition\"] == \"T\")\n",
    "# female_tumor = (design[\"gender\"] == \"female\") & (design[\"Condition\"] == \"T\")\n",
    "# male_tumor.name = \"Male.Tumor\"\n",
    "# female_tumor.name = \"Female.Tumor\"\n",
    "\n",
    "# df_encoded = pd.concat([df_encoded, male_tumor, female_tumor], axis=1)\n",
    "# df_encoded.index.name = None\n",
    "# df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302103d4-7295-425a-9c70-1db66a00a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# design_file = \"../data/thyroid/thyroid_meta.csv\"\n",
    "\n",
    "# design = pd.read_csv(design_file, index_col=0)\n",
    "# # don't include days_to_birth since it is perfectly confounded with submitter_id\n",
    "# design = design.T.rename({\"case\":\"Condition\"},axis=1)[[\"gender\",\"submitter_id\",\"Condition\"]]\n",
    "# #design[\"gender\"] = [\"M\",\"F\"] * (len(design)//2)\n",
    "\n",
    "\n",
    "# design_file_N = \"../data/test/test.design.csv\"\n",
    "# design = design.loc[df.columns]\n",
    "\n",
    "\n",
    "# df_encoded = pd.get_dummies(design, columns=['gender', 'submitter_id', 'Condition'], drop_first=True)\n",
    "\n",
    "# # Add a constant column for the intercept\n",
    "# df_encoded['intercept'] = True\n",
    "\n",
    "# # Check the rank\n",
    "# matrix = df_encoded.values\n",
    "# rank = np.linalg.matrix_rank(matrix)\n",
    "# full_rank = rank == matrix.shape[1]\n",
    "\n",
    "# print(f\"Rank: {rank}\")\n",
    "# print(f\"Number of columns: {matrix.shape[1]}\")\n",
    "# print(f\"Is full rank: {full_rank}\")\n",
    "# df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ddb463-e3f4-4721-af71-7e2060a25ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# s = np.random.choice([\"M\",\"F\"],N)\n",
    "# s = np.concatenate([s,s])\n",
    "# # Example data\n",
    "# data = {\n",
    "#     'patient': [i for i in range(1, N+1)] + [i for i in range(1, N+1)],\n",
    "#     'condition': ['N'] * N + ['T'] * N,\n",
    "#     'sex': s\n",
    "# }\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# # Ensure each patient has samples in both conditions\n",
    "# assert df.groupby('patient')['condition'].nunique().eq(2).all()\n",
    "\n",
    "# # Create the design matrix\n",
    "# design = pd.get_dummies(df, columns=['patient', 'sex', 'condition'], drop_first=True)\n",
    "\n",
    "# # Check rank\n",
    "# rank = np.linalg.matrix_rank(design.values)\n",
    "# ncols = design.shape[1]\n",
    "\n",
    "# print(f\"Rank: {rank}, Number of columns: {ncols}\")\n",
    "# design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920da934-988f-450f-be52-3af02c29467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DEA import run_dea\n",
    "\n",
    "design_file = \"../data/GSEPN/GIPF/GIPF.meta.csv\"\n",
    "design_file = \"../data/thyroid/thyroid_meta.csv\"\n",
    "\n",
    "design = pd.read_csv(design_file, index_col=0)\n",
    "design = design.T.rename({\"case\":\"Condition\",\"gender\":\"Sex\",\"submitter_id\":\"Patient\"},axis=1)[[\"Sex\",\"Patient\",\"Condition\"]]\n",
    "\n",
    "\n",
    "design_file_N = \"../data/test/test.design.repeated.csv\"\n",
    "design = design.loc[df.columns]\n",
    "design.to_csv(design_file_N)\n",
    "\n",
    "outfile = f\"/storage/homefs/pd21v747/RNASeqReplicability/data/test/test.controlled.N{N}.csv\"\n",
    "edgerqlf_kwargs = {\"filter_expr\": False, \"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"], \"lfc\": 0, \"design\": design_file_N,\n",
    "                   \"check_gof\": False, \"verbose\":True}\n",
    "\n",
    "run_dea(df, outfile, \"edgerqlf\", True, **edgerqlf_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d756c55-b989-4638-84fc-ce8e7791a517",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outfile_uncontrolled = f\"/storage/homefs/pd21v747/RNASeqReplicability/data/test/test.uncontrolled.N{N}.csv\"\n",
    "edgerqlf_kwargs = {\"filter_expr\": False, \"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"], \"lfc\": 0, \"design\": \"paired\", \"check_gof\": False,\n",
    "                  \"N_control\": N, \"N_treat\": N, \"verbose\": True}\n",
    "run_dea(df, outfile_uncontrolled, \"edgerqlf\", True, **edgerqlf_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db70fc50-70ef-45fb-98e3-b621fc17d162",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_N = [4,15]#[4,5,15,100]\n",
    "\n",
    "fig, ax = plt.subplots(1,len(all_N),figsize=(4*len(all_N),4))\n",
    "\n",
    "for i, n in enumerate(all_N):\n",
    "\n",
    "    outfile = f\"/storage/homefs/pd21v747/RNASeqReplicability/data/test/test.controlled.N{n}.csv\"\n",
    "    outfile_uncontrolled = f\"/storage/homefs/pd21v747/RNASeqReplicability/data/test/test.uncontrolled.N{n}.csv\"\n",
    "\n",
    "    res = pd.read_csv(outfile, index_col=0)\n",
    "    res2 = pd.read_csv(outfile_uncontrolled, index_col=0)\n",
    "\n",
    "    ax[i].scatter(res[\"FDR\"],res2[\"FDR\"])\n",
    "    ax[i].plot( (min(res[\"FDR\"]),1), (min(res[\"FDR\"]),1), ls=\"--\",c=\"red\")\n",
    "    if n > 5:\n",
    "        ax[i].set_xscale(\"log\")\n",
    "        ax[i].set_yscale(\"log\")\n",
    "    ax[i].set_xlabel(\"FDR uncontrolled\")\n",
    "    ax[i].set_ylabel(\"FDR controlled\")\n",
    "    ax[i].set_title(f\"N={n}\")\n",
    "    \n",
    "    #ax[i].set_xlim(min(min(res[\"FDR\"]),min(res2[\"FDR\"])), 1)\n",
    "    #ax[i].set_ylim(min(min(res[\"FDR\"]),min(res2[\"FDR\"])), 1)\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d8c134-746d-464a-b3cd-454ee3177919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DEA import run_dea\n",
    "\n",
    "outfile = \"/storage/homefs/pd21v747/RNASeqReplicability/data/test/goftest.csv\"\n",
    "\n",
    "edgerqlf_kwargs = {\"filter_expr\": False, \"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"], \"lfc\": 0, \"design\": \"paired\", \"check_gof\": True}\n",
    "        \n",
    "run_dea(df, outfile, \"edgerqlf\", True, **edgerqlf_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4073300b-b9dc-40d7-a48a-f9510b53e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv(outfile, index_col=0)\n",
    "sig = res[res[\"FDR\"]<0.05]\n",
    "print(len(sig))\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9884ecc0-1a0d-4c9b-a355-6127872e858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedfit = gof.sort_values(by=\"x\").index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fe81e3-db5c-4962-9a77-e8fa82d1967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sortedfit[1]\n",
    "print(res.loc[g])\n",
    "\n",
    "plt.hist(df.loc[g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e73de6-e212-4f8b-b951-05512ec2b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = outfile.split(\"/\")\n",
    "g[-1] = \"gof.\" + g[-1]\n",
    "gof_file = \"/\".join(g)\n",
    "gof = pd.read_csv(gof_file, index_col=0)\n",
    "\n",
    "assert len(res) == len(gof)\n",
    "gof.index = res.index\n",
    "\n",
    "#gof.loc[sig.index].hist()\n",
    "gof.hist()\n",
    "plt.xlabel(\"pvalue goodness-of-fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc2fd96-501f-4636-9cf7-f0ec44cda437",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(res[\"FDR\"], gof[\"x\"], alpha=0.1)\n",
    "plt.xlabel(\"FDR DEG\")\n",
    "plt.ylabel(\"pval goodness-of-fit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d588dd6-05cc-4120-9938-3922f0f74f18",
   "metadata": {},
   "source": [
    "## Wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f525dfb9-1f71-496c-88a6-d294f8ab0be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc import paired_replicate_sampler\n",
    "\n",
    "N = 3\n",
    "f = \"/storage/homefs/pd21v747/RNASeqReplicability/data/GSEBP/BPLT/BPLT.csv\"\n",
    "f = \"/storage/homefs/pd21v747/RNASeqReplicability/data/kidney/KIRC/KIRC.csv\"\n",
    "f = \"/storage/homefs/pd21v747/RNASeqReplicability/data/prostate/PRAD/PRAD.csv\"\n",
    "f = \"/storage/homefs/pd21v747/RNASeqReplicability/data/thyroid/THCA/THCA.csv\"\n",
    "#f = \"../data/GSEPN/GIPF/GIPF.csv\"\n",
    "\n",
    "tab = pd.read_csv(f, index_col=0)\n",
    "\n",
    "try:\n",
    "    df = paired_replicate_sampler(tab, N)[0]\n",
    "except:\n",
    "    c = tab.columns.str.startswith(\"control\").sum()\n",
    "    m = min(c, tab.columns.str.startswith(\"ipf\").sum())\n",
    "    tab = tab.iloc[:,list(range(m))+list(range(c,c+m))]\n",
    "    df = paired_replicate_sampler(tab, N)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08d6790-f21b-41f6-b1de-4ba81268840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ranksums, wilcoxon\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from DEA import normalize_counts\n",
    "\n",
    "def wilcox_test(df_unnormalized, design, outfile=\"\", overwrite=False):\n",
    "    \"\"\"Perform Wilcoxon rank sum test for each gene\"\"\"\n",
    "    \n",
    "    if design == \"paired\":\n",
    "        if len(df_unnormalized.columns) % 2 != 0:\n",
    "            raise Exception(\"df must have even number of columns for paired design\")\n",
    "        test_func = wilcoxon\n",
    "\n",
    "    elif design == \"unpaired\":\n",
    "        test_func = ranksums\n",
    "    else:\n",
    "        raise Exception(\"General design matrix not supported, must be paired or unpaired\")\n",
    "        \n",
    "    if os.path.isfile(outfile) and not overwrite:\n",
    "        logging.info(\"Existing file not overwritten\")\n",
    "        return\n",
    "    \n",
    "    df = normalize_counts(df_unnormalized)\n",
    "    wilcoxon_results = {}\n",
    "    for i, gene in enumerate(df.index):\n",
    "        control_values = df.iloc[i, :len(df.columns)//2]\n",
    "        treatment_values = df.iloc[i, len(df.columns)//2:]\n",
    "\n",
    "        try:\n",
    "            statistic, p_value = test_func(control_values, treatment_values)\n",
    "        except ValueError:\n",
    "            statistic, p_value = np.nan, np.nan\n",
    "        \n",
    "        wilcoxon_results[gene] = {'statistic': statistic, 'p_value': p_value}\n",
    "\n",
    "    wilcoxon_results_df = pd.DataFrame.from_dict(wilcoxon_results, orient='index')\n",
    "    p_values = wilcoxon_results_df['p_value']\n",
    "    \n",
    "    _, corrected_p_values, _, _ = multipletests(p_values.dropna(), method='fdr_bh')\n",
    "    wilcoxon_results_df.loc[~wilcoxon_results_df['p_value'].isna(), 'FDR'] = corrected_p_values    \n",
    "\n",
    "    if outfile != \"\":\n",
    "        save_df(wilcoxon_results_df, outfile)\n",
    "    return wilcoxon_results_df\n",
    "\n",
    "\n",
    "def save_df(df, path):\n",
    "    file_extension = path.split('.')[-1].lower()\n",
    "    if file_extension == 'csv':\n",
    "        df.to_csv(path)\n",
    "    elif file_extension == 'feather':\n",
    "        df.to_feather(path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file extension. Supported extensions are: .csv and .feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e65b64-c400-48ad-92f9-edff2e15a0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DEA import run_dea\n",
    "\n",
    "outfile = \"/storage/homefs/pd21v747/RNASeqReplicability/data/test/test.csv\"\n",
    "edgerqlf_kwargs = {\"filter_expr\": False, \"cols_to_keep\": [\"logFC\",\"logCPM\",\"FDR\"], \"lfc\": 0, \"design\": \"paired\"}\n",
    "run_dea(df, outfile, \"edgerqlf\", True, **edgerqlf_kwargs)\n",
    "res = pd.read_csv(outfile, index_col=0)\n",
    "sig = res[res[\"FDR\"]<0.05]\n",
    "print(len(sig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a21671-2305-4080-9fe7-5790466ec4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile=\"/storage/homefs/pd21v747/RNASeqReplicability/data/test/wilcox_test_unpaired.csv\"\n",
    "wilcoxon_results_df_unpaired = wilcox_test(df, outfile=outfile, design=\"unpaired\", overwrite=True)\n",
    "\n",
    "outfile=\"/storage/homefs/pd21v747/RNASeqReplicability/data/test/wilcox_test.csv\"\n",
    "wilcoxon_results_df_pair = wilcox_test(df, outfile=outfile, design=\"paired\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277085d4-ee34-40b1-8293-a0c3866f33c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=wilcoxon_results_df_pair[\"FDR\"], y=res[\"FDR\"], kind=\"reg\", line_kws=dict(color=\"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b19829-98bd-4ada-87ab-59b6d56057f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=wilcoxon_results_df_unpaired[\"FDR\"], y=res[\"FDR\"], kind=\"reg\", line_kws=dict(color=\"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f173dd-0362-4528-bb37-6d0f6454c865",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=wilcoxon_results_df_unpaired[\"FDR\"], y=wilcoxon_results_df_pair[\"FDR\"], kind=\"reg\", line_kws=dict(color=\"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ce6f91-5a84-4baa-a411-5386d431ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_wrs = wilcoxon_results_df[wilcoxon_results_df[\"FDR\"]<0.05]\n",
    "print(len(sig.index), len(sig_wrs), len(sig.index.intersection(sig_wrs.index)))\n",
    "\n",
    "sig_wrs_norm = wilcoxon_results_df_norm[wilcoxon_results_df_norm[\"FDR\"]<0.05]\n",
    "print(len(sig.index), len(sig_wrs_norm), len(sig.index.intersection(sig_wrs_norm.index)))\n",
    "\n",
    "len(sig_wrs.index.intersection(sig_wrs_norm.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e523946-1291-4c2a-bf10-f3e5588bb3ef",
   "metadata": {},
   "source": [
    "### Formal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c338922-8bd6-4216-a10a-75242f2341f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = normalize_counts(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5535f2c0-cec3-4546-b936-823fb379846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_values = df_norm.iloc[:, :len(df_norm.columns)//2] + 1\n",
    "treatment_values = df_norm.iloc[:, len(df_norm.columns)//2:] + 1\n",
    "control_values.columns = [c[1:] for c in control_values.columns]\n",
    "treatment_values.columns = [c[1:] for c in treatment_values.columns]\n",
    "\n",
    "control_values = np.log2(control_values)\n",
    "treatment_values = np.log2(treatment_values)\n",
    "\n",
    "lfc_thresh = 0\n",
    "#treatment_values -= 2**lfc_thresh\n",
    "\n",
    "_, p_values = wilcoxon(control_values, treatment_values, axis=1, alternative=\"greater\")\n",
    "\n",
    "_, corrected_p_values, _, _ = multipletests(p_values, method='fdr_bh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f80103-5636-4079-81b0-2392acbd87f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(control_values-treatment_values).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577b8dbe-951a-4d61-8625-c9d77bc13473",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(corrected_p_values)\n",
    "(corrected_p_values < 0.05).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d826cbd0-c577-47f3-8776-251e7f0fd8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wilcoxon_results = {}\n",
    "for i, gene in enumerate(df_norm.index):\n",
    "    if i > 100: break\n",
    "    control_values = df_norm.iloc[i, :len(df_norm.columns)//2]\n",
    "    treatment_values = df_norm.iloc[i, len(df_norm.columns)//2:]\n",
    "\n",
    "    try:\n",
    "        statistic, p_value = wilcoxon(control_values, treatment_values)\n",
    "    except ValueError:\n",
    "        statistic, p_value = np.nan, np.nan\n",
    "\n",
    "    wilcoxon_results[gene] = {'statistic': statistic, 'p_value': p_value}\n",
    "\n",
    "wilcoxon_results_df = pd.DataFrame.from_dict(wilcoxon_results, orient='index')\n",
    "p_values = wilcoxon_results_df['p_value']\n",
    "\n",
    "_, corrected_p_values, _, _ = multipletests(p_values.dropna(), method='fdr_bh')\n",
    "wilcoxon_results_df.loc[~wilcoxon_results_df['p_value'].isna(), 'FDR'] = corrected_p_values  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2e3733-0952-42d2-8c85-952a5fd509e5",
   "metadata": {},
   "source": [
    "# Misc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a43d0f-57b1-4b59-b0d6-6f56a91b55c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from process import delete_redundant_slurmfiles\n",
    "\n",
    "delete_redundant_slurmfiles(outpath, outname, all_N)            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d315f72e-d093-4c2f-b946-342d4050bc26",
   "metadata": {},
   "source": [
    "## ZIP\n",
    "\n",
    "tar -czf unpaired_folders.tar.gz $(find . -type d -name '*_unpaired')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fce6b5-092e-4a5a-aae6-3b74f4ae1015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "def zip_gsea_subdir(directory, target_subdir):\n",
    "    # Define the full path to the gsea subdirectory\n",
    "    gsea_dir = os.path.join(directory, target_subdir)\n",
    "\n",
    "    # Check if the gsea subdirectory exists\n",
    "    if os.path.exists(gsea_dir) and os.path.isdir(gsea_dir):\n",
    "        # Define the path for the zip file\n",
    "        zip_filename = os.path.join(directory, f\"{target_subdir}.zip\")\n",
    "        \n",
    "        try:\n",
    "            # Zip the gsea folder\n",
    "            with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "                # Walk through the gsea directory and add files to the zip\n",
    "                for root, dirs, files in os.walk(gsea_dir):\n",
    "                    for file in files:\n",
    "                        full_path = os.path.join(root, file)\n",
    "                        relative_path = os.path.relpath(full_path, start=gsea_dir)\n",
    "                        zipf.write(full_path, arcname=relative_path)\n",
    "\n",
    "            print(f\"{target_subdir} subdir zipped successfully into {zip_filename}\")\n",
    "\n",
    "            # Remove the original gsea folder\n",
    "            shutil.rmtree(gsea_dir)\n",
    "            print(f\"{target_subdir} subdir removed after zipping.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "    else:\n",
    "        print(f\"{target_subdir} subdir does not exist in {directory}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e19834-8215-4d80-85f4-08a0d063095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_N = [3,4,5,6,7,8,9,10,12,15]\n",
    "cancer_sites = {\"liver\": \"LIHC\",\n",
    "         \"thyroid\": \"THCA\",\n",
    "         \"lung\": \"LUAD\",\n",
    "         \"lung2\": \"LUSC\",\n",
    "         \"kidney\": \"KIRC\",\n",
    "         \"colorectal\": \"COAD\",\n",
    "         \"breast\": \"BRCA\",\n",
    "         \"prostate\": \"PRAD\"}\n",
    "\n",
    "cancer_sites_unpaired = {k+\"_unpaired\":v+\"_unpaired\" for k,v in cancer_sites.items()}\n",
    "\n",
    "for d in cancer_sites_unpaired:\n",
    "    outpath = f\"../data/{d}/{cancer_sites_unpaired[d]}\"\n",
    "    for N in all_N:\n",
    "        sub = f\"{cancer_sites_unpaired[d]}_N{N}\"\n",
    "        outpath_n = os.path.join(outpath,sub)\n",
    "        print(outpath_n)\n",
    "        zip_gsea_subdir(outpath, sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a9d8b1-a700-4b80-8897-bf2420635c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_N = [3,4,5,6,7,8,9,10,12,15]\n",
    "# cohorts = range(1,101)\n",
    "\n",
    "# for d in datasets:\n",
    "#     outpath = datasets[d][\"outpath\"]\n",
    "#     for N in all_N:\n",
    "#         outpath_n = os.path.join(outpath,f\"{d}_N{N}\"\n",
    "#         print(outpath_n)\n",
    "#         #for cohort in cohorts:\n",
    "#             #outpath_c = os.path.join(outpath,f\"{d}_N{N}/{d}_N{N}_{cohort:04}\")\n",
    "#             #print(outpath_c)\n",
    "#             #zip_gsea_subdir(outpath_c, \"gsea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1854f49-54b3-47df-9003-ff1dbe844932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "importlib.reload(sys.modules[\"enrichment\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad887a9-a60a-4263-8de4-df0c53700e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in BRCA.*; do\n",
    "    new_name=\"BRCA_unpaired.${file#*.}\"\n",
    "    mv \"$file\" \"$new_name\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112aafde-8f4a-44b2-80bf-89ed4f3825bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rna-rep)",
   "language": "python",
   "name": "rna-rep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
